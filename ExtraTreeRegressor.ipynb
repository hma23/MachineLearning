{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x5EA9gOl5fl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54L_PuJzoP34",
        "outputId": "bfb1b704-4d2a-4ca7-95bc-3a36b09cf8a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#To show all records for our data frame\n",
        "pd.set_option(\"display.min_rows\", 200)\n",
        "pd.set_option(\"display.max_rows\", 500)\n",
        "pd.get_option(\"display.max_rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j4rI5RQmhqD",
        "outputId": "aad1d761-f4ca-40e9-e128-3151d65961c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KCddeJ5RXtE"
      },
      "source": [
        "## Data Exploration and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4DXWrO5Mmhso",
        "outputId": "a434d52f-e2d0-45d0-a938-2b83a5694eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-28d4f0a1-240b-46b9-ada2-c09da5b8c5bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>box_output</th>\n",
              "      <th>Latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>89</td>\n",
              "      <td>71.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>43</td>\n",
              "      <td>146.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>28</td>\n",
              "      <td>218.549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>20</td>\n",
              "      <td>291.848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>17</td>\n",
              "      <td>365.552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28d4f0a1-240b-46b9-ada2-c09da5b8c5bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28d4f0a1-240b-46b9-ada2-c09da5b8c5bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28d4f0a1-240b-46b9-ada2-c09da5b8c5bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size Intensity  box_output  Latency\n",
              "0             1          13      High          89   71.048\n",
              "1             2          13      High          43  146.048\n",
              "2             3          13      High          28  218.549\n",
              "3             4          13      High          20  291.848\n",
              "4             5          13      High          17  365.552"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/data/Book1_new.xlsx')\n",
        "#uncomment next line to show all values\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "uIS8XkNpZKl8",
        "outputId": "f0a42dcc-6828-4038-f907-2d49cdc2dced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1bac7940-1636-47ae-b496-19f965a1fdb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>box_output</th>\n",
              "      <th>Latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.631579</td>\n",
              "      <td>12.226316</td>\n",
              "      <td>46.052632</td>\n",
              "      <td>412.643607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.824324</td>\n",
              "      <td>3.342265</td>\n",
              "      <td>62.498824</td>\n",
              "      <td>387.241382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>11.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.250000</td>\n",
              "      <td>104.718917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>251.401000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>659.292825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>1645.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bac7940-1636-47ae-b496-19f965a1fdb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bac7940-1636-47ae-b496-19f965a1fdb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bac7940-1636-47ae-b496-19f965a1fdb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Block_period  Block_size  box_output      Latency\n",
              "count    190.000000  190.000000  190.000000   190.000000\n",
              "mean       6.631579   12.226316   46.052632   412.643607\n",
              "std        3.824324    3.342265   62.498824   387.241382\n",
              "min        1.000000    7.000000    3.000000    11.035000\n",
              "25%        4.000000   10.000000    9.250000   104.718917\n",
              "50%        5.000000   13.000000   26.000000   251.401000\n",
              "75%       10.000000   14.000000   62.000000   659.292825\n",
              "max       14.000000   21.000000  589.000000  1645.100000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9TfswLHRh5L"
      },
      "outputs": [],
      "source": [
        "#sns.pairplot(df, height=3, aspect=1.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PevyUGkUDXU"
      },
      "outputs": [],
      "source": [
        "#sns.heatmap(df.corr(), annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYxNrC70VkB8"
      },
      "outputs": [],
      "source": [
        "#sns.boxplot(x=\"Intensity\", y=\"box_output\", data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHEpBCU-pouD"
      },
      "outputs": [],
      "source": [
        "#sns.boxplot(x=\"Intensity\", y=\"Latency\", data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntDBSGoemyq2"
      },
      "outputs": [],
      "source": [
        "# Make dummies for our catagorial variables to make it able to insert to machine learning models\n",
        "df_all = df.copy()\n",
        "df_all_dum = pd.get_dummies(df_all, prefix=['Intensity'], columns=['Intensity'])\n",
        "#uncomment next line to show all values\n",
        "# df_all_dum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9dZn52kqQxj"
      },
      "outputs": [],
      "source": [
        "# We will try to convert the intenisty to ordinal numbers and see the difference in accurcy using pycaret \n",
        "df_all_ordinal = df.copy()\n",
        "df_all_ordinal = df_all_ordinal.replace({\"Intensity\":{\"Low\": 23600, \"Medium\": 35788, \"High\":143362 }})\n",
        "#uncomment next line to show all values\n",
        "# df_all_ordinal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoSSXm7bPja0"
      },
      "source": [
        "### Comparison between different Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305qRGc4aKuZ",
        "outputId": "9489128b-29cc-45fe-c64c-866a57bac7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.7/dist-packages (2.3.5)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.9.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.0.1)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.5)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.post1)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.19.5)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.1.0)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.22.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.19.0)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.4)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.3.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret) (3.0.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.37.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.12.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.27.1)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.9.0)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.7.4)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
            "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.0)\n",
            "Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (6.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (21.2.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (4.2.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas-profiling>=2.8.0->pycaret) (3.10.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (3.6.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.1)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.16.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.27)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (20.1.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (5.0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.18.7)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.1.25)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.1.6)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.0.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow->pycaret) (1.2.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (5.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.12.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.7.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (1.17)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn->pycaret) (0.5.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4756-TDtmw_P"
      },
      "outputs": [],
      "source": [
        "from pycaret.regression import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFNR3iRz_Zh"
      },
      "source": [
        "### Predict box_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cZM0QEI05Bb"
      },
      "outputs": [],
      "source": [
        "#for dummy variable approche\n",
        "df_ouput_dum = df_all_dum.copy()\n",
        "df_ouput_dum.drop('Latency', axis=1, inplace=True)\n",
        "\n",
        "#for numerical ordinal variable approche\n",
        "df_ouput_ord = df_all_ordinal.copy()\n",
        "df_ouput_ord.drop('Latency', axis=1, inplace=True)\n",
        "\n",
        "#uncomment one of next line to show it's values\n",
        "# df_ouput_dum\n",
        "# df_ouput_ord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f88f2eb67204b459949d5115f5751e0",
            "3f27a94f3f884e6dabdb11887cbaefc3",
            "1fed08ffa8d54478947f230646ff6cb6",
            "9f21af9ca86345148c1d5ca6eed4e5fa",
            "09ed1d21d50643599350dfa868146b39",
            "29d55a132fdb4e75a10d66d5d0c61bf4"
          ]
        },
        "id": "WdBVzOiSmxCz",
        "outputId": "e12b0f9f-25d4-4d2f-ebd2-42e8a1b8f3f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-10a82280-b24f-4c19-adfc-0e188d088c83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>box_output</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(190, 4)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(132, 3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(58, 3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>KFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>reg-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>USI</td>\n",
              "      <td>dc6c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Transform Target</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Transform Target Method</td>\n",
              "      <td>box-cox</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10a82280-b24f-4c19-adfc-0e188d088c83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10a82280-b24f-4c19-adfc-0e188d088c83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10a82280-b24f-4c19-adfc-0e188d088c83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               123\n",
              "1                                   Target        box_output\n",
              "2                            Original Data          (190, 4)\n",
              "3                           Missing Values             False\n",
              "4                         Numeric Features                 3\n",
              "5                     Categorical Features                 0\n",
              "6                         Ordinal Features             False\n",
              "7                High Cardinality Features             False\n",
              "8                  High Cardinality Method              None\n",
              "9                    Transformed Train Set          (132, 3)\n",
              "10                    Transformed Test Set           (58, 3)\n",
              "11                      Shuffle Train-Test              True\n",
              "12                     Stratify Train-Test             False\n",
              "13                          Fold Generator             KFold\n",
              "14                             Fold Number                10\n",
              "15                                CPU Jobs                -1\n",
              "16                                 Use GPU             False\n",
              "17                          Log Experiment             False\n",
              "18                         Experiment Name  reg-default-name\n",
              "19                                     USI              dc6c\n",
              "20                         Imputation Type            simple\n",
              "21          Iterative Imputation Iteration              None\n",
              "22                         Numeric Imputer              mean\n",
              "23      Iterative Imputation Numeric Model              None\n",
              "24                     Categorical Imputer          constant\n",
              "25  Iterative Imputation Categorical Model              None\n",
              "26           Unknown Categoricals Handling    least_frequent\n",
              "27                               Normalize             False\n",
              "28                        Normalize Method              None\n",
              "29                          Transformation             False\n",
              "30                   Transformation Method              None\n",
              "31                                     PCA             False\n",
              "32                              PCA Method              None\n",
              "33                          PCA Components              None\n",
              "34                     Ignore Low Variance             False\n",
              "35                     Combine Rare Levels             False\n",
              "36                    Rare Level Threshold              None\n",
              "37                         Numeric Binning             False\n",
              "38                         Remove Outliers             False\n",
              "39                      Outliers Threshold              None\n",
              "40                Remove Multicollinearity             False\n",
              "41             Multicollinearity Threshold              None\n",
              "42             Remove Perfect Collinearity              True\n",
              "43                              Clustering             False\n",
              "44                    Clustering Iteration              None\n",
              "45                     Polynomial Features             False\n",
              "46                       Polynomial Degree              None\n",
              "47                    Trignometry Features             False\n",
              "48                    Polynomial Threshold              None\n",
              "49                          Group Features             False\n",
              "50                       Feature Selection             False\n",
              "51                Feature Selection Method           classic\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                        Transform Target             False\n",
              "57                 Transform Target Method           box-cox"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "exp_reg101 = setup(data = df_ouput_ord, target = 'box_output', numeric_features = ['Block_period','Block_size','Intensity'], session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735,
          "referenced_widgets": [
            "9c3738e4159042778f6cea4eb5c03955",
            "5e16571292da4f9eb8771b5ad2e766d8",
            "2cff73513a624e09ad11ff2f12f8499f"
          ]
        },
        "id": "jTM74Tb5aAlu",
        "outputId": "8c52de50-f8ee-4412-ca48-7c43653eb880"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4e1a6a99-0a17-45f1-be85-dce327f43408\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "      <td>6.6435</td>\n",
              "      <td>1091.4478</td>\n",
              "      <td>15.8759</td>\n",
              "      <td>0.9408</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.0777</td>\n",
              "      <td>0.359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbr</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>7.4212</td>\n",
              "      <td>1035.6056</td>\n",
              "      <td>15.4335</td>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.1331</td>\n",
              "      <td>0.1084</td>\n",
              "      <td>0.041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>8.6183</td>\n",
              "      <td>1315.5203</td>\n",
              "      <td>18.7493</td>\n",
              "      <td>0.9153</td>\n",
              "      <td>0.1486</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Regressor</td>\n",
              "      <td>11.1159</td>\n",
              "      <td>1369.2500</td>\n",
              "      <td>23.7514</td>\n",
              "      <td>0.8443</td>\n",
              "      <td>0.2016</td>\n",
              "      <td>0.1531</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Regressor</td>\n",
              "      <td>15.0304</td>\n",
              "      <td>2354.4702</td>\n",
              "      <td>29.8594</td>\n",
              "      <td>0.7688</td>\n",
              "      <td>0.2682</td>\n",
              "      <td>0.1859</td>\n",
              "      <td>0.063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>AdaBoost Regressor</td>\n",
              "      <td>21.0480</td>\n",
              "      <td>1770.2670</td>\n",
              "      <td>31.9032</td>\n",
              "      <td>0.6751</td>\n",
              "      <td>0.6505</td>\n",
              "      <td>0.9295</td>\n",
              "      <td>0.053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>19.0264</td>\n",
              "      <td>2245.2876</td>\n",
              "      <td>32.4069</td>\n",
              "      <td>0.6616</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.4558</td>\n",
              "      <td>0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llar</th>\n",
              "      <td>Lasso Least Angle Regression</td>\n",
              "      <td>27.2688</td>\n",
              "      <td>3245.0144</td>\n",
              "      <td>41.1229</td>\n",
              "      <td>0.4665</td>\n",
              "      <td>0.6910</td>\n",
              "      <td>1.0097</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>br</th>\n",
              "      <td>Bayesian Ridge</td>\n",
              "      <td>28.3402</td>\n",
              "      <td>2885.7628</td>\n",
              "      <td>40.2005</td>\n",
              "      <td>0.4179</td>\n",
              "      <td>0.7734</td>\n",
              "      <td>1.4871</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>28.5719</td>\n",
              "      <td>2897.3036</td>\n",
              "      <td>40.3545</td>\n",
              "      <td>0.4093</td>\n",
              "      <td>0.7838</td>\n",
              "      <td>1.5357</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lasso</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>28.7809</td>\n",
              "      <td>2897.8530</td>\n",
              "      <td>40.4761</td>\n",
              "      <td>0.4013</td>\n",
              "      <td>0.8018</td>\n",
              "      <td>1.5803</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>28.8415</td>\n",
              "      <td>2897.1509</td>\n",
              "      <td>40.5109</td>\n",
              "      <td>0.3988</td>\n",
              "      <td>0.8023</td>\n",
              "      <td>1.5948</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>28.8453</td>\n",
              "      <td>2897.0189</td>\n",
              "      <td>40.5125</td>\n",
              "      <td>0.3986</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>1.5957</td>\n",
              "      <td>0.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lar</th>\n",
              "      <td>Least Angle Regression</td>\n",
              "      <td>28.8458</td>\n",
              "      <td>2897.1771</td>\n",
              "      <td>40.5137</td>\n",
              "      <td>0.3986</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>1.5957</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huber</th>\n",
              "      <td>Huber Regressor</td>\n",
              "      <td>32.1434</td>\n",
              "      <td>5127.1389</td>\n",
              "      <td>51.1921</td>\n",
              "      <td>0.2601</td>\n",
              "      <td>1.0815</td>\n",
              "      <td>0.9496</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omp</th>\n",
              "      <td>Orthogonal Matching Pursuit</td>\n",
              "      <td>32.6134</td>\n",
              "      <td>3918.3942</td>\n",
              "      <td>50.6036</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>0.9187</td>\n",
              "      <td>1.3668</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Regressor</td>\n",
              "      <td>44.5952</td>\n",
              "      <td>5233.1223</td>\n",
              "      <td>60.2192</td>\n",
              "      <td>-0.2737</td>\n",
              "      <td>1.2653</td>\n",
              "      <td>2.7355</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>par</th>\n",
              "      <td>Passive Aggressive Regressor</td>\n",
              "      <td>245.8966</td>\n",
              "      <td>151473.4188</td>\n",
              "      <td>293.6684</td>\n",
              "      <td>-164.9846</td>\n",
              "      <td>2.6131</td>\n",
              "      <td>19.8490</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e1a6a99-0a17-45f1-be85-dce327f43408')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e1a6a99-0a17-45f1-be85-dce327f43408 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e1a6a99-0a17-45f1-be85-dce327f43408');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model       MAE          MSE      RMSE  \\\n",
              "et                  Extra Trees Regressor    6.6435    1091.4478   15.8759   \n",
              "gbr           Gradient Boosting Regressor    7.4212    1035.6056   15.4335   \n",
              "rf                Random Forest Regressor    8.6183    1315.5203   18.7493   \n",
              "dt                Decision Tree Regressor   11.1159    1369.2500   23.7514   \n",
              "knn                 K Neighbors Regressor   15.0304    2354.4702   29.8594   \n",
              "ada                    AdaBoost Regressor   21.0480    1770.2670   31.9032   \n",
              "lightgbm  Light Gradient Boosting Machine   19.0264    2245.2876   32.4069   \n",
              "llar         Lasso Least Angle Regression   27.2688    3245.0144   41.1229   \n",
              "br                         Bayesian Ridge   28.3402    2885.7628   40.2005   \n",
              "en                            Elastic Net   28.5719    2897.3036   40.3545   \n",
              "lasso                    Lasso Regression   28.7809    2897.8530   40.4761   \n",
              "ridge                    Ridge Regression   28.8415    2897.1509   40.5109   \n",
              "lr                      Linear Regression   28.8453    2897.0189   40.5125   \n",
              "lar                Least Angle Regression   28.8458    2897.1771   40.5137   \n",
              "huber                     Huber Regressor   32.1434    5127.1389   51.1921   \n",
              "omp           Orthogonal Matching Pursuit   32.6134    3918.3942   50.6036   \n",
              "dummy                     Dummy Regressor   44.5952    5233.1223   60.2192   \n",
              "par          Passive Aggressive Regressor  245.8966  151473.4188  293.6684   \n",
              "\n",
              "                R2   RMSLE     MAPE  TT (Sec)  \n",
              "et          0.9408  0.1055   0.0777     0.359  \n",
              "gbr         0.9367  0.1331   0.1084     0.041  \n",
              "rf          0.9153  0.1486   0.1099     0.413  \n",
              "dt          0.8443  0.2016   0.1531     0.015  \n",
              "knn         0.7688  0.2682   0.1859     0.063  \n",
              "ada         0.6751  0.6505   0.9295     0.053  \n",
              "lightgbm    0.6616  0.6280   0.4558     0.061  \n",
              "llar        0.4665  0.6910   1.0097     0.014  \n",
              "br          0.4179  0.7734   1.4871     0.012  \n",
              "en          0.4093  0.7838   1.5357     0.016  \n",
              "lasso       0.4013  0.8018   1.5803     0.016  \n",
              "ridge       0.3988  0.8023   1.5948     0.015  \n",
              "lr          0.3986  0.8024   1.5957     0.310  \n",
              "lar         0.3986  0.8024   1.5957     0.014  \n",
              "huber       0.2601  1.0815   0.9496     0.021  \n",
              "omp         0.0484  0.9187   1.3668     0.012  \n",
              "dummy      -0.2737  1.2653   2.7355     0.015  \n",
              "par      -164.9846  2.6131  19.8490     0.013  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
              "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                    max_samples=None, min_impurity_decrease=0.0,\n",
              "                    min_impurity_split=None, min_samples_leaf=1,\n",
              "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
              "                    random_state=123, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umHIw6RPQFdz"
      },
      "source": [
        "**After apply pycaret regression with intensty numirc ordinal and dummies variable we note that max accurcy for dummies approch with is with gradiant boast regressor with R2 = .93 and for numirc ordianal the best model is extra tree regressor with R2 = .94 so numirc approch is slightly better than dummies variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GmOLfbpLg4Rh",
        "outputId": "fdcecf10-a282-47e1-9b14-bb6dae311322"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-159074d3-4188-44ab-bcfa-389e604dcfe8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-159074d3-4188-44ab-bcfa-389e604dcfe8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-159074d3-4188-44ab-bcfa-389e604dcfe8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-159074d3-4188-44ab-bcfa-389e604dcfe8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  Intensity\n",
              "0             1          13     143362\n",
              "1             2          13     143362\n",
              "2             3          13     143362\n",
              "3             4          13     143362\n",
              "4             5          13     143362"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#split our data to y that contain our output \"box_output\" and to x that conatin the featuers inputs for our model\n",
        "y_output=df_ouput_ord[\"box_output\"]\n",
        "x_output=df_ouput_ord.copy()\n",
        "x_output.drop(columns = ['box_output'],inplace = True)\n",
        "x_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd5-bduDhY5A"
      },
      "outputs": [],
      "source": [
        "#split x,y to train and test to measure the accurcy of the model\n",
        "X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.2, random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsKho5Cv-l58"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "def reg_out(rand):\n",
        "  for i in range(rand):\n",
        "    print('random state is',i)\n",
        "    X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.1, random_state = i)\n",
        "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0,bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                        max_samples=None, min_impurity_decrease=0.0,\n",
        "                        min_impurity_split=None, min_samples_leaf=1,\n",
        "                        min_samples_split=2, min_weight_fraction_leaf=0.0,n_jobs=-1, oob_score=False,\n",
        "                        verbose=0, warm_start=False).fit(X_train_output, y_train_output)\n",
        "\n",
        "    R2_score = reg.score(X_test_output, y_test_output)\n",
        "    print(\"R2 score for this model is\", R2_score)\n",
        "    y_pred_output = reg.predict(X_test_output)\n",
        "    MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "    RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "    print(\"RMSE score for this model is\", RMSE)\n",
        "\n",
        "# reg_out(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgyWKILeLeLm",
        "outputId": "86283938-a1ba-4ab5-fde7-8f906aaa06f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for this model is 0.9968461133890045\n",
            "RMSE score for this model is 1.562639467459835\n"
          ]
        }
      ],
      "source": [
        "#from above equation we can note that the best random state is 1 to make model learning well and generlize for validation data\n",
        "X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.1, random_state = 1)\n",
        "reg = ExtraTreesRegressor(n_estimators=100, random_state=0,bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_output, y_train_output)\n",
        "\n",
        "R2_score = reg.score(X_test_output, y_test_output)\n",
        "print(\"R2 score for this model is\", R2_score)\n",
        "\n",
        "y_pred_output = reg.predict(X_test_output)\n",
        "MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "print(\"RMSE score for this model is\", RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfKR52myGGLE",
        "outputId": "c47ffe65-d6e7-4176-c3b7-068adee3dc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 1.5626394674598347\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse_out = mean_squared_error(y_test_output, y_pred_output)\n",
        "sk_rmse_out = sk_mse_out**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NilPkG6CGPeJ",
        "outputId": "c0560476-781a-4934-e216-7cb6f09ae741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -19.848016 using {'criterion': 'mse', 'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 150}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#define your own mse and set greater_is_better=False\n",
        "# mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
        "\n",
        "etr = ExtraTreesRegressor(n_estimators=100).fit(X_train_output, y_train_output)\n",
        "                            \n",
        "param_grid = {\n",
        "    'n_estimators': [100,120,130,150],\n",
        "    'criterion': ['mse', 'mae'],\n",
        "    'max_depth': [80,100,110],\n",
        "    #'oob_score': [True, False],\n",
        "    'max_features': ['auto','sqrt','log2'],  \n",
        "    #'bootstrap': [True, False],\n",
        "    #'warm_start': [True, False],\n",
        "    'min_samples_split': [1,2]\n",
        "}\n",
        "\n",
        "gcv = GridSearchCV(etr,param_grid,scoring='neg_root_mean_squared_error',cv=5,n_jobs=-1).fit(x_output,y_output)\n",
        "\n",
        "# grid_result = gsc.fit(x_output, y_output)\n",
        "\n",
        "print(\"Best: %f using %s\" % (gcv.best_score_, gcv.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySmK3crQIPhu"
      },
      "source": [
        "## Visualizations\n",
        "### actual and predicted box_output vs Model featuers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "myyAI0ERL8qJ",
        "outputId": "358cf573-2ddb-4b5b-c21b-b6b78a7e1d0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5dcdd53b-c66d-4419-be00-7e9817447528\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>actual_output</th>\n",
              "      <th>pred_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>89</td>\n",
              "      <td>89.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>43</td>\n",
              "      <td>43.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>28</td>\n",
              "      <td>28.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>20</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>17</td>\n",
              "      <td>17.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dcdd53b-c66d-4419-be00-7e9817447528')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dcdd53b-c66d-4419-be00-7e9817447528 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dcdd53b-c66d-4419-be00-7e9817447528');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  Intensity  actual_output  pred_output\n",
              "0             1          13     143362             89        89.00\n",
              "1             2          13     143362             43        43.00\n",
              "2             3          13     143362             28        28.00\n",
              "3             4          13     143362             20        20.00\n",
              "4             5          13     143362             17        17.41"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#combine x_output,y_output and y_pred_all on one table to be able to visiualize it\n",
        "y_pred_alloutput = reg.predict(x_output)\n",
        "\n",
        "df_vis_output = x_output.copy()\n",
        "df_vis_output['actual_output'] = y_output\n",
        "df_vis_output['pred_output'] = y_pred_alloutput\n",
        "df_vis_output.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance of ExtraTreeRegressor for Throughput"
      ],
      "metadata": {
        "id": "RtVAvarsbjHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "iu0M4r1lILCS",
        "outputId": "d0fc2123-9f04-4a82-f386-acaa4896e8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Error: -5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa6707460d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = [20, 10])\n",
        "base_color = sns.color_palette()[0]\n",
        " \n",
        "# plt.subplot(1, 2, 1)\n",
        "# # plot Block_period VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_period', y='actual_output', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_period', y='pred_output', color='red')\n",
        "# plt.title('Block_period vs actual and prdicted output')\n",
        "# plt.ylabel('Output')\n",
        "# plt.xlabel('Block_period')\n",
        "# plt.legend(['actual_output', 'pred_output'], loc='upper right')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plot Block_size VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_size', y='actual_output', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_size', y='pred_output', color='red')\n",
        "# plt.title('Block_size vs actual and predicted output')\n",
        "# plt.ylabel('Output')\n",
        "# plt.xlabel('Block_size')\n",
        "# plt.legend(['actual_output', 'pred_output'], loc='upper right')\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "#to see the relationship between the predicted values using scattered graph\n",
        "## test\n",
        "\n",
        "## residuals\n",
        "residuals = y_test_output - y_pred_output\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true  = y_test_output.get(max_idx)\n",
        "max_pred = y_pred_output[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))\n",
        "\n",
        "from statsmodels.graphics.api import abline_plot\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "ax.scatter(y_pred_output, y_test_output, color=\"black\")\n",
        "abline_plot(intercept=0, slope=1, color=\"red\", ax=ax)\n",
        "#ax[0].vlines(x=max_pred, ymin=max_true, ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "ax.grid(True)\n",
        "ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs Actual Throughput\")\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "## Plot predicted vs residuals\n",
        "# ax[1].scatter(y_pred_output, residuals, color=\"red\")\n",
        "# ax[1].vlines(x=max_pred, ymin=0, ymax=max_error, color='black', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "# ax[1].grid(True)\n",
        "# ax[1].set(xlabel=\"Predicted\", ylabel=\"Residuals\", title=\"Predicted vs Residuals\")\n",
        "# ax[1].hlines(y=0, xmin=np.min(y_pred_output), xmax=np.max(y_pred_output))\n",
        "# ax[1].legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R9U-GzuQY1c"
      },
      "source": [
        "## Implement of GaussianProcess Regression model for predicting Throughput and Latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa1M_3B1iYeT",
        "outputId": "ccb51835-e2da-42f0-efff-80f0fa3b5cb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianProcessRegressor(alpha=0.1, copy_X_train=True,\n",
              "                         kernel=1**2 * RBF(length_scale=10),\n",
              "                         n_restarts_optimizer=10, normalize_y=True,\n",
              "                         optimizer='fmin_l_bfgs_b', random_state=None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Import gussian prosess from sklearn library and handle it's parameter then start to train our data using it\n",
        "import sklearn.gaussian_process as gp\n",
        "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
        "gp_model_output = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
        "gp_model_output.fit(X_train_output, y_train_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx_PdxAVUlYc",
        "outputId": "855934dd-10b1-4a18-bd4a-c5cb7be05180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30.71535522, 30.71535522, 30.71535522])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#example of how to predict value using gaussian_process model\n",
        "gp_model_output.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iizbavFwiwER"
      },
      "outputs": [],
      "source": [
        "#Get y_pred to measure the accurcy using it and y_test\n",
        "y_pred_output = gp_model_output.predict(X_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-d4gDHsizGy",
        "outputId": "9f57cd63-36e6-42cd-f3e5-5f8a5d86f9cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.538030574220205"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#here we are measure the mean squre error and root mean squre error\n",
        "MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "#show the value of root mean squre error\n",
        "RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKq_6RihjEnW",
        "outputId": "f17dc1af-5d30-4e13-9d58-582f692a8f01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.983832172737457"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#Getting the R2 score (accurcy of regression model) from model\n",
        "gp_model_output.score(X_test_output, y_test_output )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ajsop0jkrB6",
        "outputId": "98810593-2426-41c2-f756-372610ff0a25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98383217, 0.97590581, 0.69685348, 0.93174674, 0.76728646,\n",
              "       0.98917274, 0.91729935, 0.97032897, 0.924163  , 0.89926476])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#Implement the cross validation to get accurcy using different sets and get mean of all scores that will express the accurcy solving overfitting problem\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "# evaluate model\n",
        "scores = cross_val_score(gp_model_output, x_output, y_output, cv=cv, n_jobs=-1)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOBkEHAwyEOv",
        "outputId": "9066ee26-5aa7-4c79-b68b-7a8f0ad6119e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9055853479687453"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXL4m2xtRDfd"
      },
      "source": [
        "##Implement Regression Neural Network Model to predict Throughput\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy5tR2JxB9vu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmeMf7alCCEK"
      },
      "outputs": [],
      "source": [
        "nu_model = Sequential()\n",
        "nu_model.add(Dense(units=32, activation='relu', input_shape=[X_train_output.shape[1]]))\n",
        "nu_model.add(Dropout(0.1))\n",
        "nu_model.add(Dense(units=64, activation='relu'))\n",
        "nu_model.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvaRyNUzCFRT"
      },
      "outputs": [],
      "source": [
        "nu_model.compile(loss='mean_squared_error', optimizer=Adam())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGMkgU0jCIxz"
      },
      "outputs": [],
      "source": [
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                         patience = 200,\n",
        "                         verbose = 1,\n",
        "                         factor = 0.75,\n",
        "                         min_lr = 1e-4)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsdUKIsXCPl0",
        "outputId": "f13f94c9-bfaa-4adc-e9fc-740a531a91c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                128       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,305\n",
            "Trainable params: 2,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nu_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvqlD9KDCSgU",
        "outputId": "98680c62-9996-43a9-99c1-65c2d4233aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 50ms/step - loss: 47759876.0000 - val_loss: 3385419.2500 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23239842.0000 - val_loss: 14200784.0000 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14316295.0000 - val_loss: 49668.2500 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9318604.0000 - val_loss: 3793814.2500 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9233937.0000 - val_loss: 222237.5156 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7997453.0000 - val_loss: 976948.8125 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5897720.5000 - val_loss: 509289.1875 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7429761.0000 - val_loss: 46932.5703 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4856785.5000 - val_loss: 14296.8398 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2480170.5000 - val_loss: 152429.5312 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2236063.0000 - val_loss: 50121.4922 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3253157.2500 - val_loss: 48005.4766 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2684127.0000 - val_loss: 26572.0859 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1393163.2500 - val_loss: 68270.3828 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2739248.7500 - val_loss: 19391.1602 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1865591.3750 - val_loss: 38454.9336 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2114123.2500 - val_loss: 2545.5818 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2008101.0000 - val_loss: 8289.2920 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1283808.8750 - val_loss: 190932.2344 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1308255.2500 - val_loss: 33383.0469 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2005135.0000 - val_loss: 6073.4678 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1829012.7500 - val_loss: 16580.8301 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1393778.1250 - val_loss: 10723.2656 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1074762.7500 - val_loss: 5829.5308 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1560817.7500 - val_loss: 77068.3594 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 866866.2500 - val_loss: 19131.1074 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 780620.0000 - val_loss: 32597.8672 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1166543.1250 - val_loss: 29074.6582 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 705861.5000 - val_loss: 30435.2715 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 697630.6250 - val_loss: 2308.3606 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1022467.6250 - val_loss: 93364.3594 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 910896.6250 - val_loss: 61745.5195 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1197126.3750 - val_loss: 54680.6055 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 884294.3125 - val_loss: 50834.6914 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1377679.3750 - val_loss: 12792.0898 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1018490.1250 - val_loss: 8647.4248 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1052269.2500 - val_loss: 3874.3108 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 583199.6250 - val_loss: 35036.5430 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 664524.3750 - val_loss: 14473.2188 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 600450.5000 - val_loss: 2239.2463 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 730532.9375 - val_loss: 3202.4890 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 573837.7500 - val_loss: 248917.3125 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 520288.0000 - val_loss: 109063.9922 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 812610.5000 - val_loss: 21519.7109 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 983253.0625 - val_loss: 3703.4937 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 554638.7500 - val_loss: 117019.5156 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 580227.8125 - val_loss: 48404.2578 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 664203.2500 - val_loss: 8301.1592 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 516202.6562 - val_loss: 46272.5586 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 527616.6875 - val_loss: 16103.2568 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 528627.5000 - val_loss: 243076.6562 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 724226.3750 - val_loss: 126103.2578 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 700701.1875 - val_loss: 71066.5391 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 403008.4688 - val_loss: 4590.3926 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 449755.6875 - val_loss: 10265.2783 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 417474.7812 - val_loss: 4837.1431 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 625311.0000 - val_loss: 91136.9609 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 403388.9062 - val_loss: 186323.8125 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 721902.2500 - val_loss: 103335.1797 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 414347.3125 - val_loss: 12022.8389 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 370853.2500 - val_loss: 2250.9355 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 360110.8750 - val_loss: 36678.1055 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 368280.7812 - val_loss: 127972.9688 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 303513.1562 - val_loss: 10924.8105 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 351253.3125 - val_loss: 3450.3154 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 449228.3438 - val_loss: 31762.0293 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 384690.4688 - val_loss: 2254.4492 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 392179.6562 - val_loss: 29542.4004 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 269546.7812 - val_loss: 19350.8848 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 369443.3750 - val_loss: 2508.3762 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 216441.1406 - val_loss: 30965.1973 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 265464.5625 - val_loss: 12053.2012 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 222695.2969 - val_loss: 6204.8325 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 339550.1875 - val_loss: 11808.0029 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 346020.2812 - val_loss: 5000.1602 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 251170.3750 - val_loss: 13671.3564 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 436892.2188 - val_loss: 2231.5850 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 262769.2500 - val_loss: 33915.3125 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 267313.8125 - val_loss: 2534.0935 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 324249.0312 - val_loss: 10477.9521 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 273543.6250 - val_loss: 4026.3638 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 274969.1250 - val_loss: 17703.4238 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 237460.4688 - val_loss: 4673.6680 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 320916.4062 - val_loss: 15553.4980 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 262212.6250 - val_loss: 129891.1250 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 183903.8281 - val_loss: 75938.6250 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 463036.2812 - val_loss: 94910.8359 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 366231.3438 - val_loss: 60358.2422 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 367352.2500 - val_loss: 2921.9685 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 390069.9062 - val_loss: 29802.3438 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 279070.5625 - val_loss: 10300.7988 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 225439.0938 - val_loss: 2299.2488 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 158336.1094 - val_loss: 20989.9473 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 259776.1250 - val_loss: 2610.5017 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 211030.7969 - val_loss: 19553.9492 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 177401.8750 - val_loss: 4588.9556 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 193530.0781 - val_loss: 4670.4946 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 255913.1250 - val_loss: 2425.4182 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 110126.2969 - val_loss: 13556.7627 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 327561.9375 - val_loss: 2219.0754 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 162399.6094 - val_loss: 2505.9380 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 179114.7344 - val_loss: 9347.0527 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 184453.1875 - val_loss: 2635.3350 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 215162.2812 - val_loss: 2763.9570 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 213013.8750 - val_loss: 23012.4453 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 210003.2656 - val_loss: 4878.6851 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 239262.5312 - val_loss: 3112.4019 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 177212.4531 - val_loss: 2546.5149 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 173220.3906 - val_loss: 13889.9111 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 251157.6719 - val_loss: 70419.3438 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 280948.8750 - val_loss: 57934.9844 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 124968.4844 - val_loss: 27541.3262 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 152847.4375 - val_loss: 29636.5664 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 171971.0781 - val_loss: 2334.9116 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 219212.2656 - val_loss: 3572.1367 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 117860.9062 - val_loss: 5498.2012 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 99037.8125 - val_loss: 2411.6152 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 248195.4375 - val_loss: 10315.6758 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 123660.1328 - val_loss: 6745.0771 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 146010.9219 - val_loss: 6006.1816 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 233697.9531 - val_loss: 10231.7832 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 156723.6406 - val_loss: 13938.6680 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 177373.4844 - val_loss: 11690.8057 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 200971.3750 - val_loss: 2311.9229 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 194266.3906 - val_loss: 10288.6025 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 171728.5469 - val_loss: 2887.0806 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 224460.4844 - val_loss: 5654.9072 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 173050.4688 - val_loss: 2365.3494 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 131894.7969 - val_loss: 26145.0215 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 161006.4531 - val_loss: 2241.3945 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 118926.7500 - val_loss: 18891.3223 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 156347.2188 - val_loss: 10907.2139 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 191531.3281 - val_loss: 6399.6025 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 321002.8125 - val_loss: 3755.8821 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122681.4609 - val_loss: 3883.1553 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 132103.8750 - val_loss: 3379.6731 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 178495.5625 - val_loss: 5339.0566 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 134780.7969 - val_loss: 10235.3027 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 157161.3125 - val_loss: 5482.6289 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 140760.5000 - val_loss: 2246.5361 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 104281.5078 - val_loss: 2955.4929 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 142037.5938 - val_loss: 16177.1094 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 249189.1719 - val_loss: 21590.3340 - lr: 0.0010\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 148621.3281 - val_loss: 8013.9990 - lr: 0.0010\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114242.4375 - val_loss: 4265.0103 - lr: 0.0010\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 104827.8516 - val_loss: 5563.5239 - lr: 0.0010\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 102744.4688 - val_loss: 18892.3906 - lr: 0.0010\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 146103.1406 - val_loss: 2275.7458 - lr: 0.0010\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 206846.5625 - val_loss: 3529.8127 - lr: 0.0010\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 149534.6250 - val_loss: 31430.7148 - lr: 0.0010\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 167118.3750 - val_loss: 2903.7219 - lr: 0.0010\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 189890.0000 - val_loss: 5831.8677 - lr: 0.0010\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 104849.5859 - val_loss: 5165.4351 - lr: 0.0010\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 132778.5156 - val_loss: 44563.4219 - lr: 0.0010\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 151338.7656 - val_loss: 11425.4053 - lr: 0.0010\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 190463.2969 - val_loss: 35979.0781 - lr: 0.0010\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 98356.6016 - val_loss: 26432.9375 - lr: 0.0010\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 194832.1719 - val_loss: 13392.7676 - lr: 0.0010\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 197160.2969 - val_loss: 17087.9395 - lr: 0.0010\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 152185.1719 - val_loss: 2442.5457 - lr: 0.0010\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 185679.7500 - val_loss: 2249.7336 - lr: 0.0010\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 232493.0938 - val_loss: 25536.2754 - lr: 0.0010\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 139616.2031 - val_loss: 13641.8691 - lr: 0.0010\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 151046.2500 - val_loss: 20831.2852 - lr: 0.0010\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 116314.6484 - val_loss: 20812.4395 - lr: 0.0010\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 132474.7812 - val_loss: 6578.3848 - lr: 0.0010\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 125145.0000 - val_loss: 3192.3938 - lr: 0.0010\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 127377.1797 - val_loss: 4597.8062 - lr: 0.0010\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 135614.5000 - val_loss: 68851.6094 - lr: 0.0010\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 138819.5938 - val_loss: 29654.7305 - lr: 0.0010\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 109538.7812 - val_loss: 69558.7266 - lr: 0.0010\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 165201.9375 - val_loss: 53133.8086 - lr: 0.0010\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 126619.4844 - val_loss: 4839.3784 - lr: 0.0010\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 139626.2969 - val_loss: 12562.9209 - lr: 0.0010\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 92884.8516 - val_loss: 2544.3320 - lr: 0.0010\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 95905.3359 - val_loss: 20130.7246 - lr: 0.0010\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 231523.9062 - val_loss: 11149.5547 - lr: 0.0010\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 152537.4219 - val_loss: 47121.7773 - lr: 0.0010\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 92377.9766 - val_loss: 4503.4976 - lr: 0.0010\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 226354.6406 - val_loss: 5067.3101 - lr: 0.0010\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 80387.6094 - val_loss: 3497.0769 - lr: 0.0010\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 69827.0469 - val_loss: 2624.8660 - lr: 0.0010\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 73879.7656 - val_loss: 2705.2065 - lr: 0.0010\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 140991.1562 - val_loss: 2390.0742 - lr: 0.0010\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 94792.5625 - val_loss: 4048.6785 - lr: 0.0010\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 102476.4141 - val_loss: 2626.9983 - lr: 0.0010\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 90832.4688 - val_loss: 16341.3818 - lr: 0.0010\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 164672.0156 - val_loss: 4759.0073 - lr: 0.0010\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 91170.7969 - val_loss: 4091.5845 - lr: 0.0010\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 73255.3672 - val_loss: 2687.3350 - lr: 0.0010\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 87963.6016 - val_loss: 4182.5552 - lr: 0.0010\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 68707.9688 - val_loss: 2266.3044 - lr: 0.0010\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 97149.5625 - val_loss: 3185.1089 - lr: 0.0010\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57180.3359 - val_loss: 3040.1555 - lr: 0.0010\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 77934.5781 - val_loss: 3485.2061 - lr: 0.0010\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 114489.1719 - val_loss: 2424.4849 - lr: 0.0010\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 69604.7578 - val_loss: 3538.3230 - lr: 0.0010\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 155390.5312 - val_loss: 16265.7715 - lr: 0.0010\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 124677.5859 - val_loss: 7029.1011 - lr: 0.0010\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 129743.2812 - val_loss: 3730.9861 - lr: 0.0010\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 75025.9219 - val_loss: 2699.0310 - lr: 0.0010\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 107780.3516 - val_loss: 7001.4302 - lr: 0.0010\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 108684.9609 - val_loss: 2392.0090 - lr: 0.0010\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 113242.7969 - val_loss: 5039.3862 - lr: 0.0010\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 91859.5625 - val_loss: 34743.3164 - lr: 0.0010\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 98191.8984 - val_loss: 40601.4258 - lr: 0.0010\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 87998.4297 - val_loss: 85565.9453 - lr: 0.0010\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 109448.0859 - val_loss: 30424.3574 - lr: 0.0010\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 206274.3906 - val_loss: 68802.4297 - lr: 0.0010\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 183586.6250 - val_loss: 45534.3047 - lr: 0.0010\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 108360.1719 - val_loss: 2975.6743 - lr: 0.0010\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 114220.5469 - val_loss: 25998.3848 - lr: 0.0010\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 124226.0469 - val_loss: 2290.1162 - lr: 0.0010\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 62571.1172 - val_loss: 3863.8062 - lr: 0.0010\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 161795.1250 - val_loss: 2938.4158 - lr: 0.0010\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 62694.3008 - val_loss: 3564.4893 - lr: 0.0010\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 97341.7812 - val_loss: 18109.1426 - lr: 0.0010\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 69980.3984 - val_loss: 2809.7424 - lr: 0.0010\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 84360.3672 - val_loss: 2287.9294 - lr: 0.0010\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 131307.2344 - val_loss: 3006.0168 - lr: 0.0010\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 81595.4531 - val_loss: 9169.5527 - lr: 0.0010\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 73264.6406 - val_loss: 2320.3508 - lr: 0.0010\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 87806.3203 - val_loss: 25780.7539 - lr: 0.0010\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 147443.7812 - val_loss: 19816.5957 - lr: 0.0010\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 91860.4453 - val_loss: 15583.7861 - lr: 0.0010\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 56110.1758 - val_loss: 2528.9583 - lr: 0.0010\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46509.8711 - val_loss: 5060.3696 - lr: 0.0010\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 86459.6016 - val_loss: 2772.9841 - lr: 0.0010\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 81802.0625 - val_loss: 3705.5178 - lr: 0.0010\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 94152.0078 - val_loss: 2373.8286 - lr: 0.0010\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 83704.5703 - val_loss: 10351.7314 - lr: 0.0010\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 104724.1641 - val_loss: 58014.8516 - lr: 0.0010\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 157847.3906 - val_loss: 151020.8125 - lr: 0.0010\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 164431.3750 - val_loss: 159647.0781 - lr: 0.0010\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 177477.2656 - val_loss: 175516.3594 - lr: 0.0010\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 163446.3750 - val_loss: 21518.6191 - lr: 0.0010\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 134787.4531 - val_loss: 20404.3945 - lr: 0.0010\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 79792.4141 - val_loss: 2661.3110 - lr: 0.0010\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 217664.7031 - val_loss: 4713.4175 - lr: 0.0010\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 150576.1250 - val_loss: 41045.3516 - lr: 0.0010\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 76575.7109 - val_loss: 2276.3267 - lr: 0.0010\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 91563.2422 - val_loss: 8780.6777 - lr: 0.0010\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 96531.0703 - val_loss: 39456.6055 - lr: 0.0010\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 82917.6328 - val_loss: 15117.2715 - lr: 0.0010\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 84988.6016 - val_loss: 4322.2212 - lr: 0.0010\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 70601.4688 - val_loss: 7636.6011 - lr: 0.0010\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 68310.6719 - val_loss: 7418.1323 - lr: 0.0010\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 67158.5156 - val_loss: 2679.0059 - lr: 0.0010\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 76275.5625 - val_loss: 17748.3613 - lr: 0.0010\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 75096.1875 - val_loss: 43729.1953 - lr: 0.0010\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 59868.4922 - val_loss: 6327.8828 - lr: 0.0010\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 135692.6719 - val_loss: 7415.9771 - lr: 0.0010\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 61417.7734 - val_loss: 2187.2800 - lr: 0.0010\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 58687.5938 - val_loss: 4071.2461 - lr: 0.0010\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 86734.1328 - val_loss: 5298.7402 - lr: 0.0010\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 62394.0898 - val_loss: 2284.2041 - lr: 0.0010\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 50463.6445 - val_loss: 24161.3281 - lr: 0.0010\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 123690.1016 - val_loss: 2423.7209 - lr: 0.0010\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 71519.1016 - val_loss: 6144.4204 - lr: 0.0010\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 80362.4453 - val_loss: 4034.3330 - lr: 0.0010\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 79024.6562 - val_loss: 11879.7627 - lr: 0.0010\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 76933.7969 - val_loss: 37017.4961 - lr: 0.0010\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 61467.8203 - val_loss: 4590.4800 - lr: 0.0010\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 59097.4453 - val_loss: 5153.6597 - lr: 0.0010\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 88367.6875 - val_loss: 10142.7539 - lr: 0.0010\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 65789.3906 - val_loss: 11381.8623 - lr: 0.0010\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 81682.3750 - val_loss: 13299.2383 - lr: 0.0010\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 53626.2500 - val_loss: 2446.9426 - lr: 0.0010\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 75755.4844 - val_loss: 2650.7969 - lr: 0.0010\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 44842.8047 - val_loss: 10178.1709 - lr: 0.0010\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 62644.6016 - val_loss: 5315.3760 - lr: 0.0010\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 76297.8281 - val_loss: 2513.2063 - lr: 0.0010\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 64012.6914 - val_loss: 2456.1299 - lr: 0.0010\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 55169.5938 - val_loss: 2943.8652 - lr: 0.0010\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48093.5664 - val_loss: 2301.8164 - lr: 0.0010\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 101526.1562 - val_loss: 11295.5996 - lr: 0.0010\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 43558.9141 - val_loss: 2317.4385 - lr: 0.0010\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 50405.0352 - val_loss: 9157.5371 - lr: 0.0010\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 61459.6328 - val_loss: 7268.1729 - lr: 0.0010\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 67044.5312 - val_loss: 2220.9497 - lr: 0.0010\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 144826.7656 - val_loss: 5950.2466 - lr: 0.0010\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44170.3164 - val_loss: 2465.3997 - lr: 0.0010\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 41279.5625 - val_loss: 10642.4883 - lr: 0.0010\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 59899.0625 - val_loss: 17121.4883 - lr: 0.0010\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 60231.2891 - val_loss: 17923.1758 - lr: 0.0010\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 78736.5469 - val_loss: 3129.0515 - lr: 0.0010\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 50708.1562 - val_loss: 2297.1555 - lr: 0.0010\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 52887.2969 - val_loss: 7710.9463 - lr: 0.0010\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 74722.3125 - val_loss: 35386.3086 - lr: 0.0010\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 65579.0312 - val_loss: 9840.9336 - lr: 0.0010\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 93153.8125 - val_loss: 2199.5542 - lr: 0.0010\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 39541.8438 - val_loss: 19569.1797 - lr: 0.0010\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 111032.9688 - val_loss: 11895.5859 - lr: 0.0010\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 47982.1250 - val_loss: 5119.1064 - lr: 0.0010\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 81002.3438 - val_loss: 3398.3992 - lr: 0.0010\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 60162.9688 - val_loss: 6477.4629 - lr: 0.0010\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42393.5430 - val_loss: 7627.9868 - lr: 0.0010\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 92347.8125 - val_loss: 10011.2695 - lr: 0.0010\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 77515.1484 - val_loss: 2213.8638 - lr: 0.0010\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 81324.2812 - val_loss: 11569.1055 - lr: 0.0010\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 60008.4961 - val_loss: 22670.4492 - lr: 0.0010\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 81471.9453 - val_loss: 7939.2285 - lr: 0.0010\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 39047.3281 - val_loss: 5425.2319 - lr: 0.0010\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 47695.9922 - val_loss: 2307.7039 - lr: 0.0010\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 123234.3125 - val_loss: 17244.0703 - lr: 0.0010\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 59822.7383 - val_loss: 20178.0195 - lr: 0.0010\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 93069.1406 - val_loss: 22247.2148 - lr: 0.0010\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 83656.9375 - val_loss: 3515.3892 - lr: 0.0010\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 72026.1875 - val_loss: 8427.5820 - lr: 0.0010\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34149.8750 - val_loss: 2690.9758 - lr: 0.0010\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 61715.4102 - val_loss: 2767.4971 - lr: 0.0010\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 45395.4258 - val_loss: 43792.7305 - lr: 0.0010\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 78008.5625 - val_loss: 5489.7886 - lr: 0.0010\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 121406.2578 - val_loss: 8799.1689 - lr: 0.0010\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 110425.8125 - val_loss: 24947.0156 - lr: 0.0010\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 57960.6836 - val_loss: 2634.0632 - lr: 0.0010\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 68997.6484 - val_loss: 7160.9307 - lr: 0.0010\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 78268.5312 - val_loss: 25866.7793 - lr: 0.0010\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 75541.1328 - val_loss: 2308.9653 - lr: 0.0010\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 101969.4531 - val_loss: 13692.8486 - lr: 0.0010\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 95580.2500 - val_loss: 6262.7109 - lr: 0.0010\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 42902.9453 - val_loss: 2724.8450 - lr: 0.0010\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 51082.3828 - val_loss: 4396.1230 - lr: 0.0010\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39923.6641 - val_loss: 2680.5828 - lr: 0.0010\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 79928.1250 - val_loss: 2389.8044 - lr: 0.0010\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 94403.0703 - val_loss: 10122.6533 - lr: 0.0010\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 50065.2891 - val_loss: 19298.9609 - lr: 0.0010\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 73555.9531 - val_loss: 3136.0371 - lr: 0.0010\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 56009.6172 - val_loss: 22653.1602 - lr: 0.0010\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 78139.5078 - val_loss: 19096.1660 - lr: 0.0010\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 95761.9297 - val_loss: 16705.8711 - lr: 0.0010\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 79952.8672 - val_loss: 21477.5977 - lr: 0.0010\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 70806.9688 - val_loss: 3257.3257 - lr: 0.0010\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47234.4688 - val_loss: 4303.5708 - lr: 0.0010\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 52517.4727 - val_loss: 17651.9199 - lr: 0.0010\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 54501.3945 - val_loss: 2946.5063 - lr: 0.0010\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 63621.5156 - val_loss: 7687.3965 - lr: 0.0010\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46559.4414 - val_loss: 30035.2422 - lr: 0.0010\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 51505.2031 - val_loss: 12949.2588 - lr: 0.0010\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 62216.2422 - val_loss: 2445.9153 - lr: 0.0010\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 61189.1289 - val_loss: 7641.8105 - lr: 0.0010\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 54816.3789 - val_loss: 55466.0312 - lr: 0.0010\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 73790.0078 - val_loss: 23384.1543 - lr: 0.0010\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 63549.6328 - val_loss: 2386.7461 - lr: 0.0010\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31811.2969 - val_loss: 2441.0823 - lr: 0.0010\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47080.4023 - val_loss: 12160.9043 - lr: 0.0010\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 50931.7148 - val_loss: 47028.5117 - lr: 0.0010\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 57574.8438 - val_loss: 9983.2656 - lr: 0.0010\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 77358.6875 - val_loss: 2906.5427 - lr: 0.0010\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 100459.4453 - val_loss: 5285.5166 - lr: 0.0010\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 63774.8438 - val_loss: 2209.9309 - lr: 0.0010\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34911.4609 - val_loss: 2794.6848 - lr: 0.0010\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 45931.1133 - val_loss: 2236.5823 - lr: 0.0010\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 72783.5156 - val_loss: 11723.7461 - lr: 0.0010\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 69721.6797 - val_loss: 5110.4614 - lr: 0.0010\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 48453.0977 - val_loss: 2743.8218 - lr: 0.0010\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 29279.9082 - val_loss: 3857.9155 - lr: 0.0010\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 59673.5352 - val_loss: 18750.2910 - lr: 0.0010\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 49724.4219 - val_loss: 3519.2998 - lr: 0.0010\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38587.8477 - val_loss: 8916.1973 - lr: 0.0010\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 61151.5859 - val_loss: 5238.7290 - lr: 0.0010\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 63272.5820 - val_loss: 2414.2058 - lr: 0.0010\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 47824.0195 - val_loss: 8321.3340 - lr: 0.0010\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35506.3789 - val_loss: 6125.6880 - lr: 0.0010\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44327.1289 - val_loss: 7913.4839 - lr: 0.0010\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 67979.8203 - val_loss: 12585.4424 - lr: 0.0010\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 34723.5703 - val_loss: 4183.6729 - lr: 0.0010\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 43771.4805 - val_loss: 8283.5195 - lr: 0.0010\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 48287.6758 - val_loss: 34303.3125 - lr: 0.0010\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 62125.4062 - val_loss: 2971.5808 - lr: 0.0010\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 63820.2422 - val_loss: 13317.8682 - lr: 0.0010\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 55656.3906 - val_loss: 68333.3906 - lr: 0.0010\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 57915.6289 - val_loss: 2468.1060 - lr: 0.0010\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 128659.2031 - val_loss: 24749.5723 - lr: 0.0010\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 69991.8516 - val_loss: 64788.9219 - lr: 0.0010\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 99897.9141 - val_loss: 28873.3301 - lr: 0.0010\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 97526.8594 - val_loss: 101025.4766 - lr: 0.0010\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 99898.4844 - val_loss: 53590.4219 - lr: 0.0010\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 72579.4375 - val_loss: 2604.6614 - lr: 0.0010\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 74994.4062 - val_loss: 23861.2520 - lr: 0.0010\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46057.1094 - val_loss: 21417.0977 - lr: 0.0010\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 60247.0195 - val_loss: 19853.3242 - lr: 0.0010\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 81659.4922 - val_loss: 45501.5703 - lr: 0.0010\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 113053.1094 - val_loss: 2249.8098 - lr: 0.0010\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 77820.8359 - val_loss: 20363.5371 - lr: 0.0010\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 46229.1328 - val_loss: 32858.3984 - lr: 0.0010\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 48171.6094 - val_loss: 11642.4395 - lr: 0.0010\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 55747.5469 - val_loss: 12901.9619 - lr: 0.0010\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 49866.6562 - val_loss: 3762.5215 - lr: 0.0010\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 51517.8438 - val_loss: 37501.0078 - lr: 0.0010\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 67728.5781 - val_loss: 2542.4758 - lr: 0.0010\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 64533.5312 - val_loss: 4815.1924 - lr: 0.0010\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 56532.0664 - val_loss: 10742.6787 - lr: 0.0010\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 52059.7070 - val_loss: 11038.5742 - lr: 0.0010\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39862.3438 - val_loss: 2574.6975 - lr: 0.0010\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42670.7148 - val_loss: 8290.1387 - lr: 0.0010\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 58312.7031 - val_loss: 7298.1641 - lr: 0.0010\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 40590.2656 - val_loss: 3585.8704 - lr: 0.0010\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 54044.2070 - val_loss: 2863.2312 - lr: 0.0010\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 45623.7930 - val_loss: 2391.8574 - lr: 0.0010\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29592.3457 - val_loss: 2224.0776 - lr: 0.0010\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 72328.2188 - val_loss: 2421.0530 - lr: 0.0010\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26032.8730 - val_loss: 4659.9756 - lr: 0.0010\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 59195.1562 - val_loss: 2504.5212 - lr: 0.0010\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36034.6836 - val_loss: 21245.3223 - lr: 0.0010\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40484.9141 - val_loss: 2215.4683 - lr: 0.0010\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26207.8438 - val_loss: 3755.7629 - lr: 0.0010\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 52049.7734 - val_loss: 2970.7715 - lr: 0.0010\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35123.2383 - val_loss: 10564.3096 - lr: 0.0010\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41539.7148 - val_loss: 8101.4429 - lr: 0.0010\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31667.6289 - val_loss: 3706.1233 - lr: 0.0010\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34319.8281 - val_loss: 11039.1748 - lr: 0.0010\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 63814.9180 - val_loss: 21727.3965 - lr: 0.0010\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 57648.6562 - val_loss: 3653.3621 - lr: 0.0010\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 66054.7734 - val_loss: 5952.3896 - lr: 0.0010\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 62836.9648 - val_loss: 29102.8535 - lr: 0.0010\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 40891.6211 - val_loss: 4235.9458 - lr: 0.0010\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 48542.2344 - val_loss: 6571.7563 - lr: 0.0010\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 77695.9844 - val_loss: 31257.4648 - lr: 0.0010\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 121170.3047 - val_loss: 21425.6543 - lr: 0.0010\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 81213.3438 - val_loss: 2812.3645 - lr: 0.0010\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 36581.4844 - val_loss: 6118.8687 - lr: 0.0010\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 37044.0742 - val_loss: 24049.3887 - lr: 0.0010\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 71483.4219 - val_loss: 3640.6746 - lr: 0.0010\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 56168.7227 - val_loss: 2393.7361 - lr: 0.0010\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 42023.0312 - val_loss: 15879.2324 - lr: 0.0010\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 73972.1641 - val_loss: 3703.2839 - lr: 0.0010\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39657.7383 - val_loss: 6374.5298 - lr: 0.0010\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24094.3359 - val_loss: 5779.6074 - lr: 0.0010\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32757.0508 - val_loss: 3971.7500 - lr: 0.0010\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 47691.2266 - val_loss: 12101.1455 - lr: 0.0010\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40223.4023 - val_loss: 11583.7285 - lr: 0.0010\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 37902.9219 - val_loss: 3226.0168 - lr: 0.0010\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24052.1562 - val_loss: 6049.2891 - lr: 0.0010\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 55853.2891 - val_loss: 2490.8293 - lr: 0.0010\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29718.0566 - val_loss: 2612.9363 - lr: 0.0010\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30578.6699 - val_loss: 12930.4160 - lr: 0.0010\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 77160.8438 - val_loss: 9652.7432 - lr: 0.0010\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44941.6250 - val_loss: 3679.0095 - lr: 0.0010\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 38737.8086 - val_loss: 12363.3711 - lr: 0.0010\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31014.2949 - val_loss: 2739.4116 - lr: 0.0010\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 102471.7578 - val_loss: 7018.6499 - lr: 0.0010\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36507.0469 - val_loss: 2378.6875 - lr: 0.0010\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40526.9219 - val_loss: 14947.4209 - lr: 0.0010\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 62690.6250 - val_loss: 3760.3005 - lr: 0.0010\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26659.3535 - val_loss: 8658.4170 - lr: 0.0010\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43646.7773 - val_loss: 4128.0649 - lr: 0.0010\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 40803.3164 - val_loss: 2161.9902 - lr: 0.0010\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24160.7148 - val_loss: 5190.1753 - lr: 0.0010\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43798.3750 - val_loss: 2159.0808 - lr: 0.0010\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34770.3164 - val_loss: 2637.4880 - lr: 0.0010\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23986.1445 - val_loss: 11116.8984 - lr: 0.0010\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31307.0840 - val_loss: 12035.8965 - lr: 0.0010\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33127.7266 - val_loss: 2238.2981 - lr: 0.0010\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36070.7109 - val_loss: 2642.1487 - lr: 0.0010\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 60417.3750 - val_loss: 29335.7637 - lr: 0.0010\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43760.2266 - val_loss: 21030.4199 - lr: 0.0010\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42614.4297 - val_loss: 2323.4050 - lr: 0.0010\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 55007.2500 - val_loss: 24663.5820 - lr: 0.0010\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 37405.2734 - val_loss: 3379.2988 - lr: 0.0010\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40691.4648 - val_loss: 5157.6123 - lr: 0.0010\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 48091.0742 - val_loss: 2530.5007 - lr: 0.0010\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32424.8594 - val_loss: 23878.2363 - lr: 0.0010\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 55084.1484 - val_loss: 3159.9282 - lr: 0.0010\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 28440.7031 - val_loss: 2800.8140 - lr: 0.0010\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28682.2676 - val_loss: 26603.0938 - lr: 0.0010\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 48422.2773 - val_loss: 3246.6406 - lr: 0.0010\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29490.9844 - val_loss: 2438.2307 - lr: 0.0010\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 39729.3047 - val_loss: 26059.8125 - lr: 0.0010\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 50061.8242 - val_loss: 4860.9575 - lr: 0.0010\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 55522.7539 - val_loss: 13886.7578 - lr: 0.0010\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 37019.5781 - val_loss: 12441.9014 - lr: 0.0010\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 63643.7812 - val_loss: 4616.8169 - lr: 0.0010\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 56810.1094 - val_loss: 4561.3130 - lr: 0.0010\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38500.1406 - val_loss: 12516.5674 - lr: 0.0010\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31435.0410 - val_loss: 3031.9316 - lr: 0.0010\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23020.3848 - val_loss: 4299.0508 - lr: 0.0010\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 40142.8047 - val_loss: 23090.7402 - lr: 0.0010\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 60501.4609 - val_loss: 7376.8086 - lr: 0.0010\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 65394.3164 - val_loss: 13234.3174 - lr: 0.0010\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 69854.9844 - val_loss: 3508.4856 - lr: 0.0010\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 38595.9688 - val_loss: 6997.1177 - lr: 0.0010\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 56403.9766 - val_loss: 16561.2734 - lr: 0.0010\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 42678.5859 - val_loss: 2163.4658 - lr: 0.0010\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 55616.5664 - val_loss: 18527.1895 - lr: 0.0010\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29288.1543 - val_loss: 4610.0078 - lr: 0.0010\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47104.4219 - val_loss: 26177.5117 - lr: 0.0010\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 47500.9648 - val_loss: 2333.5339 - lr: 0.0010\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 38547.6602 - val_loss: 7218.2930 - lr: 0.0010\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40073.4922 - val_loss: 2234.9963 - lr: 0.0010\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 48172.4688 - val_loss: 11549.7549 - lr: 0.0010\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 52522.3789 - val_loss: 2592.9924 - lr: 0.0010\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 119512.5547 - val_loss: 25526.6113 - lr: 0.0010\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48246.2891 - val_loss: 2157.3533 - lr: 0.0010\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 41356.2773 - val_loss: 14256.0654 - lr: 0.0010\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 60298.7227 - val_loss: 3413.4382 - lr: 0.0010\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42336.6641 - val_loss: 20514.2734 - lr: 0.0010\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26860.4590 - val_loss: 8008.6377 - lr: 0.0010\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 60261.5781 - val_loss: 28124.9902 - lr: 0.0010\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42962.8711 - val_loss: 18795.5527 - lr: 0.0010\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 73049.1562 - val_loss: 24510.1777 - lr: 0.0010\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 107411.7031 - val_loss: 2577.2349 - lr: 0.0010\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 134138.2188 - val_loss: 166690.7500 - lr: 0.0010\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 108768.1406 - val_loss: 16633.2793 - lr: 0.0010\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 90435.8672 - val_loss: 60439.8125 - lr: 0.0010\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 104681.1172 - val_loss: 5345.8369 - lr: 0.0010\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 70950.3281 - val_loss: 146047.9688 - lr: 0.0010\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 125690.1172 - val_loss: 4973.8682 - lr: 0.0010\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 64286.2930 - val_loss: 25364.9277 - lr: 0.0010\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 57149.8086 - val_loss: 3441.8987 - lr: 0.0010\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 53138.8945 - val_loss: 2301.6248 - lr: 0.0010\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31942.6094 - val_loss: 8572.7158 - lr: 0.0010\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19373.1094 - val_loss: 9709.6133 - lr: 0.0010\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47553.8477 - val_loss: 4715.5288 - lr: 0.0010\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27456.1094 - val_loss: 3325.9629 - lr: 0.0010\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36231.8906 - val_loss: 5492.4473 - lr: 0.0010\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35253.3047 - val_loss: 8996.0752 - lr: 0.0010\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 50856.3828 - val_loss: 2161.3438 - lr: 0.0010\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 57561.7148 - val_loss: 4589.6094 - lr: 0.0010\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34913.3867 - val_loss: 5742.5601 - lr: 0.0010\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 61090.4570 - val_loss: 15800.5557 - lr: 0.0010\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 39471.0625 - val_loss: 2222.2148 - lr: 0.0010\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 38228.5469 - val_loss: 2242.7830 - lr: 0.0010\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33744.3398 - val_loss: 6497.8799 - lr: 0.0010\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47728.9180 - val_loss: 25139.5176 - lr: 0.0010\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34970.0000 - val_loss: 2297.2920 - lr: 0.0010\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46534.4922 - val_loss: 3888.6606 - lr: 0.0010\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29053.9805 - val_loss: 21955.7949 - lr: 0.0010\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33851.9453 - val_loss: 3181.4160 - lr: 0.0010\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 59809.2305 - val_loss: 9030.0195 - lr: 0.0010\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33009.9648 - val_loss: 2682.5090 - lr: 0.0010\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32212.5703 - val_loss: 3951.7651 - lr: 0.0010\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30829.9023 - val_loss: 4786.5864 - lr: 0.0010\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 69792.8672 - val_loss: 2205.4229 - lr: 0.0010\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24679.0957 - val_loss: 2577.0247 - lr: 0.0010\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29537.1016 - val_loss: 4684.3740 - lr: 0.0010\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35687.2930 - val_loss: 4046.3528 - lr: 0.0010\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22857.3789 - val_loss: 2933.3694 - lr: 0.0010\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 28334.2324 - val_loss: 3032.5879 - lr: 0.0010\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44252.2344 - val_loss: 51903.1641 - lr: 0.0010\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 49043.0156 - val_loss: 3705.4558 - lr: 0.0010\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 43016.8438 - val_loss: 18435.9102 - lr: 0.0010\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 44171.2539 - val_loss: 3725.2952 - lr: 0.0010\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26135.0469 - val_loss: 13317.7207 - lr: 0.0010\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 57893.4336 - val_loss: 6376.5737 - lr: 0.0010\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 37827.7031 - val_loss: 3857.3474 - lr: 0.0010\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39589.1406 - val_loss: 34918.2695 - lr: 0.0010\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 66590.0078 - val_loss: 2168.8083 - lr: 0.0010\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37772.8984 - val_loss: 39181.5664 - lr: 0.0010\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 47635.1562 - val_loss: 13796.5557 - lr: 0.0010\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 56798.6367 - val_loss: 7498.3242 - lr: 0.0010\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 40492.8086 - val_loss: 10495.6846 - lr: 0.0010\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35922.5391 - val_loss: 3077.5845 - lr: 0.0010\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35610.5898 - val_loss: 4367.2632 - lr: 0.0010\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36636.0898 - val_loss: 3002.0371 - lr: 0.0010\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 43127.7422 - val_loss: 2348.3889 - lr: 0.0010\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 50807.2539 - val_loss: 3159.8770 - lr: 0.0010\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20976.9121 - val_loss: 16295.2109 - lr: 0.0010\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 42420.7578 - val_loss: 24163.8613 - lr: 0.0010\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 44690.0469 - val_loss: 2646.2029 - lr: 0.0010\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 41766.7031 - val_loss: 2235.8372 - lr: 0.0010\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30171.2344 - val_loss: 6733.5518 - lr: 0.0010\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 21870.3379 - val_loss: 3895.8438 - lr: 0.0010\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30960.3164 - val_loss: 20344.3789 - lr: 0.0010\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 46930.8438 - val_loss: 2740.2168 - lr: 0.0010\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 52258.6758 - val_loss: 66052.7266 - lr: 0.0010\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 81322.2266 - val_loss: 11468.4443 - lr: 0.0010\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 45239.5703 - val_loss: 26498.6777 - lr: 0.0010\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 51575.2305 - val_loss: 5973.9243 - lr: 0.0010\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 44469.0312 - val_loss: 9086.9043 - lr: 0.0010\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38353.7109 - val_loss: 14499.0508 - lr: 0.0010\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32711.9043 - val_loss: 2256.1521 - lr: 0.0010\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 75156.6875 - val_loss: 7304.7124 - lr: 0.0010\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26433.3457 - val_loss: 9931.2383 - lr: 0.0010\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37248.4805 - val_loss: 22797.7344 - lr: 0.0010\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 32263.6797 - val_loss: 8746.7803 - lr: 0.0010\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 34136.9531 - val_loss: 6089.8257 - lr: 0.0010\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 34841.2773 - val_loss: 14143.2490 - lr: 0.0010\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 41307.4609 - val_loss: 19298.1641 - lr: 0.0010\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 51307.2578 - val_loss: 48120.4453 - lr: 0.0010\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48576.6797 - val_loss: 9959.9150 - lr: 0.0010\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 39842.5078 - val_loss: 2784.7134 - lr: 0.0010\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23850.9492 - val_loss: 4685.3618 - lr: 0.0010\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 48121.1758 - val_loss: 2995.6584 - lr: 0.0010\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30060.8301 - val_loss: 13814.2705 - lr: 0.0010\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 37125.6914 - val_loss: 8672.9883 - lr: 0.0010\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33735.7773 - val_loss: 2264.1831 - lr: 0.0010\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31321.1133 - val_loss: 2323.7297 - lr: 0.0010\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20440.5801 - val_loss: 5994.0547 - lr: 0.0010\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 25815.2051 - val_loss: 10177.0254 - lr: 0.0010\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36861.7930 - val_loss: 2572.0991 - lr: 0.0010\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27553.3848 - val_loss: 27147.0508 - lr: 0.0010\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31500.5957 - val_loss: 2388.6760 - lr: 0.0010\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 26196.6836 - val_loss: 17518.9688 - lr: 0.0010\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38026.2539 - val_loss: 4271.0889 - lr: 0.0010\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29434.8594 - val_loss: 2803.9399 - lr: 0.0010\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 62286.4648 - val_loss: 7489.4688 - lr: 0.0010\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30221.5020 - val_loss: 2181.0166 - lr: 0.0010\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38652.0938 - val_loss: 6734.1108 - lr: 0.0010\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 41836.2344 - val_loss: 2234.6836 - lr: 0.0010\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36481.3320 - val_loss: 8766.7852 - lr: 0.0010\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35847.0703 - val_loss: 5603.4800 - lr: 0.0010\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 18411.2070 - val_loss: 5319.3423 - lr: 0.0010\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 24997.4902 - val_loss: 2494.3318 - lr: 0.0010\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 25652.1055 - val_loss: 10953.3623 - lr: 0.0010\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 58193.1250 - val_loss: 31259.1973 - lr: 0.0010\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 42810.5547 - val_loss: 2596.4722 - lr: 0.0010\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 49607.1914 - val_loss: 2142.3831 - lr: 0.0010\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34198.6836 - val_loss: 22192.1191 - lr: 0.0010\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33380.9453 - val_loss: 2386.9087 - lr: 0.0010\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28413.2207 - val_loss: 10620.3545 - lr: 0.0010\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 42652.0508 - val_loss: 12554.1582 - lr: 0.0010\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22309.8730 - val_loss: 7554.1382 - lr: 0.0010\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 38594.7891 - val_loss: 5390.5581 - lr: 0.0010\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 37990.5703 - val_loss: 9390.6709 - lr: 0.0010\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40695.1289 - val_loss: 12521.9697 - lr: 0.0010\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 43017.4453 - val_loss: 4119.1963 - lr: 0.0010\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 19416.4902 - val_loss: 4877.6812 - lr: 0.0010\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22185.3047 - val_loss: 3253.7800 - lr: 0.0010\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25419.3281 - val_loss: 16041.0000 - lr: 0.0010\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36716.8906 - val_loss: 2167.1487 - lr: 0.0010\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 43523.5039 - val_loss: 5344.5776 - lr: 0.0010\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26448.0742 - val_loss: 2339.7461 - lr: 0.0010\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 34555.8320 - val_loss: 2523.3936 - lr: 0.0010\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 60395.7539 - val_loss: 3262.7878 - lr: 0.0010\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24180.0352 - val_loss: 7769.5591 - lr: 0.0010\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28431.5391 - val_loss: 8975.2070 - lr: 0.0010\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 39094.7148 - val_loss: 2617.4028 - lr: 0.0010\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 25013.4980 - val_loss: 2370.4609 - lr: 0.0010\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39124.7422 - val_loss: 23885.3750 - lr: 0.0010\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30493.2285 - val_loss: 3261.8416 - lr: 0.0010\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 18656.8633 - val_loss: 7506.7573 - lr: 0.0010\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25621.8359 - val_loss: 9496.3799 - lr: 0.0010\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 25511.9199 - val_loss: 3029.8564 - lr: 0.0010\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29018.4004 - val_loss: 2321.0720 - lr: 0.0010\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17578.1855 - val_loss: 3151.8425 - lr: 0.0010\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 27282.6855 - val_loss: 2693.3638 - lr: 0.0010\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32332.9375 - val_loss: 16362.8076 - lr: 0.0010\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 41245.6328 - val_loss: 2676.8115 - lr: 0.0010\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 38242.7930 - val_loss: 24245.3828 - lr: 0.0010\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 48810.7148 - val_loss: 38137.9219 - lr: 0.0010\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 47843.4844 - val_loss: 2754.6697 - lr: 0.0010\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29931.7285 - val_loss: 15284.1299 - lr: 0.0010\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 42753.6172 - val_loss: 12325.3115 - lr: 0.0010\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 35149.4922 - val_loss: 3189.4414 - lr: 0.0010\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26921.4863 - val_loss: 11724.7598 - lr: 0.0010\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 34769.2305 - val_loss: 2134.2620 - lr: 0.0010\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19834.1270 - val_loss: 2537.3135 - lr: 0.0010\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32049.5078 - val_loss: 5145.4561 - lr: 0.0010\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 28084.2539 - val_loss: 3603.0188 - lr: 0.0010\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19742.1543 - val_loss: 20274.8438 - lr: 0.0010\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24986.3496 - val_loss: 6235.9116 - lr: 0.0010\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39770.3398 - val_loss: 4495.6538 - lr: 0.0010\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 37604.6016 - val_loss: 2945.7878 - lr: 0.0010\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 40112.4062 - val_loss: 5990.1060 - lr: 0.0010\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17742.4336 - val_loss: 2233.2712 - lr: 0.0010\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37027.1484 - val_loss: 2151.9814 - lr: 0.0010\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20559.7969 - val_loss: 2968.3232 - lr: 0.0010\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 27046.5391 - val_loss: 4030.6675 - lr: 0.0010\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20442.2520 - val_loss: 2207.8242 - lr: 0.0010\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 64061.0312 - val_loss: 2159.3076 - lr: 0.0010\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23834.6289 - val_loss: 7490.6011 - lr: 0.0010\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 39424.3203 - val_loss: 40972.0703 - lr: 0.0010\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 35781.9883 - val_loss: 5536.2881 - lr: 0.0010\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29479.1523 - val_loss: 2458.6614 - lr: 0.0010\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 34135.4102 - val_loss: 3127.1130 - lr: 0.0010\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 25666.6523 - val_loss: 2666.7283 - lr: 0.0010\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 26014.1914 - val_loss: 20694.0605 - lr: 0.0010\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31119.7676 - val_loss: 6247.6089 - lr: 0.0010\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32409.9219 - val_loss: 2302.4958 - lr: 0.0010\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 32069.9844 - val_loss: 18549.4922 - lr: 0.0010\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47903.6211 - val_loss: 9360.6123 - lr: 0.0010\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27115.2148 - val_loss: 2155.0593 - lr: 0.0010\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 44143.1328 - val_loss: 17404.0723 - lr: 0.0010\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 39195.4180 - val_loss: 20848.6777 - lr: 0.0010\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 34693.8242 - val_loss: 5130.6646 - lr: 0.0010\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 95524.3828 - val_loss: 4386.8281 - lr: 0.0010\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 44542.3438 - val_loss: 2738.6897 - lr: 0.0010\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 47297.4766 - val_loss: 33923.7852 - lr: 0.0010\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 33986.4766 - val_loss: 11790.3564 - lr: 0.0010\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 26877.1172 - val_loss: 2146.2146 - lr: 0.0010\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 26003.5586 - val_loss: 10340.6924 - lr: 0.0010\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 49326.8242 - val_loss: 7432.3657 - lr: 0.0010\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 27010.1270 - val_loss: 9192.7949 - lr: 0.0010\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28072.3770 - val_loss: 65443.4414 - lr: 0.0010\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 54899.4805 - val_loss: 5441.2036 - lr: 0.0010\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37662.2695 - val_loss: 3361.1995 - lr: 0.0010\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25628.7578 - val_loss: 5902.9092 - lr: 0.0010\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 37492.9648 - val_loss: 2136.9119 - lr: 0.0010\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35481.8125 - val_loss: 18743.9492 - lr: 0.0010\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 46819.3047 - val_loss: 2205.0635 - lr: 0.0010\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16169.4414 - val_loss: 2130.0378 - lr: 0.0010\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24478.4531 - val_loss: 2814.1204 - lr: 0.0010\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 28392.8105 - val_loss: 7426.3262 - lr: 0.0010\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25544.6172 - val_loss: 6358.2109 - lr: 0.0010\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 37004.9492 - val_loss: 8460.6250 - lr: 0.0010\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30669.8477 - val_loss: 14477.4375 - lr: 0.0010\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 27484.4668 - val_loss: 8956.4639 - lr: 0.0010\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21959.9707 - val_loss: 4092.9575 - lr: 0.0010\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 41742.2109 - val_loss: 33759.4336 - lr: 0.0010\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 46039.3438 - val_loss: 15863.5605 - lr: 0.0010\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 47620.8516 - val_loss: 15493.1855 - lr: 0.0010\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 243581.7500 - val_loss: 6995.0498 - lr: 0.0010\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 50321.4375 - val_loss: 16755.7871 - lr: 0.0010\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 33742.2578 - val_loss: 26992.9922 - lr: 0.0010\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 56066.4258 - val_loss: 14015.9434 - lr: 0.0010\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46223.9766 - val_loss: 3798.1550 - lr: 0.0010\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17388.6738 - val_loss: 3257.5742 - lr: 0.0010\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24956.9453 - val_loss: 2153.0515 - lr: 0.0010\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19676.1699 - val_loss: 3726.7397 - lr: 0.0010\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32216.0801 - val_loss: 2484.5684 - lr: 0.0010\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26115.5488 - val_loss: 5316.6484 - lr: 0.0010\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 42134.4023 - val_loss: 2342.8313 - lr: 0.0010\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31463.3594 - val_loss: 2133.9189 - lr: 0.0010\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23412.8164 - val_loss: 8793.3789 - lr: 0.0010\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 28216.8906 - val_loss: 21081.8398 - lr: 0.0010\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 54988.5586 - val_loss: 6070.2100 - lr: 0.0010\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 49823.6250 - val_loss: 7326.9707 - lr: 0.0010\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 46359.5312 - val_loss: 60083.0781 - lr: 0.0010\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 70869.2734 - val_loss: 30256.5957 - lr: 0.0010\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 73783.0391 - val_loss: 25617.1250 - lr: 0.0010\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 45569.3203 - val_loss: 52398.5273 - lr: 0.0010\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 69840.7734 - val_loss: 57315.7344 - lr: 0.0010\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 84823.1875 - val_loss: 8722.5215 - lr: 0.0010\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 26916.3203 - val_loss: 5851.5107 - lr: 0.0010\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27868.5469 - val_loss: 19064.6426 - lr: 0.0010\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26054.2832 - val_loss: 3611.6746 - lr: 0.0010\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19312.5625 - val_loss: 2336.1558 - lr: 0.0010\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20844.5762 - val_loss: 2119.7705 - lr: 0.0010\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13385.8271 - val_loss: 2733.0630 - lr: 0.0010\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24029.0488 - val_loss: 2120.3291 - lr: 0.0010\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 23558.5996 - val_loss: 3040.5803 - lr: 0.0010\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26817.8965 - val_loss: 3065.8584 - lr: 0.0010\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 21795.3379 - val_loss: 3264.0454 - lr: 0.0010\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23386.8164 - val_loss: 3578.2681 - lr: 0.0010\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32227.6836 - val_loss: 9897.3037 - lr: 0.0010\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22933.9688 - val_loss: 6975.8589 - lr: 0.0010\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20515.1484 - val_loss: 4495.1919 - lr: 0.0010\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14071.7295 - val_loss: 3452.2957 - lr: 0.0010\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19523.4219 - val_loss: 3537.7041 - lr: 0.0010\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 16965.8398 - val_loss: 4620.1104 - lr: 0.0010\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 29150.0332 - val_loss: 10089.0674 - lr: 0.0010\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 44844.6562 - val_loss: 2546.5095 - lr: 0.0010\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13630.5361 - val_loss: 4071.2334 - lr: 0.0010\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18176.9941 - val_loss: 13460.8076 - lr: 0.0010\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 36158.4414 - val_loss: 16076.5732 - lr: 0.0010\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 30744.3789 - val_loss: 4019.7668 - lr: 0.0010\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26081.6152 - val_loss: 5473.3662 - lr: 0.0010\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30151.0117 - val_loss: 5955.3262 - lr: 0.0010\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23348.9219 - val_loss: 6419.5601 - lr: 0.0010\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 43433.0625 - val_loss: 22002.9902 - lr: 0.0010\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 47225.5547 - val_loss: 2280.5195 - lr: 0.0010\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33769.3477 - val_loss: 2180.4990 - lr: 0.0010\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 22275.4297 - val_loss: 2287.9438 - lr: 0.0010\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16247.8525 - val_loss: 2943.6414 - lr: 0.0010\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19681.6523 - val_loss: 2698.0601 - lr: 0.0010\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 38269.2578 - val_loss: 17483.9492 - lr: 0.0010\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 27125.0215 - val_loss: 2166.7942 - lr: 0.0010\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20484.7891 - val_loss: 4612.9673 - lr: 0.0010\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27391.4531 - val_loss: 6456.5127 - lr: 0.0010\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 24696.0781 - val_loss: 17518.5957 - lr: 0.0010\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31323.7910 - val_loss: 2183.6914 - lr: 0.0010\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 41188.0430 - val_loss: 2209.6304 - lr: 0.0010\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22506.7266 - val_loss: 7068.8428 - lr: 0.0010\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29712.6250 - val_loss: 4313.9141 - lr: 0.0010\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17979.0293 - val_loss: 3756.1992 - lr: 0.0010\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20235.2324 - val_loss: 6091.0239 - lr: 0.0010\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 28855.2344 - val_loss: 2353.1006 - lr: 0.0010\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27575.6855 - val_loss: 2578.6086 - lr: 0.0010\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19618.7344 - val_loss: 20252.2500 - lr: 0.0010\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24790.1406 - val_loss: 2509.2786 - lr: 0.0010\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17404.0469 - val_loss: 2811.5664 - lr: 0.0010\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19399.4824 - val_loss: 3495.6118 - lr: 0.0010\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16978.8633 - val_loss: 3454.0566 - lr: 0.0010\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20473.5156 - val_loss: 3840.9165 - lr: 0.0010\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 19068.6816 - val_loss: 3304.5986 - lr: 0.0010\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 14614.0439 - val_loss: 4426.9321 - lr: 0.0010\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13470.5352 - val_loss: 2545.0146 - lr: 0.0010\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 11679.5703 - val_loss: 3531.1086 - lr: 0.0010\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 16310.8975 - val_loss: 12544.6211 - lr: 0.0010\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24889.1035 - val_loss: 2127.3015 - lr: 0.0010\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 21539.3594 - val_loss: 2614.1643 - lr: 0.0010\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25544.5352 - val_loss: 2942.5952 - lr: 0.0010\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 22782.5293 - val_loss: 2516.5310 - lr: 0.0010\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11473.2715 - val_loss: 2306.8235 - lr: 0.0010\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19215.5352 - val_loss: 2204.3792 - lr: 0.0010\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20182.0898 - val_loss: 2237.0559 - lr: 0.0010\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 23181.2773 - val_loss: 2122.4724 - lr: 0.0010\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 15190.0020 - val_loss: 2592.4927 - lr: 0.0010\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15369.3154 - val_loss: 2461.8860 - lr: 0.0010\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 25164.7500 - val_loss: 52588.7422 - lr: 0.0010\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 44018.1562 - val_loss: 9776.9531 - lr: 0.0010\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28050.4395 - val_loss: 2968.4817 - lr: 0.0010\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27786.0742 - val_loss: 8905.9375 - lr: 0.0010\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 36207.4766 - val_loss: 2619.1218 - lr: 0.0010\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19127.0156 - val_loss: 2374.9990 - lr: 0.0010\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19994.7031 - val_loss: 2463.4016 - lr: 0.0010\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 33975.5469 - val_loss: 7624.1025 - lr: 0.0010\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 21807.9727 - val_loss: 2286.8450 - lr: 0.0010\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26993.3320 - val_loss: 3170.4446 - lr: 0.0010\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 47209.7734 - val_loss: 17456.2754 - lr: 0.0010\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 49685.9961 - val_loss: 16575.7539 - lr: 0.0010\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 50444.3750 - val_loss: 10320.8896 - lr: 0.0010\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 63335.4648 - val_loss: 9580.1982 - lr: 0.0010\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35087.0977 - val_loss: 12319.8799 - lr: 0.0010\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26711.0332 - val_loss: 6082.3569 - lr: 0.0010\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 24605.9961 - val_loss: 4106.3340 - lr: 0.0010\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26708.9102 - val_loss: 3400.7178 - lr: 0.0010\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21878.6758 - val_loss: 5318.7363 - lr: 0.0010\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29391.4375 - val_loss: 4189.1099 - lr: 0.0010\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19969.6035 - val_loss: 3145.0112 - lr: 0.0010\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 38278.0352 - val_loss: 2214.0740 - lr: 0.0010\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36732.5430 - val_loss: 21299.6777 - lr: 0.0010\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30122.0781 - val_loss: 22787.3320 - lr: 0.0010\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32425.5742 - val_loss: 26262.6816 - lr: 0.0010\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 38527.0781 - val_loss: 3431.9172 - lr: 0.0010\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31925.6875 - val_loss: 6174.8672 - lr: 0.0010\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 16613.3535 - val_loss: 2177.5278 - lr: 0.0010\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20475.3359 - val_loss: 7628.6572 - lr: 0.0010\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 16933.5723 - val_loss: 2107.5156 - lr: 0.0010\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 14759.1357 - val_loss: 3458.7839 - lr: 0.0010\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 16092.0225 - val_loss: 2367.1265 - lr: 0.0010\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19313.9727 - val_loss: 2607.7156 - lr: 0.0010\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14357.4893 - val_loss: 2099.0405 - lr: 0.0010\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24840.2266 - val_loss: 5101.4961 - lr: 0.0010\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17449.1094 - val_loss: 3681.8030 - lr: 0.0010\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15577.1084 - val_loss: 3125.2576 - lr: 0.0010\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25554.5469 - val_loss: 2629.6890 - lr: 0.0010\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24173.0234 - val_loss: 2440.3035 - lr: 0.0010\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19476.6953 - val_loss: 2690.9128 - lr: 0.0010\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20396.4785 - val_loss: 6447.9014 - lr: 0.0010\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18812.4062 - val_loss: 5489.4380 - lr: 0.0010\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24934.5156 - val_loss: 2392.5642 - lr: 0.0010\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 21082.2090 - val_loss: 19335.9473 - lr: 0.0010\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48517.2148 - val_loss: 2737.2905 - lr: 0.0010\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34489.4922 - val_loss: 2582.8789 - lr: 0.0010\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 84196.5469 - val_loss: 5020.5439 - lr: 0.0010\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20494.6777 - val_loss: 3228.4089 - lr: 0.0010\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15234.0039 - val_loss: 5332.7856 - lr: 0.0010\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17443.0371 - val_loss: 18611.9316 - lr: 0.0010\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30817.3594 - val_loss: 2421.6047 - lr: 0.0010\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19532.8809 - val_loss: 2214.2461 - lr: 0.0010\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20383.0117 - val_loss: 7754.8569 - lr: 0.0010\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18767.3750 - val_loss: 3435.7632 - lr: 0.0010\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20181.4199 - val_loss: 7700.0688 - lr: 0.0010\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 23327.1250 - val_loss: 20223.4766 - lr: 0.0010\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29823.1348 - val_loss: 9609.9805 - lr: 0.0010\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27101.8633 - val_loss: 10809.1143 - lr: 0.0010\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30096.5488 - val_loss: 6057.7017 - lr: 0.0010\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25924.9902 - val_loss: 2563.7085 - lr: 0.0010\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33352.1211 - val_loss: 2771.5647 - lr: 0.0010\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 42556.4062 - val_loss: 2651.9282 - lr: 0.0010\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26251.6211 - val_loss: 21661.0742 - lr: 0.0010\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23530.4316 - val_loss: 9271.9746 - lr: 0.0010\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 19035.0586 - val_loss: 2386.6340 - lr: 0.0010\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21700.7773 - val_loss: 2632.6826 - lr: 0.0010\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 13398.9414 - val_loss: 2509.8113 - lr: 0.0010\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20238.6465 - val_loss: 2685.4316 - lr: 0.0010\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16912.5586 - val_loss: 3542.5383 - lr: 0.0010\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 20571.1641 - val_loss: 3423.4668 - lr: 0.0010\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 15406.5332 - val_loss: 4168.0869 - lr: 0.0010\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 18152.3203 - val_loss: 2604.3191 - lr: 0.0010\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 29131.1992 - val_loss: 2597.1418 - lr: 0.0010\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 20408.3262 - val_loss: 3882.5662 - lr: 0.0010\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 15187.6719 - val_loss: 2196.8525 - lr: 0.0010\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 15319.0781 - val_loss: 2255.2222 - lr: 0.0010\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20205.2910 - val_loss: 2801.9160 - lr: 0.0010\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 13698.4600 - val_loss: 2284.7954 - lr: 0.0010\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13705.7080 - val_loss: 2756.7881 - lr: 0.0010\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11744.2500 - val_loss: 2677.5173 - lr: 0.0010\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20530.2969 - val_loss: 5564.2837 - lr: 0.0010\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15287.0732 - val_loss: 4436.3281 - lr: 0.0010\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26045.7559 - val_loss: 2357.8872 - lr: 0.0010\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32909.5820 - val_loss: 3674.8489 - lr: 0.0010\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 31930.3926 - val_loss: 11118.5234 - lr: 0.0010\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33847.7188 - val_loss: 2089.8411 - lr: 0.0010\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11211.9443 - val_loss: 2102.6880 - lr: 0.0010\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13175.6123 - val_loss: 2630.7451 - lr: 0.0010\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12386.4502 - val_loss: 2089.0579 - lr: 0.0010\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18102.6973 - val_loss: 3774.3318 - lr: 0.0010\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 13818.7266 - val_loss: 4759.7056 - lr: 0.0010\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 13103.8936 - val_loss: 2442.4851 - lr: 0.0010\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21702.8672 - val_loss: 44567.7070 - lr: 0.0010\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 43898.9844 - val_loss: 45416.6797 - lr: 0.0010\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 50851.9180 - val_loss: 24461.2109 - lr: 0.0010\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29610.4336 - val_loss: 2286.2437 - lr: 0.0010\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16295.8066 - val_loss: 2176.0225 - lr: 0.0010\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 21609.9395 - val_loss: 4724.2261 - lr: 0.0010\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19157.6133 - val_loss: 2326.7830 - lr: 0.0010\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 22626.4590 - val_loss: 2201.2891 - lr: 0.0010\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 18823.0020 - val_loss: 11680.2969 - lr: 0.0010\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24612.8203 - val_loss: 8519.9736 - lr: 0.0010\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17076.5820 - val_loss: 2489.7363 - lr: 0.0010\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19131.2715 - val_loss: 2131.1389 - lr: 0.0010\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 22209.4707 - val_loss: 2086.1255 - lr: 0.0010\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25303.0117 - val_loss: 2176.7629 - lr: 0.0010\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19465.2285 - val_loss: 7113.5054 - lr: 0.0010\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17444.7168 - val_loss: 16014.5801 - lr: 0.0010\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 22050.3262 - val_loss: 42159.5117 - lr: 0.0010\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 43238.2148 - val_loss: 27118.8691 - lr: 0.0010\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 53262.3125 - val_loss: 9355.7871 - lr: 0.0010\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 30879.2754 - val_loss: 3560.7642 - lr: 0.0010\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 18984.4453 - val_loss: 4420.2759 - lr: 0.0010\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17096.8594 - val_loss: 31365.3848 - lr: 0.0010\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 43574.1445 - val_loss: 29246.6406 - lr: 0.0010\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29362.3867 - val_loss: 4901.4697 - lr: 0.0010\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23901.8906 - val_loss: 3113.9629 - lr: 0.0010\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 26352.1543 - val_loss: 2218.1025 - lr: 0.0010\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16878.3301 - val_loss: 2078.4746 - lr: 0.0010\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 53320.3242 - val_loss: 18641.1035 - lr: 0.0010\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 43299.2695 - val_loss: 3471.1006 - lr: 0.0010\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19746.0020 - val_loss: 2229.2302 - lr: 0.0010\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11095.7998 - val_loss: 5921.3564 - lr: 0.0010\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21615.6348 - val_loss: 2417.2957 - lr: 0.0010\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 14549.7646 - val_loss: 4537.6367 - lr: 0.0010\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 19183.0527 - val_loss: 5490.2207 - lr: 0.0010\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 14135.8516 - val_loss: 3110.8835 - lr: 0.0010\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 16263.4043 - val_loss: 4922.2993 - lr: 0.0010\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 15834.5879 - val_loss: 4677.9883 - lr: 0.0010\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23675.2168 - val_loss: 4800.0269 - lr: 0.0010\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 27948.1406 - val_loss: 4438.6021 - lr: 0.0010\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33468.1250 - val_loss: 4945.3062 - lr: 0.0010\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17428.5215 - val_loss: 15805.5713 - lr: 0.0010\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 26318.0781 - val_loss: 2366.9727 - lr: 0.0010\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 15670.6357 - val_loss: 4288.3359 - lr: 0.0010\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17446.4219 - val_loss: 7528.7607 - lr: 0.0010\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16651.9453 - val_loss: 6462.3330 - lr: 0.0010\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22426.9102 - val_loss: 3813.1055 - lr: 0.0010\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 16631.0488 - val_loss: 5930.5454 - lr: 0.0010\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 47453.6016 - val_loss: 37657.3984 - lr: 0.0010\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 38209.9961 - val_loss: 6730.5171 - lr: 0.0010\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32604.2500 - val_loss: 2781.1531 - lr: 0.0010\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19098.7832 - val_loss: 4779.4727 - lr: 0.0010\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13591.2812 - val_loss: 4836.6240 - lr: 0.0010\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11660.1123 - val_loss: 7817.3472 - lr: 0.0010\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 39095.3828 - val_loss: 31695.4785 - lr: 0.0010\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 32940.6484 - val_loss: 2602.0894 - lr: 0.0010\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30886.8594 - val_loss: 2561.2461 - lr: 0.0010\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 21241.1484 - val_loss: 4076.6973 - lr: 0.0010\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29227.3633 - val_loss: 3361.0137 - lr: 0.0010\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27000.3809 - val_loss: 5285.3979 - lr: 0.0010\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22127.5430 - val_loss: 4448.0913 - lr: 0.0010\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 15423.9668 - val_loss: 2072.0195 - lr: 0.0010\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 14461.0195 - val_loss: 2092.1978 - lr: 0.0010\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 15715.8516 - val_loss: 2198.0076 - lr: 0.0010\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 14505.6504 - val_loss: 6807.3135 - lr: 0.0010\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 17321.1797 - val_loss: 2601.3555 - lr: 0.0010\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17005.6465 - val_loss: 3143.1270 - lr: 0.0010\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 15398.3164 - val_loss: 3285.6965 - lr: 0.0010\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12982.8662 - val_loss: 18636.4766 - lr: 0.0010\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26731.5137 - val_loss: 8022.6367 - lr: 0.0010\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19286.6016 - val_loss: 40366.2422 - lr: 0.0010\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 40142.6094 - val_loss: 65260.5156 - lr: 0.0010\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 49738.7969 - val_loss: 29562.8574 - lr: 0.0010\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 32114.3672 - val_loss: 28574.6074 - lr: 0.0010\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 36554.0508 - val_loss: 2464.4775 - lr: 0.0010\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 21534.3965 - val_loss: 2457.9124 - lr: 0.0010\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17835.7676 - val_loss: 8693.9082 - lr: 0.0010\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18676.5352 - val_loss: 21596.2422 - lr: 0.0010\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 28973.7969 - val_loss: 18972.5234 - lr: 0.0010\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 36554.3984 - val_loss: 2462.5859 - lr: 0.0010\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25844.5332 - val_loss: 2756.8892 - lr: 0.0010\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 16134.7588 - val_loss: 2182.6956 - lr: 0.0010\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17975.2344 - val_loss: 2139.0413 - lr: 0.0010\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19264.3418 - val_loss: 3685.1589 - lr: 0.0010\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 26683.2793 - val_loss: 23559.5293 - lr: 0.0010\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35491.9688 - val_loss: 23173.7930 - lr: 0.0010\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 24732.2539 - val_loss: 9857.1191 - lr: 0.0010\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 14859.0674 - val_loss: 21046.2070 - lr: 0.0010\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 22238.0879 - val_loss: 6814.2925 - lr: 0.0010\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 19461.3223 - val_loss: 7684.0215 - lr: 0.0010\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 15267.6758 - val_loss: 12675.4111 - lr: 0.0010\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 14918.0488 - val_loss: 15306.3164 - lr: 0.0010\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 21305.9219 - val_loss: 21335.1094 - lr: 0.0010\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 27383.2949 - val_loss: 18024.6543 - lr: 0.0010\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26955.7930 - val_loss: 8318.3486 - lr: 0.0010\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 16406.6172 - val_loss: 3472.6289 - lr: 0.0010\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 21122.1582 - val_loss: 2076.7903 - lr: 0.0010\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12683.7588 - val_loss: 4715.9658 - lr: 0.0010\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17007.0801 - val_loss: 2072.8147 - lr: 0.0010\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 18881.2656 - val_loss: 4357.3320 - lr: 0.0010\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 17903.4902 - val_loss: 9225.3184 - lr: 0.0010\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 20646.4922 - val_loss: 3329.1343 - lr: 0.0010\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 19726.5078 - val_loss: 14751.8496 - lr: 0.0010\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19769.0879 - val_loss: 2080.5029 - lr: 0.0010\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 14761.8984 - val_loss: 8159.8945 - lr: 0.0010\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30545.7812 - val_loss: 4591.2671 - lr: 0.0010\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13963.0869 - val_loss: 2846.3315 - lr: 0.0010\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11595.2900 - val_loss: 3931.0845 - lr: 0.0010\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 17912.4590 - val_loss: 15772.2646 - lr: 0.0010\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30078.1406 - val_loss: 12828.6826 - lr: 0.0010\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 36144.5156 - val_loss: 11961.5283 - lr: 0.0010\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 35464.3164 - val_loss: 8086.4678 - lr: 0.0010\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 25631.9824 - val_loss: 4640.7949 - lr: 0.0010\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 17934.0371 - val_loss: 20334.3965 - lr: 0.0010\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 23379.1836 - val_loss: 22088.3047 - lr: 0.0010\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 26290.8535 - val_loss: 37976.6875 - lr: 0.0010\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 32541.3496 - val_loss: 108891.9844 - lr: 0.0010\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 77570.8516 - val_loss: 47935.8594 - lr: 0.0010\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 40838.5625 - val_loss: 10355.4219 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "history = nu_model.fit(X_train_output, y_train_output, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[lrd, mcp, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V88vdGiCghm",
        "outputId": "5a9742b2-c1b4-4982-898a-45d3b079cbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step - loss: 12570.5098\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12570.509765625"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "nu_model.evaluate(X_test_output, y_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2tPnc2xCkbU",
        "outputId": "9036880d-a71d-42e0-efe8-0025cca801bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[145.8082  ],\n",
              "       [145.78769 ],\n",
              "       [145.90683 ],\n",
              "       [145.96054 ],\n",
              "       [145.76913 ],\n",
              "       [ 39.158295],\n",
              "       [145.78378 ],\n",
              "       [145.88339 ],\n",
              "       [145.89902 ],\n",
              "       [145.9078  ],\n",
              "       [ 39.099213],\n",
              "       [145.80234 ],\n",
              "       [145.82285 ],\n",
              "       [ 39.235443],\n",
              "       [ 39.0455  ],\n",
              "       [145.7828  ],\n",
              "       [145.95078 ],\n",
              "       [145.75156 ],\n",
              "       [145.85507 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y_pred_output = nu_model.predict(X_test_output)\n",
        "y_pred_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBx-E25FlMS9",
        "outputId": "571cf807-b65c-4dbb-f619-4f9e031045e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[145.8707],\n",
              "       [145.8707],\n",
              "       [145.8707]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#showing the prdiction of some random points\n",
        "nu_model.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sBcVCr6Cm6C",
        "outputId": "1efc7b5e-9546-45a3-c53f-5fda80fefaa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15.236137398078434"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#geeting the r2 score for y_test and y_pred\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test_output, y_pred_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGYwUtc7F0s-",
        "outputId": "35af37c4-aae2-405b-c42b-a299210ba6a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112.11845648197546"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#calculate the root mean square error for neural network model\n",
        "RMSE = (((y_pred_output[:,0]-y_test_output)**2).mean())**.5\n",
        "RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "-7qNaCgaFA3Y",
        "outputId": "90ddb969-dc0c-4934-bf95-1d5f637c48d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH5MMErINHf0"
      },
      "source": [
        "**As we see from R2 and RMSE the neural network is very bad for these data and can not be able to detect the patterens from our small dataset so we will use best model we discoverd in pycaret Extra tree regroessor with numirc ordinal tenisty values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNummzcUNGob",
        "outputId": "5e0da10c-ca84-47dd-89e1-eba473b8b659"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9968461133890045"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(X_train_output, y_train_output)\n",
        "reg.score(X_test_output, y_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw3zrbEBO3eo",
        "outputId": "9708d0e5-1e64-4ee4-c72d-dbc3b4f8d14b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28., 28., 28.])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#showing the prdiction of some random points\n",
        "reg.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDhyCOKXPkBy"
      },
      "source": [
        "# Predict Latency thru Neural networks regression \n",
        "### Comparison between different models in pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqQSM6oxPjiU"
      },
      "outputs": [],
      "source": [
        "#for dummy variable approach\n",
        "df_laten_dum = df_all_dum.copy()\n",
        "df_laten_dum.drop('box_output', axis=1, inplace=True)\n",
        "\n",
        "#for numerical ordinal variable approach\n",
        "df_laten_ord = df_all_ordinal.copy()\n",
        "df_laten_ord.drop('box_output', axis=1, inplace=True)\n",
        "\n",
        "#uncomment one of next line to show it's values\n",
        "# df_laten_dum.head()\n",
        "# df_laten_ord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6b107ed261ec4a35a17c322abaff5a3c",
            "97ff2c17fafc46fbbf8ea9e775adf937",
            "59744b085bac4551adcf37ed16c1fbc5",
            "e4728f1154984a239b31f64130ee41a5",
            "9dda01900c0b46aab0fe57d0f9346457",
            "f77836c6dc964b979405b723a0d717d5"
          ]
        },
        "id": "DfVUUKQHPPkb",
        "outputId": "81ceb8c5-5d32-4934-f274-cd4a413ca026"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9caabb1b-1d39-494a-929e-8951b37f7b71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Latency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(190, 6)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(132, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(58, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>KFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>reg-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>USI</td>\n",
              "      <td>9160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Transform Target</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Transform Target Method</td>\n",
              "      <td>box-cox</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9caabb1b-1d39-494a-929e-8951b37f7b71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9caabb1b-1d39-494a-929e-8951b37f7b71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9caabb1b-1d39-494a-929e-8951b37f7b71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               123\n",
              "1                                   Target           Latency\n",
              "2                            Original Data          (190, 6)\n",
              "3                           Missing Values             False\n",
              "4                         Numeric Features                 5\n",
              "5                     Categorical Features                 0\n",
              "6                         Ordinal Features             False\n",
              "7                High Cardinality Features             False\n",
              "8                  High Cardinality Method              None\n",
              "9                    Transformed Train Set          (132, 5)\n",
              "10                    Transformed Test Set           (58, 5)\n",
              "11                      Shuffle Train-Test              True\n",
              "12                     Stratify Train-Test             False\n",
              "13                          Fold Generator             KFold\n",
              "14                             Fold Number                10\n",
              "15                                CPU Jobs                -1\n",
              "16                                 Use GPU             False\n",
              "17                          Log Experiment             False\n",
              "18                         Experiment Name  reg-default-name\n",
              "19                                     USI              9160\n",
              "20                         Imputation Type            simple\n",
              "21          Iterative Imputation Iteration              None\n",
              "22                         Numeric Imputer              mean\n",
              "23      Iterative Imputation Numeric Model              None\n",
              "24                     Categorical Imputer          constant\n",
              "25  Iterative Imputation Categorical Model              None\n",
              "26           Unknown Categoricals Handling    least_frequent\n",
              "27                               Normalize             False\n",
              "28                        Normalize Method              None\n",
              "29                          Transformation             False\n",
              "30                   Transformation Method              None\n",
              "31                                     PCA             False\n",
              "32                              PCA Method              None\n",
              "33                          PCA Components              None\n",
              "34                     Ignore Low Variance             False\n",
              "35                     Combine Rare Levels             False\n",
              "36                    Rare Level Threshold              None\n",
              "37                         Numeric Binning             False\n",
              "38                         Remove Outliers             False\n",
              "39                      Outliers Threshold              None\n",
              "40                Remove Multicollinearity             False\n",
              "41             Multicollinearity Threshold              None\n",
              "42             Remove Perfect Collinearity              True\n",
              "43                              Clustering             False\n",
              "44                    Clustering Iteration              None\n",
              "45                     Polynomial Features             False\n",
              "46                       Polynomial Degree              None\n",
              "47                    Trignometry Features             False\n",
              "48                    Polynomial Threshold              None\n",
              "49                          Group Features             False\n",
              "50                       Feature Selection             False\n",
              "51                Feature Selection Method           classic\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                        Transform Target             False\n",
              "57                 Transform Target Method           box-cox"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "exp_reg101 = setup(data = df_laten_dum, target = 'Latency', numeric_features = ['Block_period','Block_size'], session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735,
          "referenced_widgets": [
            "794f4f6304014c0ea2aabc020f22da8e",
            "07414a6ddf344a6d902a040765fa376f",
            "f844722b2e9d409fb706624d75418d1a"
          ]
        },
        "id": "gpqCV7CFQzA0",
        "outputId": "38dff00d-9c53-44f7-cea3-1fc75805aacf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fea3e6d8-c8ec-4190-bfc7-4577a1ad6549\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "      <td>17.5122</td>\n",
              "      <td>1088.5077</td>\n",
              "      <td>28.5000</td>\n",
              "      <td>0.9933</td>\n",
              "      <td>0.1080</td>\n",
              "      <td>0.0752</td>\n",
              "      <td>0.381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbr</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>27.4762</td>\n",
              "      <td>1623.9351</td>\n",
              "      <td>38.3856</td>\n",
              "      <td>0.9888</td>\n",
              "      <td>0.1891</td>\n",
              "      <td>0.1420</td>\n",
              "      <td>0.043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>28.5001</td>\n",
              "      <td>1953.8883</td>\n",
              "      <td>39.7239</td>\n",
              "      <td>0.9871</td>\n",
              "      <td>0.1693</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Regressor</td>\n",
              "      <td>45.4888</td>\n",
              "      <td>4102.1749</td>\n",
              "      <td>61.7987</td>\n",
              "      <td>0.9714</td>\n",
              "      <td>0.1764</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>60.3390</td>\n",
              "      <td>8173.9975</td>\n",
              "      <td>85.8819</td>\n",
              "      <td>0.9402</td>\n",
              "      <td>0.3806</td>\n",
              "      <td>0.3034</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>AdaBoost Regressor</td>\n",
              "      <td>79.3329</td>\n",
              "      <td>9884.5993</td>\n",
              "      <td>97.3343</td>\n",
              "      <td>0.9278</td>\n",
              "      <td>0.5127</td>\n",
              "      <td>0.6022</td>\n",
              "      <td>0.077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llar</th>\n",
              "      <td>Lasso Least Angle Regression</td>\n",
              "      <td>101.7077</td>\n",
              "      <td>19933.8098</td>\n",
              "      <td>137.5799</td>\n",
              "      <td>0.8497</td>\n",
              "      <td>0.6915</td>\n",
              "      <td>0.8799</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lasso</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>102.3703</td>\n",
              "      <td>19846.1875</td>\n",
              "      <td>137.0728</td>\n",
              "      <td>0.8494</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.9719</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lar</th>\n",
              "      <td>Least Angle Regression</td>\n",
              "      <td>103.1232</td>\n",
              "      <td>19934.0796</td>\n",
              "      <td>137.3521</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>0.6155</td>\n",
              "      <td>0.9884</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>103.1232</td>\n",
              "      <td>19934.0809</td>\n",
              "      <td>137.3521</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>0.6155</td>\n",
              "      <td>0.9884</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>101.7961</td>\n",
              "      <td>19916.1281</td>\n",
              "      <td>137.2169</td>\n",
              "      <td>0.8488</td>\n",
              "      <td>0.6221</td>\n",
              "      <td>0.9582</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>br</th>\n",
              "      <td>Bayesian Ridge</td>\n",
              "      <td>102.1630</td>\n",
              "      <td>19922.9986</td>\n",
              "      <td>137.2594</td>\n",
              "      <td>0.8488</td>\n",
              "      <td>0.6327</td>\n",
              "      <td>0.9669</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huber</th>\n",
              "      <td>Huber Regressor</td>\n",
              "      <td>93.9216</td>\n",
              "      <td>21027.8562</td>\n",
              "      <td>139.9129</td>\n",
              "      <td>0.8367</td>\n",
              "      <td>0.6918</td>\n",
              "      <td>0.7991</td>\n",
              "      <td>0.028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>par</th>\n",
              "      <td>Passive Aggressive Regressor</td>\n",
              "      <td>99.0486</td>\n",
              "      <td>23116.0783</td>\n",
              "      <td>147.9253</td>\n",
              "      <td>0.8205</td>\n",
              "      <td>0.7179</td>\n",
              "      <td>0.9357</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Regressor</td>\n",
              "      <td>110.9859</td>\n",
              "      <td>28487.8929</td>\n",
              "      <td>161.9928</td>\n",
              "      <td>0.7823</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7546</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>113.8900</td>\n",
              "      <td>31986.6044</td>\n",
              "      <td>174.0746</td>\n",
              "      <td>0.7536</td>\n",
              "      <td>0.5970</td>\n",
              "      <td>0.6488</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omp</th>\n",
              "      <td>Orthogonal Matching Pursuit</td>\n",
              "      <td>176.6694</td>\n",
              "      <td>57129.3705</td>\n",
              "      <td>232.7619</td>\n",
              "      <td>0.5620</td>\n",
              "      <td>1.0175</td>\n",
              "      <td>1.1021</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Regressor</td>\n",
              "      <td>310.9017</td>\n",
              "      <td>143944.2133</td>\n",
              "      <td>375.3520</td>\n",
              "      <td>-0.0348</td>\n",
              "      <td>1.1869</td>\n",
              "      <td>2.4696</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fea3e6d8-c8ec-4190-bfc7-4577a1ad6549')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fea3e6d8-c8ec-4190-bfc7-4577a1ad6549 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fea3e6d8-c8ec-4190-bfc7-4577a1ad6549');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model       MAE          MSE      RMSE  \\\n",
              "et                  Extra Trees Regressor   17.5122    1088.5077   28.5000   \n",
              "gbr           Gradient Boosting Regressor   27.4762    1623.9351   38.3856   \n",
              "rf                Random Forest Regressor   28.5001    1953.8883   39.7239   \n",
              "dt                Decision Tree Regressor   45.4888    4102.1749   61.7987   \n",
              "lightgbm  Light Gradient Boosting Machine   60.3390    8173.9975   85.8819   \n",
              "ada                    AdaBoost Regressor   79.3329    9884.5993   97.3343   \n",
              "llar         Lasso Least Angle Regression  101.7077   19933.8098  137.5799   \n",
              "lasso                    Lasso Regression  102.3703   19846.1875  137.0728   \n",
              "lar                Least Angle Regression  103.1232   19934.0796  137.3521   \n",
              "lr                      Linear Regression  103.1232   19934.0809  137.3521   \n",
              "ridge                    Ridge Regression  101.7961   19916.1281  137.2169   \n",
              "br                         Bayesian Ridge  102.1630   19922.9986  137.2594   \n",
              "huber                     Huber Regressor   93.9216   21027.8562  139.9129   \n",
              "par          Passive Aggressive Regressor   99.0486   23116.0783  147.9253   \n",
              "knn                 K Neighbors Regressor  110.9859   28487.8929  161.9928   \n",
              "en                            Elastic Net  113.8900   31986.6044  174.0746   \n",
              "omp           Orthogonal Matching Pursuit  176.6694   57129.3705  232.7619   \n",
              "dummy                     Dummy Regressor  310.9017  143944.2133  375.3520   \n",
              "\n",
              "              R2   RMSLE    MAPE  TT (Sec)  \n",
              "et        0.9933  0.1080  0.0752     0.381  \n",
              "gbr       0.9888  0.1891  0.1420     0.043  \n",
              "rf        0.9871  0.1693  0.1349     0.412  \n",
              "dt        0.9714  0.1764  0.1525     0.016  \n",
              "lightgbm  0.9402  0.3806  0.3034     0.026  \n",
              "ada       0.9278  0.5127  0.6022     0.077  \n",
              "llar      0.8497  0.6915  0.8799     0.018  \n",
              "lasso     0.8494  0.6389  0.9719     0.018  \n",
              "lar       0.8489  0.6155  0.9884     0.017  \n",
              "lr        0.8489  0.6155  0.9884     0.017  \n",
              "ridge     0.8488  0.6221  0.9582     0.017  \n",
              "br        0.8488  0.6327  0.9669     0.017  \n",
              "huber     0.8367  0.6918  0.7991     0.028  \n",
              "par       0.8205  0.7179  0.9357     0.021  \n",
              "knn       0.7823  0.6260  0.7546     0.062  \n",
              "en        0.7536  0.5970  0.6488     0.019  \n",
              "omp       0.5620  1.0175  1.1021     0.017  \n",
              "dummy    -0.0348  1.1869  2.4696     0.014  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
              "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                    max_samples=None, min_impurity_decrease=0.0,\n",
              "                    min_impurity_split=None, min_samples_leaf=1,\n",
              "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
              "                    random_state=123, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIPsOPERslt"
      },
      "source": [
        "***Dummy approach here is better than numeric ordinal for intensity feature but with very little difference..R2 for Dummy = .9933 and also we get better RMSE and for ordinal = .9925 so we can use dummy here and the extra tree regressor is the best that get these accuracies in the two cases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glqZhXxzU_qU"
      },
      "outputs": [],
      "source": [
        "#split our data to y that contain our output \"Latency\" and to x that contain the features inputs for our model\n",
        "y_lat=df_laten_dum[\"Latency\"]\n",
        "x_lat=df_laten_dum.copy()\n",
        "x_lat.drop(columns = ['Latency'],inplace = True)\n",
        "# x_lat.head()\n",
        "\n",
        "#split x,y to train and test to measure the accurcy of the model\n",
        "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(x_lat, y_lat, test_size = .05, random_state = 43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99DdjFoSf_O"
      },
      "source": [
        "## Try neural network for Latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5IH5-ZJV5RV"
      },
      "outputs": [],
      "source": [
        "# data normalization with sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "norm = MinMaxScaler().fit(X_train_lat)\n",
        "\n",
        "# transform training data\n",
        "X_train_norm = norm.transform(X_train_lat)\n",
        "\n",
        "# transform testing dataabs\n",
        "X_test_norm = norm.transform(X_test_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wfky7NGxWu0e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2aQPSetRDL9"
      },
      "outputs": [],
      "source": [
        "nu_model_lat = Sequential()\n",
        "nu_model_lat.add(Dense(units=100, activation='relu', input_shape=[X_train_norm.shape[1]]))\n",
        "nu_model_lat.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtKpIr9S8-q",
        "outputId": "0695bbbb-574c-41a9-e7f5-fae50adadec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               600       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 701\n",
            "Trainable params: 701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nu_model_lat.compile(loss='mean_squared_error', optimizer=Adam())\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                         patience = 300,\n",
        "                         verbose = 1,\n",
        "                         factor = 0.75,\n",
        "                         min_lr = 1e-6)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=600)\n",
        "nu_model_lat.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhBwFxzJTWRF",
        "outputId": "87f0a6b1-5d1c-4841-9dfb-e490cf90119c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 826.8510 - val_loss: 926.9459 - lr: 0.0010\n",
            "Epoch 5502/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 827.0521 - val_loss: 917.7995 - lr: 0.0010\n",
            "Epoch 5503/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 826.0605 - val_loss: 920.5325 - lr: 0.0010\n",
            "Epoch 5504/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 826.5075 - val_loss: 919.3827 - lr: 0.0010\n",
            "Epoch 5505/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 826.3082 - val_loss: 921.2405 - lr: 0.0010\n",
            "Epoch 5506/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 825.5965 - val_loss: 909.1725 - lr: 0.0010\n",
            "Epoch 5507/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 827.2005 - val_loss: 915.6033 - lr: 0.0010\n",
            "Epoch 5508/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 824.9815 - val_loss: 899.5132 - lr: 0.0010\n",
            "Epoch 5509/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 826.7982 - val_loss: 886.9548 - lr: 0.0010\n",
            "Epoch 5510/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 826.5679 - val_loss: 888.7294 - lr: 0.0010\n",
            "Epoch 5511/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 824.5078 - val_loss: 909.8306 - lr: 0.0010\n",
            "Epoch 5512/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 822.5585 - val_loss: 921.7452 - lr: 0.0010\n",
            "Epoch 5513/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 822.5598 - val_loss: 934.4527 - lr: 0.0010\n",
            "Epoch 5514/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 824.8196 - val_loss: 949.3161 - lr: 0.0010\n",
            "Epoch 5515/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 825.1374 - val_loss: 945.3686 - lr: 0.0010\n",
            "Epoch 5516/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 824.1043 - val_loss: 934.9616 - lr: 0.0010\n",
            "Epoch 5517/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 822.9001 - val_loss: 932.3320 - lr: 0.0010\n",
            "Epoch 5518/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 822.6810 - val_loss: 929.2487 - lr: 0.0010\n",
            "Epoch 5519/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 821.9610 - val_loss: 915.8815 - lr: 0.0010\n",
            "Epoch 5520/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 821.1596 - val_loss: 909.2742 - lr: 0.0010\n",
            "Epoch 5521/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 822.2692 - val_loss: 897.7374 - lr: 0.0010\n",
            "Epoch 5522/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 821.1598 - val_loss: 900.1942 - lr: 0.0010\n",
            "Epoch 5523/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 822.4772 - val_loss: 905.6166 - lr: 0.0010\n",
            "Epoch 5524/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 820.5479 - val_loss: 905.9454 - lr: 0.0010\n",
            "Epoch 5525/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 820.2560 - val_loss: 912.7507 - lr: 0.0010\n",
            "Epoch 5526/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 822.2798 - val_loss: 926.4361 - lr: 0.0010\n",
            "Epoch 5527/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 820.1819 - val_loss: 928.0855 - lr: 0.0010\n",
            "Epoch 5528/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 819.9070 - val_loss: 928.7122 - lr: 0.0010\n",
            "Epoch 5529/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 820.2454 - val_loss: 932.4673 - lr: 0.0010\n",
            "Epoch 5530/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 820.8229 - val_loss: 916.7719 - lr: 0.0010\n",
            "Epoch 5531/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 818.6668 - val_loss: 915.3152 - lr: 0.0010\n",
            "Epoch 5532/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 818.4997 - val_loss: 913.0701 - lr: 0.0010\n",
            "Epoch 5533/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 818.6240 - val_loss: 913.2797 - lr: 0.0010\n",
            "Epoch 5534/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 818.0643 - val_loss: 917.0452 - lr: 0.0010\n",
            "Epoch 5535/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 817.9059 - val_loss: 910.3622 - lr: 0.0010\n",
            "Epoch 5536/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 818.7625 - val_loss: 899.8646 - lr: 0.0010\n",
            "Epoch 5537/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 817.2994 - val_loss: 900.6464 - lr: 0.0010\n",
            "Epoch 5538/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 817.5347 - val_loss: 904.7722 - lr: 0.0010\n",
            "Epoch 5539/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 816.6605 - val_loss: 899.2161 - lr: 0.0010\n",
            "Epoch 5540/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 816.8687 - val_loss: 894.1505 - lr: 0.0010\n",
            "Epoch 5541/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 816.4472 - val_loss: 903.4647 - lr: 0.0010\n",
            "Epoch 5542/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 818.4485 - val_loss: 912.9847 - lr: 0.0010\n",
            "Epoch 5543/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 815.6550 - val_loss: 909.6561 - lr: 0.0010\n",
            "Epoch 5544/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 815.2393 - val_loss: 903.7390 - lr: 0.0010\n",
            "Epoch 5545/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 815.3834 - val_loss: 892.1995 - lr: 0.0010\n",
            "Epoch 5546/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 815.0302 - val_loss: 891.9800 - lr: 0.0010\n",
            "Epoch 5547/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 814.7527 - val_loss: 896.2819 - lr: 0.0010\n",
            "Epoch 5548/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 814.3766 - val_loss: 892.6049 - lr: 0.0010\n",
            "Epoch 5549/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 816.5032 - val_loss: 901.0994 - lr: 0.0010\n",
            "Epoch 5550/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 813.3984 - val_loss: 893.8436 - lr: 0.0010\n",
            "Epoch 5551/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 814.0544 - val_loss: 884.3469 - lr: 0.0010\n",
            "Epoch 5552/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 813.4319 - val_loss: 885.4285 - lr: 0.0010\n",
            "Epoch 5553/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 813.2138 - val_loss: 888.9293 - lr: 0.0010\n",
            "Epoch 5554/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 814.3812 - val_loss: 897.3843 - lr: 0.0010\n",
            "Epoch 5555/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 812.3522 - val_loss: 889.8762 - lr: 0.0010\n",
            "Epoch 5556/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 813.0389 - val_loss: 879.2900 - lr: 0.0010\n",
            "Epoch 5557/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 812.2742 - val_loss: 872.3730 - lr: 0.0010\n",
            "Epoch 5558/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 813.1702 - val_loss: 874.7112 - lr: 0.0010\n",
            "Epoch 5559/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 811.9240 - val_loss: 872.7526 - lr: 0.0010\n",
            "Epoch 5560/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 812.1212 - val_loss: 876.4352 - lr: 0.0010\n",
            "Epoch 5561/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 811.2023 - val_loss: 881.7065 - lr: 0.0010\n",
            "Epoch 5562/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 810.8946 - val_loss: 884.8170 - lr: 0.0010\n",
            "Epoch 5563/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 810.8341 - val_loss: 889.0546 - lr: 0.0010\n",
            "Epoch 5564/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 810.9600 - val_loss: 905.8298 - lr: 0.0010\n",
            "Epoch 5565/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 811.6680 - val_loss: 911.9750 - lr: 0.0010\n",
            "Epoch 5566/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 814.1392 - val_loss: 890.3169 - lr: 0.0010\n",
            "Epoch 5567/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 811.1052 - val_loss: 899.4361 - lr: 0.0010\n",
            "Epoch 5568/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 809.5432 - val_loss: 896.7771 - lr: 0.0010\n",
            "Epoch 5569/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 809.1758 - val_loss: 894.4682 - lr: 0.0010\n",
            "Epoch 5570/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 809.2634 - val_loss: 884.0172 - lr: 0.0010\n",
            "Epoch 5571/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 810.3309 - val_loss: 877.2841 - lr: 0.0010\n",
            "Epoch 5572/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 808.0838 - val_loss: 887.7449 - lr: 0.0010\n",
            "Epoch 5573/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 810.8828 - val_loss: 907.8453 - lr: 0.0010\n",
            "Epoch 5574/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 808.5457 - val_loss: 905.4234 - lr: 0.0010\n",
            "Epoch 5575/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 807.9443 - val_loss: 899.8223 - lr: 0.0010\n",
            "Epoch 5576/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 807.8385 - val_loss: 889.6240 - lr: 0.0010\n",
            "Epoch 5577/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 807.2712 - val_loss: 889.0082 - lr: 0.0010\n",
            "Epoch 5578/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 807.1058 - val_loss: 888.0346 - lr: 0.0010\n",
            "Epoch 5579/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 807.5769 - val_loss: 884.8401 - lr: 0.0010\n",
            "Epoch 5580/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 807.1938 - val_loss: 890.3877 - lr: 0.0010\n",
            "Epoch 5581/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 809.2132 - val_loss: 903.6116 - lr: 0.0010\n",
            "Epoch 5582/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 806.0854 - val_loss: 896.6159 - lr: 0.0010\n",
            "Epoch 5583/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 806.9468 - val_loss: 878.2911 - lr: 0.0010\n",
            "Epoch 5584/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 806.2166 - val_loss: 867.7317 - lr: 0.0010\n",
            "Epoch 5585/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 807.3582 - val_loss: 859.2726 - lr: 0.0010\n",
            "Epoch 5586/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 807.2377 - val_loss: 872.3528 - lr: 0.0010\n",
            "Epoch 5587/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 805.2507 - val_loss: 877.5200 - lr: 0.0010\n",
            "Epoch 5588/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 804.6656 - val_loss: 880.6920 - lr: 0.0010\n",
            "Epoch 5589/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 804.2012 - val_loss: 886.7990 - lr: 0.0010\n",
            "Epoch 5590/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 805.1349 - val_loss: 896.9844 - lr: 0.0010\n",
            "Epoch 5591/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 804.6147 - val_loss: 888.9930 - lr: 0.0010\n",
            "Epoch 5592/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 804.4345 - val_loss: 890.0679 - lr: 0.0010\n",
            "Epoch 5593/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 803.9260 - val_loss: 872.5183 - lr: 0.0010\n",
            "Epoch 5594/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 803.9526 - val_loss: 865.1808 - lr: 0.0010\n",
            "Epoch 5595/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 803.8540 - val_loss: 867.6326 - lr: 0.0010\n",
            "Epoch 5596/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 803.1220 - val_loss: 879.9811 - lr: 0.0010\n",
            "Epoch 5597/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 802.8156 - val_loss: 889.1110 - lr: 0.0010\n",
            "Epoch 5598/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 803.0701 - val_loss: 888.2325 - lr: 0.0010\n",
            "Epoch 5599/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 802.3865 - val_loss: 889.7967 - lr: 0.0010\n",
            "Epoch 5600/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 805.0505 - val_loss: 903.2985 - lr: 0.0010\n",
            "Epoch 5601/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 803.0671 - val_loss: 884.6101 - lr: 0.0010\n",
            "Epoch 5602/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 802.0153 - val_loss: 872.4966 - lr: 0.0010\n",
            "Epoch 5603/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 802.8114 - val_loss: 865.4241 - lr: 0.0010\n",
            "Epoch 5604/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 801.3291 - val_loss: 869.2034 - lr: 0.0010\n",
            "Epoch 5605/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 801.3817 - val_loss: 881.9698 - lr: 0.0010\n",
            "Epoch 5606/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 800.4034 - val_loss: 880.7399 - lr: 0.0010\n",
            "Epoch 5607/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 801.1756 - val_loss: 884.2189 - lr: 0.0010\n",
            "Epoch 5608/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 799.9274 - val_loss: 877.9000 - lr: 0.0010\n",
            "Epoch 5609/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 799.6565 - val_loss: 875.1682 - lr: 0.0010\n",
            "Epoch 5610/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 799.7701 - val_loss: 874.0268 - lr: 0.0010\n",
            "Epoch 5611/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 799.9531 - val_loss: 870.4135 - lr: 0.0010\n",
            "Epoch 5612/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 798.5505 - val_loss: 882.0622 - lr: 0.0010\n",
            "Epoch 5613/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 799.7103 - val_loss: 892.8031 - lr: 0.0010\n",
            "Epoch 5614/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 799.6202 - val_loss: 891.5256 - lr: 0.0010\n",
            "Epoch 5615/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 799.9102 - val_loss: 887.8235 - lr: 0.0010\n",
            "Epoch 5616/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 801.5104 - val_loss: 896.9894 - lr: 0.0010\n",
            "Epoch 5617/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 798.1582 - val_loss: 886.6616 - lr: 0.0010\n",
            "Epoch 5618/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 798.2573 - val_loss: 870.5904 - lr: 0.0010\n",
            "Epoch 5619/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 797.6810 - val_loss: 868.1874 - lr: 0.0010\n",
            "Epoch 5620/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 797.4050 - val_loss: 869.6151 - lr: 0.0010\n",
            "Epoch 5621/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 798.1801 - val_loss: 874.5266 - lr: 0.0010\n",
            "Epoch 5622/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 796.5489 - val_loss: 868.7253 - lr: 0.0010\n",
            "Epoch 5623/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 796.9407 - val_loss: 864.3815 - lr: 0.0010\n",
            "Epoch 5624/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 798.0930 - val_loss: 859.8397 - lr: 0.0010\n",
            "Epoch 5625/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 796.6553 - val_loss: 869.4749 - lr: 0.0010\n",
            "Epoch 5626/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 795.9182 - val_loss: 875.0869 - lr: 0.0010\n",
            "Epoch 5627/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 796.5005 - val_loss: 888.0255 - lr: 0.0010\n",
            "Epoch 5628/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 796.1771 - val_loss: 884.9841 - lr: 0.0010\n",
            "Epoch 5629/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 796.1084 - val_loss: 879.6168 - lr: 0.0010\n",
            "Epoch 5630/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 795.5242 - val_loss: 889.3991 - lr: 0.0010\n",
            "Epoch 5631/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 795.6897 - val_loss: 894.3718 - lr: 0.0010\n",
            "Epoch 5632/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 794.4055 - val_loss: 886.0510 - lr: 0.0010\n",
            "Epoch 5633/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 794.3655 - val_loss: 873.6440 - lr: 0.0010\n",
            "Epoch 5634/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 794.6223 - val_loss: 865.1461 - lr: 0.0010\n",
            "Epoch 5635/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 794.6500 - val_loss: 861.9399 - lr: 0.0010\n",
            "Epoch 5636/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 795.1575 - val_loss: 853.9598 - lr: 0.0010\n",
            "Epoch 5637/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 795.5766 - val_loss: 868.5645 - lr: 0.0010\n",
            "Epoch 5638/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 793.0073 - val_loss: 870.7108 - lr: 0.0010\n",
            "Epoch 5639/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 793.3476 - val_loss: 873.2134 - lr: 0.0010\n",
            "Epoch 5640/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 793.6676 - val_loss: 867.7312 - lr: 0.0010\n",
            "Epoch 5641/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 792.1368 - val_loss: 871.1276 - lr: 0.0010\n",
            "Epoch 5642/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 794.2448 - val_loss: 883.3115 - lr: 0.0010\n",
            "Epoch 5643/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 792.2584 - val_loss: 884.4038 - lr: 0.0010\n",
            "Epoch 5644/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 792.1045 - val_loss: 877.4279 - lr: 0.0010\n",
            "Epoch 5645/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 791.7981 - val_loss: 871.6693 - lr: 0.0010\n",
            "Epoch 5646/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 791.1597 - val_loss: 869.4907 - lr: 0.0010\n",
            "Epoch 5647/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 792.4982 - val_loss: 875.6502 - lr: 0.0010\n",
            "Epoch 5648/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 790.4780 - val_loss: 869.5622 - lr: 0.0010\n",
            "Epoch 5649/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 791.1055 - val_loss: 859.2272 - lr: 0.0010\n",
            "Epoch 5650/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 790.9740 - val_loss: 854.9749 - lr: 0.0010\n",
            "Epoch 5651/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 791.6907 - val_loss: 856.5441 - lr: 0.0010\n",
            "Epoch 5652/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 790.4572 - val_loss: 854.3828 - lr: 0.0010\n",
            "Epoch 5653/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 790.5770 - val_loss: 859.8646 - lr: 0.0010\n",
            "Epoch 5654/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 789.7593 - val_loss: 857.4319 - lr: 0.0010\n",
            "Epoch 5655/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 789.9008 - val_loss: 859.3969 - lr: 0.0010\n",
            "Epoch 5656/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 789.8876 - val_loss: 865.7764 - lr: 0.0010\n",
            "Epoch 5657/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 788.7742 - val_loss: 864.9503 - lr: 0.0010\n",
            "Epoch 5658/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 788.2790 - val_loss: 859.9846 - lr: 0.0010\n",
            "Epoch 5659/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 788.5193 - val_loss: 857.7502 - lr: 0.0010\n",
            "Epoch 5660/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 788.2828 - val_loss: 865.8939 - lr: 0.0010\n",
            "Epoch 5661/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 787.6212 - val_loss: 876.6653 - lr: 0.0010\n",
            "Epoch 5662/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 787.7269 - val_loss: 884.8583 - lr: 0.0010\n",
            "Epoch 5663/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 787.3482 - val_loss: 880.9307 - lr: 0.0010\n",
            "Epoch 5664/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 787.3643 - val_loss: 880.3503 - lr: 0.0010\n",
            "Epoch 5665/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 786.4146 - val_loss: 870.6562 - lr: 0.0010\n",
            "Epoch 5666/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 785.7363 - val_loss: 858.8911 - lr: 0.0010\n",
            "Epoch 5667/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 788.0738 - val_loss: 845.2093 - lr: 0.0010\n",
            "Epoch 5668/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 786.3009 - val_loss: 851.4371 - lr: 0.0010\n",
            "Epoch 5669/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 787.4376 - val_loss: 863.0784 - lr: 0.0010\n",
            "Epoch 5670/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 785.7391 - val_loss: 852.4963 - lr: 0.0010\n",
            "Epoch 5671/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 785.8680 - val_loss: 849.5276 - lr: 0.0010\n",
            "Epoch 5672/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 786.6669 - val_loss: 866.0861 - lr: 0.0010\n",
            "Epoch 5673/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 784.7158 - val_loss: 864.0298 - lr: 0.0010\n",
            "Epoch 5674/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 784.4421 - val_loss: 860.9976 - lr: 0.0010\n",
            "Epoch 5675/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 784.4613 - val_loss: 863.9105 - lr: 0.0010\n",
            "Epoch 5676/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 783.9473 - val_loss: 867.4963 - lr: 0.0010\n",
            "Epoch 5677/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 783.6794 - val_loss: 869.1833 - lr: 0.0010\n",
            "Epoch 5678/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 783.5087 - val_loss: 866.0003 - lr: 0.0010\n",
            "Epoch 5679/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 783.8141 - val_loss: 850.7261 - lr: 0.0010\n",
            "Epoch 5680/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 783.1888 - val_loss: 845.9930 - lr: 0.0010\n",
            "Epoch 5681/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 783.2702 - val_loss: 850.7444 - lr: 0.0010\n",
            "Epoch 5682/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 782.3887 - val_loss: 850.4135 - lr: 0.0010\n",
            "Epoch 5683/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 782.5696 - val_loss: 852.0726 - lr: 0.0010\n",
            "Epoch 5684/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 782.5139 - val_loss: 853.0678 - lr: 0.0010\n",
            "Epoch 5685/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 782.0370 - val_loss: 853.3773 - lr: 0.0010\n",
            "Epoch 5686/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 782.3417 - val_loss: 847.0809 - lr: 0.0010\n",
            "Epoch 5687/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 781.8376 - val_loss: 852.2199 - lr: 0.0010\n",
            "Epoch 5688/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 781.0687 - val_loss: 853.5488 - lr: 0.0010\n",
            "Epoch 5689/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 780.7673 - val_loss: 856.6935 - lr: 0.0010\n",
            "Epoch 5690/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 780.4637 - val_loss: 861.7348 - lr: 0.0010\n",
            "Epoch 5691/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 781.1443 - val_loss: 867.2209 - lr: 0.0010\n",
            "Epoch 5692/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 780.3568 - val_loss: 866.7029 - lr: 0.0010\n",
            "Epoch 5693/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 781.7028 - val_loss: 856.4839 - lr: 0.0010\n",
            "Epoch 5694/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 780.6183 - val_loss: 863.0632 - lr: 0.0010\n",
            "Epoch 5695/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 779.5795 - val_loss: 866.5977 - lr: 0.0010\n",
            "Epoch 5696/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 779.1711 - val_loss: 861.5084 - lr: 0.0010\n",
            "Epoch 5697/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 778.7256 - val_loss: 853.6114 - lr: 0.0010\n",
            "Epoch 5698/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 778.6926 - val_loss: 847.4160 - lr: 0.0010\n",
            "Epoch 5699/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 778.4519 - val_loss: 844.9616 - lr: 0.0010\n",
            "Epoch 5700/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 778.9260 - val_loss: 833.9756 - lr: 0.0010\n",
            "Epoch 5701/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 778.9948 - val_loss: 829.3579 - lr: 0.0010\n",
            "Epoch 5702/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 777.9291 - val_loss: 836.4875 - lr: 0.0010\n",
            "Epoch 5703/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 777.5106 - val_loss: 841.3894 - lr: 0.0010\n",
            "Epoch 5704/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 778.0762 - val_loss: 848.2402 - lr: 0.0010\n",
            "Epoch 5705/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 776.8171 - val_loss: 844.4867 - lr: 0.0010\n",
            "Epoch 5706/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 776.6968 - val_loss: 841.2231 - lr: 0.0010\n",
            "Epoch 5707/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 776.9330 - val_loss: 846.8307 - lr: 0.0010\n",
            "Epoch 5708/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 776.4310 - val_loss: 838.4796 - lr: 0.0010\n",
            "Epoch 5709/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 775.9333 - val_loss: 838.3375 - lr: 0.0010\n",
            "Epoch 5710/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 775.9309 - val_loss: 844.0112 - lr: 0.0010\n",
            "Epoch 5711/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 776.1878 - val_loss: 848.8704 - lr: 0.0010\n",
            "Epoch 5712/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 775.5132 - val_loss: 834.4127 - lr: 0.0010\n",
            "Epoch 5713/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 774.8464 - val_loss: 832.1624 - lr: 0.0010\n",
            "Epoch 5714/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 774.7113 - val_loss: 834.4420 - lr: 0.0010\n",
            "Epoch 5715/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 774.3989 - val_loss: 840.2648 - lr: 0.0010\n",
            "Epoch 5716/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 773.8254 - val_loss: 845.1125 - lr: 0.0010\n",
            "Epoch 5717/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 774.1946 - val_loss: 862.3712 - lr: 0.0010\n",
            "Epoch 5718/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 774.1189 - val_loss: 867.9458 - lr: 0.0010\n",
            "Epoch 5719/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 775.6072 - val_loss: 855.3654 - lr: 0.0010\n",
            "Epoch 5720/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 773.0025 - val_loss: 858.8074 - lr: 0.0010\n",
            "Epoch 5721/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 772.9286 - val_loss: 863.4772 - lr: 0.0010\n",
            "Epoch 5722/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 773.1757 - val_loss: 862.8525 - lr: 0.0010\n",
            "Epoch 5723/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 773.3235 - val_loss: 857.3967 - lr: 0.0010\n",
            "Epoch 5724/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 772.1614 - val_loss: 859.5134 - lr: 0.0010\n",
            "Epoch 5725/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 771.8082 - val_loss: 857.3840 - lr: 0.0010\n",
            "Epoch 5726/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 772.0344 - val_loss: 851.1570 - lr: 0.0010\n",
            "Epoch 5727/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 770.9091 - val_loss: 843.7440 - lr: 0.0010\n",
            "Epoch 5728/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 770.6859 - val_loss: 838.9808 - lr: 0.0010\n",
            "Epoch 5729/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 771.4701 - val_loss: 833.1766 - lr: 0.0010\n",
            "Epoch 5730/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 771.6877 - val_loss: 840.1140 - lr: 0.0010\n",
            "Epoch 5731/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 770.1807 - val_loss: 839.9061 - lr: 0.0010\n",
            "Epoch 5732/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 772.8871 - val_loss: 824.8042 - lr: 0.0010\n",
            "Epoch 5733/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 770.2504 - val_loss: 831.7371 - lr: 0.0010\n",
            "Epoch 5734/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 769.1787 - val_loss: 839.2601 - lr: 0.0010\n",
            "Epoch 5735/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 769.5310 - val_loss: 848.2972 - lr: 0.0010\n",
            "Epoch 5736/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 769.6182 - val_loss: 843.2144 - lr: 0.0010\n",
            "Epoch 5737/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 769.5486 - val_loss: 851.7041 - lr: 0.0010\n",
            "Epoch 5738/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 769.9926 - val_loss: 844.4113 - lr: 0.0010\n",
            "Epoch 5739/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 768.1275 - val_loss: 854.5031 - lr: 0.0010\n",
            "Epoch 5740/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 768.0661 - val_loss: 856.1658 - lr: 0.0010\n",
            "Epoch 5741/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 767.6251 - val_loss: 851.7739 - lr: 0.0010\n",
            "Epoch 5742/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 767.6942 - val_loss: 841.2050 - lr: 0.0010\n",
            "Epoch 5743/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 767.0642 - val_loss: 840.2449 - lr: 0.0010\n",
            "Epoch 5744/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 766.8495 - val_loss: 834.3480 - lr: 0.0010\n",
            "Epoch 5745/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 766.7953 - val_loss: 834.6018 - lr: 0.0010\n",
            "Epoch 5746/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 767.0769 - val_loss: 836.0833 - lr: 0.0010\n",
            "Epoch 5747/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 766.2415 - val_loss: 831.6472 - lr: 0.0010\n",
            "Epoch 5748/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 767.4609 - val_loss: 814.3568 - lr: 0.0010\n",
            "Epoch 5749/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 766.9868 - val_loss: 810.5388 - lr: 0.0010\n",
            "Epoch 5750/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 766.4167 - val_loss: 815.6646 - lr: 0.0010\n",
            "Epoch 5751/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 765.2551 - val_loss: 829.6049 - lr: 0.0010\n",
            "Epoch 5752/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 764.3230 - val_loss: 849.3753 - lr: 0.0010\n",
            "Epoch 5753/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 764.7772 - val_loss: 860.3079 - lr: 0.0010\n",
            "Epoch 5754/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 765.0131 - val_loss: 853.5076 - lr: 0.0010\n",
            "Epoch 5755/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 765.3002 - val_loss: 847.6587 - lr: 0.0010\n",
            "Epoch 5756/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 764.0679 - val_loss: 848.4401 - lr: 0.0010\n",
            "Epoch 5757/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 764.7368 - val_loss: 849.6409 - lr: 0.0010\n",
            "Epoch 5758/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 763.1552 - val_loss: 838.4509 - lr: 0.0010\n",
            "Epoch 5759/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 762.9651 - val_loss: 829.3333 - lr: 0.0010\n",
            "Epoch 5760/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 762.8753 - val_loss: 831.5760 - lr: 0.0010\n",
            "Epoch 5761/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 762.4345 - val_loss: 828.3076 - lr: 0.0010\n",
            "Epoch 5762/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 764.6695 - val_loss: 815.8384 - lr: 0.0010\n",
            "Epoch 5763/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 763.9453 - val_loss: 826.9225 - lr: 0.0010\n",
            "Epoch 5764/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 762.5965 - val_loss: 823.3068 - lr: 0.0010\n",
            "Epoch 5765/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 762.0202 - val_loss: 829.4529 - lr: 0.0010\n",
            "Epoch 5766/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 761.3036 - val_loss: 838.5875 - lr: 0.0010\n",
            "Epoch 5767/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 760.9742 - val_loss: 837.8368 - lr: 0.0010\n",
            "Epoch 5768/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 760.8100 - val_loss: 838.2226 - lr: 0.0010\n",
            "Epoch 5769/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 761.7516 - val_loss: 841.5508 - lr: 0.0010\n",
            "Epoch 5770/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 760.4713 - val_loss: 839.5853 - lr: 0.0010\n",
            "Epoch 5771/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 763.7294 - val_loss: 821.6976 - lr: 0.0010\n",
            "Epoch 5772/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 760.0639 - val_loss: 827.0029 - lr: 0.0010\n",
            "Epoch 5773/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 759.7372 - val_loss: 839.1061 - lr: 0.0010\n",
            "Epoch 5774/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 759.9998 - val_loss: 850.4308 - lr: 0.0010\n",
            "Epoch 5775/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 761.6039 - val_loss: 855.2662 - lr: 0.0010\n",
            "Epoch 5776/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 760.3192 - val_loss: 832.2078 - lr: 0.0010\n",
            "Epoch 5777/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 758.5920 - val_loss: 822.4918 - lr: 0.0010\n",
            "Epoch 5778/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 758.4888 - val_loss: 819.9142 - lr: 0.0010\n",
            "Epoch 5779/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 758.3001 - val_loss: 828.1902 - lr: 0.0010\n",
            "Epoch 5780/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 757.9261 - val_loss: 824.9955 - lr: 0.0010\n",
            "Epoch 5781/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 757.3708 - val_loss: 828.3227 - lr: 0.0010\n",
            "Epoch 5782/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 757.9222 - val_loss: 831.1824 - lr: 0.0010\n",
            "Epoch 5783/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 757.1218 - val_loss: 820.2009 - lr: 0.0010\n",
            "Epoch 5784/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 756.6914 - val_loss: 813.4310 - lr: 0.0010\n",
            "Epoch 5785/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 756.4246 - val_loss: 814.8126 - lr: 0.0010\n",
            "Epoch 5786/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 757.1395 - val_loss: 810.5401 - lr: 0.0010\n",
            "Epoch 5787/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 756.4858 - val_loss: 812.6636 - lr: 0.0010\n",
            "Epoch 5788/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 756.2100 - val_loss: 824.8806 - lr: 0.0010\n",
            "Epoch 5789/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 755.6936 - val_loss: 825.2341 - lr: 0.0010\n",
            "Epoch 5790/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 754.8279 - val_loss: 818.3500 - lr: 0.0010\n",
            "Epoch 5791/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 754.5110 - val_loss: 811.3260 - lr: 0.0010\n",
            "Epoch 5792/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 754.6667 - val_loss: 806.7749 - lr: 0.0010\n",
            "Epoch 5793/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 754.3364 - val_loss: 807.7776 - lr: 0.0010\n",
            "Epoch 5794/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 754.4766 - val_loss: 811.0421 - lr: 0.0010\n",
            "Epoch 5795/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 753.8073 - val_loss: 809.9631 - lr: 0.0010\n",
            "Epoch 5796/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 754.6578 - val_loss: 801.5889 - lr: 0.0010\n",
            "Epoch 5797/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 753.9733 - val_loss: 801.6506 - lr: 0.0010\n",
            "Epoch 5798/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 752.7959 - val_loss: 811.8635 - lr: 0.0010\n",
            "Epoch 5799/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 751.7108 - val_loss: 822.7375 - lr: 0.0010\n",
            "Epoch 5800/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 751.7322 - val_loss: 832.1955 - lr: 0.0010\n",
            "Epoch 5801/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 753.1575 - val_loss: 849.7605 - lr: 0.0010\n",
            "Epoch 5802/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 753.9752 - val_loss: 841.5864 - lr: 0.0010\n",
            "Epoch 5803/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 752.3708 - val_loss: 835.1239 - lr: 0.0010\n",
            "Epoch 5804/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 752.9350 - val_loss: 816.9105 - lr: 0.0010\n",
            "Epoch 5805/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 751.3871 - val_loss: 809.9722 - lr: 0.0010\n",
            "Epoch 5806/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 751.1686 - val_loss: 803.4577 - lr: 0.0010\n",
            "Epoch 5807/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 750.4397 - val_loss: 804.0038 - lr: 0.0010\n",
            "Epoch 5808/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 750.0203 - val_loss: 811.8972 - lr: 0.0010\n",
            "Epoch 5809/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 749.8430 - val_loss: 814.9241 - lr: 0.0010\n",
            "Epoch 5810/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 749.7112 - val_loss: 821.2693 - lr: 0.0010\n",
            "Epoch 5811/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 749.7786 - val_loss: 819.2746 - lr: 0.0010\n",
            "Epoch 5812/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 749.4578 - val_loss: 818.5744 - lr: 0.0010\n",
            "Epoch 5813/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 749.6507 - val_loss: 809.7940 - lr: 0.0010\n",
            "Epoch 5814/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 750.4802 - val_loss: 804.2784 - lr: 0.0010\n",
            "Epoch 5815/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 747.4851 - val_loss: 817.8065 - lr: 0.0010\n",
            "Epoch 5816/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 748.2804 - val_loss: 828.8871 - lr: 0.0010\n",
            "Epoch 5817/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 748.2696 - val_loss: 828.3913 - lr: 0.0010\n",
            "Epoch 5818/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 747.8441 - val_loss: 821.8232 - lr: 0.0010\n",
            "Epoch 5819/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 746.7038 - val_loss: 814.1967 - lr: 0.0010\n",
            "Epoch 5820/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 748.1630 - val_loss: 805.2585 - lr: 0.0010\n",
            "Epoch 5821/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 746.6957 - val_loss: 812.2684 - lr: 0.0010\n",
            "Epoch 5822/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 746.7058 - val_loss: 809.9499 - lr: 0.0010\n",
            "Epoch 5823/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 748.9852 - val_loss: 826.7290 - lr: 0.0010\n",
            "Epoch 5824/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 745.9810 - val_loss: 822.4697 - lr: 0.0010\n",
            "Epoch 5825/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 745.7728 - val_loss: 821.5177 - lr: 0.0010\n",
            "Epoch 5826/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 746.8411 - val_loss: 807.3860 - lr: 0.0010\n",
            "Epoch 5827/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 745.6595 - val_loss: 820.4947 - lr: 0.0010\n",
            "Epoch 5828/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 745.0576 - val_loss: 816.0595 - lr: 0.0010\n",
            "Epoch 5829/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 744.6903 - val_loss: 809.5208 - lr: 0.0010\n",
            "Epoch 5830/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 744.9255 - val_loss: 812.9296 - lr: 0.0010\n",
            "Epoch 5831/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 743.2258 - val_loss: 803.1013 - lr: 0.0010\n",
            "Epoch 5832/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 745.7259 - val_loss: 790.1476 - lr: 0.0010\n",
            "Epoch 5833/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 744.4048 - val_loss: 799.6373 - lr: 0.0010\n",
            "Epoch 5834/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 743.1928 - val_loss: 799.0014 - lr: 0.0010\n",
            "Epoch 5835/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 743.0093 - val_loss: 791.5803 - lr: 0.0010\n",
            "Epoch 5836/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 742.8352 - val_loss: 792.9894 - lr: 0.0010\n",
            "Epoch 5837/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 742.8821 - val_loss: 790.7409 - lr: 0.0010\n",
            "Epoch 5838/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 741.6985 - val_loss: 797.5731 - lr: 0.0010\n",
            "Epoch 5839/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 741.3892 - val_loss: 810.2075 - lr: 0.0010\n",
            "Epoch 5840/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 741.1553 - val_loss: 815.8980 - lr: 0.0010\n",
            "Epoch 5841/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 740.8733 - val_loss: 814.5227 - lr: 0.0010\n",
            "Epoch 5842/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 741.3115 - val_loss: 810.1258 - lr: 0.0010\n",
            "Epoch 5843/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 740.4437 - val_loss: 810.6910 - lr: 0.0010\n",
            "Epoch 5844/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 740.0339 - val_loss: 806.8122 - lr: 0.0010\n",
            "Epoch 5845/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 740.3546 - val_loss: 807.7312 - lr: 0.0010\n",
            "Epoch 5846/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 739.7576 - val_loss: 805.2887 - lr: 0.0010\n",
            "Epoch 5847/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 740.3343 - val_loss: 799.0895 - lr: 0.0010\n",
            "Epoch 5848/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 738.4750 - val_loss: 808.3861 - lr: 0.0010\n",
            "Epoch 5849/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 738.8682 - val_loss: 826.2225 - lr: 0.0010\n",
            "Epoch 5850/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 739.2277 - val_loss: 826.8692 - lr: 0.0010\n",
            "Epoch 5851/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 739.2212 - val_loss: 826.5049 - lr: 0.0010\n",
            "Epoch 5852/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 738.4012 - val_loss: 818.2962 - lr: 0.0010\n",
            "Epoch 5853/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 740.8904 - val_loss: 798.4349 - lr: 0.0010\n",
            "Epoch 5854/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 737.5732 - val_loss: 799.4513 - lr: 0.0010\n",
            "Epoch 5855/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 738.2260 - val_loss: 805.9911 - lr: 0.0010\n",
            "Epoch 5856/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 736.8523 - val_loss: 794.0228 - lr: 0.0010\n",
            "Epoch 5857/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 737.0795 - val_loss: 785.0752 - lr: 0.0010\n",
            "Epoch 5858/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 736.7969 - val_loss: 788.3370 - lr: 0.0010\n",
            "Epoch 5859/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 736.2566 - val_loss: 804.5431 - lr: 0.0010\n",
            "Epoch 5860/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 736.0889 - val_loss: 803.4470 - lr: 0.0010\n",
            "Epoch 5861/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 736.0972 - val_loss: 813.2250 - lr: 0.0010\n",
            "Epoch 5862/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 735.3664 - val_loss: 807.5773 - lr: 0.0010\n",
            "Epoch 5863/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 734.7996 - val_loss: 802.6913 - lr: 0.0010\n",
            "Epoch 5864/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 734.7200 - val_loss: 798.4524 - lr: 0.0010\n",
            "Epoch 5865/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 733.9190 - val_loss: 784.5010 - lr: 0.0010\n",
            "Epoch 5866/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 734.6676 - val_loss: 772.5211 - lr: 0.0010\n",
            "Epoch 5867/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 734.7264 - val_loss: 775.5432 - lr: 0.0010\n",
            "Epoch 5868/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 734.2753 - val_loss: 782.9092 - lr: 0.0010\n",
            "Epoch 5869/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 733.8340 - val_loss: 783.6401 - lr: 0.0010\n",
            "Epoch 5870/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 733.6169 - val_loss: 792.5535 - lr: 0.0010\n",
            "Epoch 5871/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 732.7747 - val_loss: 791.8188 - lr: 0.0010\n",
            "Epoch 5872/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 733.1580 - val_loss: 786.9811 - lr: 0.0010\n",
            "Epoch 5873/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 732.1704 - val_loss: 791.8812 - lr: 0.0010\n",
            "Epoch 5874/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 731.6728 - val_loss: 797.1696 - lr: 0.0010\n",
            "Epoch 5875/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 731.7186 - val_loss: 803.3173 - lr: 0.0010\n",
            "Epoch 5876/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 731.4423 - val_loss: 801.8470 - lr: 0.0010\n",
            "Epoch 5877/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 731.3357 - val_loss: 798.4791 - lr: 0.0010\n",
            "Epoch 5878/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 730.6694 - val_loss: 795.9890 - lr: 0.0010\n",
            "Epoch 5879/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 731.4267 - val_loss: 785.5824 - lr: 0.0010\n",
            "Epoch 5880/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 730.3733 - val_loss: 787.7119 - lr: 0.0010\n",
            "Epoch 5881/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 730.0886 - val_loss: 786.6781 - lr: 0.0010\n",
            "Epoch 5882/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 729.9976 - val_loss: 790.4010 - lr: 0.0010\n",
            "Epoch 5883/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 729.4500 - val_loss: 788.3231 - lr: 0.0010\n",
            "Epoch 5884/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 729.2376 - val_loss: 793.2983 - lr: 0.0010\n",
            "Epoch 5885/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 729.1245 - val_loss: 788.4816 - lr: 0.0010\n",
            "Epoch 5886/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 728.6874 - val_loss: 788.1911 - lr: 0.0010\n",
            "Epoch 5887/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 728.1566 - val_loss: 793.4594 - lr: 0.0010\n",
            "Epoch 5888/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 728.7703 - val_loss: 800.4832 - lr: 0.0010\n",
            "Epoch 5889/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 728.8394 - val_loss: 788.3444 - lr: 0.0010\n",
            "Epoch 5890/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 727.1179 - val_loss: 785.6774 - lr: 0.0010\n",
            "Epoch 5891/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 727.0133 - val_loss: 782.0143 - lr: 0.0010\n",
            "Epoch 5892/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 727.3199 - val_loss: 786.7289 - lr: 0.0010\n",
            "Epoch 5893/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 726.4739 - val_loss: 788.4159 - lr: 0.0010\n",
            "Epoch 5894/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 726.2192 - val_loss: 788.3318 - lr: 0.0010\n",
            "Epoch 5895/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 726.5157 - val_loss: 785.3810 - lr: 0.0010\n",
            "Epoch 5896/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 725.8413 - val_loss: 788.4384 - lr: 0.0010\n",
            "Epoch 5897/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 726.0556 - val_loss: 786.5311 - lr: 0.0010\n",
            "Epoch 5898/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 725.2574 - val_loss: 787.1526 - lr: 0.0010\n",
            "Epoch 5899/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 725.0134 - val_loss: 795.1701 - lr: 0.0010\n",
            "Epoch 5900/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 724.8441 - val_loss: 794.0124 - lr: 0.0010\n",
            "Epoch 5901/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 724.5593 - val_loss: 786.5744 - lr: 0.0010\n",
            "Epoch 5902/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 723.9147 - val_loss: 787.3749 - lr: 0.0010\n",
            "Epoch 5903/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 724.7793 - val_loss: 794.0065 - lr: 0.0010\n",
            "Epoch 5904/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 724.5729 - val_loss: 776.6936 - lr: 0.0010\n",
            "Epoch 5905/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 723.7389 - val_loss: 773.7006 - lr: 0.0010\n",
            "Epoch 5906/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 723.7474 - val_loss: 780.2472 - lr: 0.0010\n",
            "Epoch 5907/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 722.8541 - val_loss: 778.5391 - lr: 0.0010\n",
            "Epoch 5908/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 722.6129 - val_loss: 777.1019 - lr: 0.0010\n",
            "Epoch 5909/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 723.0103 - val_loss: 787.2282 - lr: 0.0010\n",
            "Epoch 5910/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 722.8409 - val_loss: 778.3398 - lr: 0.0010\n",
            "Epoch 5911/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 721.8032 - val_loss: 775.8459 - lr: 0.0010\n",
            "Epoch 5912/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 721.1682 - val_loss: 778.4815 - lr: 0.0010\n",
            "Epoch 5913/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 720.8719 - val_loss: 780.1055 - lr: 0.0010\n",
            "Epoch 5914/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 721.1371 - val_loss: 787.4691 - lr: 0.0010\n",
            "Epoch 5915/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 720.1904 - val_loss: 791.7602 - lr: 0.0010\n",
            "Epoch 5916/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 722.7751 - val_loss: 803.1733 - lr: 0.0010\n",
            "Epoch 5917/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 723.5517 - val_loss: 779.7537 - lr: 0.0010\n",
            "Epoch 5918/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 719.3290 - val_loss: 774.9357 - lr: 0.0010\n",
            "Epoch 5919/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 719.7310 - val_loss: 771.3898 - lr: 0.0010\n",
            "Epoch 5920/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 718.5433 - val_loss: 760.1047 - lr: 0.0010\n",
            "Epoch 5921/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 720.0676 - val_loss: 747.8783 - lr: 0.0010\n",
            "Epoch 5922/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 720.1074 - val_loss: 745.2546 - lr: 0.0010\n",
            "Epoch 5923/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 719.7991 - val_loss: 754.3806 - lr: 0.0010\n",
            "Epoch 5924/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 719.0663 - val_loss: 760.7970 - lr: 0.0010\n",
            "Epoch 5925/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 718.0159 - val_loss: 762.6166 - lr: 0.0010\n",
            "Epoch 5926/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 717.7135 - val_loss: 762.1604 - lr: 0.0010\n",
            "Epoch 5927/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 717.4167 - val_loss: 761.5251 - lr: 0.0010\n",
            "Epoch 5928/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 716.9697 - val_loss: 765.7823 - lr: 0.0010\n",
            "Epoch 5929/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 716.5652 - val_loss: 769.1774 - lr: 0.0010\n",
            "Epoch 5930/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 716.7532 - val_loss: 774.1938 - lr: 0.0010\n",
            "Epoch 5931/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 716.1269 - val_loss: 774.6655 - lr: 0.0010\n",
            "Epoch 5932/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 717.4529 - val_loss: 766.6356 - lr: 0.0010\n",
            "Epoch 5933/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 716.4122 - val_loss: 781.6852 - lr: 0.0010\n",
            "Epoch 5934/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 717.5643 - val_loss: 784.5530 - lr: 0.0010\n",
            "Epoch 5935/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 714.0501 - val_loss: 765.2446 - lr: 0.0010\n",
            "Epoch 5936/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 716.7563 - val_loss: 745.4167 - lr: 0.0010\n",
            "Epoch 5937/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 716.8078 - val_loss: 751.3621 - lr: 0.0010\n",
            "Epoch 5938/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 716.3596 - val_loss: 744.7363 - lr: 0.0010\n",
            "Epoch 5939/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 714.3346 - val_loss: 751.6379 - lr: 0.0010\n",
            "Epoch 5940/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 715.3190 - val_loss: 767.5180 - lr: 0.0010\n",
            "Epoch 5941/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 713.2811 - val_loss: 764.5241 - lr: 0.0010\n",
            "Epoch 5942/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 713.7770 - val_loss: 756.7168 - lr: 0.0010\n",
            "Epoch 5943/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 713.3134 - val_loss: 756.2650 - lr: 0.0010\n",
            "Epoch 5944/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 712.7711 - val_loss: 760.6756 - lr: 0.0010\n",
            "Epoch 5945/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 712.3358 - val_loss: 766.8875 - lr: 0.0010\n",
            "Epoch 5946/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 712.8891 - val_loss: 773.3022 - lr: 0.0010\n",
            "Epoch 5947/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 711.5590 - val_loss: 766.7829 - lr: 0.0010\n",
            "Epoch 5948/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 711.4247 - val_loss: 761.4139 - lr: 0.0010\n",
            "Epoch 5949/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 711.2040 - val_loss: 760.5860 - lr: 0.0010\n",
            "Epoch 5950/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 711.4155 - val_loss: 757.7161 - lr: 0.0010\n",
            "Epoch 5951/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 711.3738 - val_loss: 746.8284 - lr: 0.0010\n",
            "Epoch 5952/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 711.0688 - val_loss: 742.3309 - lr: 0.0010\n",
            "Epoch 5953/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 711.2073 - val_loss: 746.5142 - lr: 0.0010\n",
            "Epoch 5954/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 710.3103 - val_loss: 754.9119 - lr: 0.0010\n",
            "Epoch 5955/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 709.6233 - val_loss: 761.0804 - lr: 0.0010\n",
            "Epoch 5956/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 709.5726 - val_loss: 762.4378 - lr: 0.0010\n",
            "Epoch 5957/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 709.8117 - val_loss: 761.0729 - lr: 0.0010\n",
            "Epoch 5958/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 708.7139 - val_loss: 769.8835 - lr: 0.0010\n",
            "Epoch 5959/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 708.6654 - val_loss: 772.1380 - lr: 0.0010\n",
            "Epoch 5960/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 708.2971 - val_loss: 777.9591 - lr: 0.0010\n",
            "Epoch 5961/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 708.7439 - val_loss: 785.4468 - lr: 0.0010\n",
            "Epoch 5962/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 708.5558 - val_loss: 782.5774 - lr: 0.0010\n",
            "Epoch 5963/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 708.4631 - val_loss: 766.3926 - lr: 0.0010\n",
            "Epoch 5964/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 709.7402 - val_loss: 750.8210 - lr: 0.0010\n",
            "Epoch 5965/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 708.8966 - val_loss: 743.5196 - lr: 0.0010\n",
            "Epoch 5966/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 707.9319 - val_loss: 752.3453 - lr: 0.0010\n",
            "Epoch 5967/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 706.5894 - val_loss: 752.4147 - lr: 0.0010\n",
            "Epoch 5968/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 706.5696 - val_loss: 755.0480 - lr: 0.0010\n",
            "Epoch 5969/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 706.6140 - val_loss: 771.0763 - lr: 0.0010\n",
            "Epoch 5970/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 706.1439 - val_loss: 772.3004 - lr: 0.0010\n",
            "Epoch 5971/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 706.5432 - val_loss: 760.5920 - lr: 0.0010\n",
            "Epoch 5972/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 705.2935 - val_loss: 763.1205 - lr: 0.0010\n",
            "Epoch 5973/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 705.4054 - val_loss: 771.5027 - lr: 0.0010\n",
            "Epoch 5974/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 704.8172 - val_loss: 777.2247 - lr: 0.0010\n",
            "Epoch 5975/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 704.8904 - val_loss: 773.4489 - lr: 0.0010\n",
            "Epoch 5976/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 704.9529 - val_loss: 776.3528 - lr: 0.0010\n",
            "Epoch 5977/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 704.4492 - val_loss: 779.0822 - lr: 0.0010\n",
            "Epoch 5978/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 704.3536 - val_loss: 771.8892 - lr: 0.0010\n",
            "Epoch 5979/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 704.2502 - val_loss: 772.0628 - lr: 0.0010\n",
            "Epoch 5980/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 703.3305 - val_loss: 774.2985 - lr: 0.0010\n",
            "Epoch 5981/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 704.4568 - val_loss: 776.9138 - lr: 0.0010\n",
            "Epoch 5982/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 703.0358 - val_loss: 757.3041 - lr: 0.0010\n",
            "Epoch 5983/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 702.2666 - val_loss: 752.4700 - lr: 0.0010\n",
            "Epoch 5984/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 702.4899 - val_loss: 750.2875 - lr: 0.0010\n",
            "Epoch 5985/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 702.3926 - val_loss: 742.7416 - lr: 0.0010\n",
            "Epoch 5986/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 702.2254 - val_loss: 742.1808 - lr: 0.0010\n",
            "Epoch 5987/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 702.1024 - val_loss: 741.1454 - lr: 0.0010\n",
            "Epoch 5988/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 701.6960 - val_loss: 741.9216 - lr: 0.0010\n",
            "Epoch 5989/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 701.4733 - val_loss: 746.7347 - lr: 0.0010\n",
            "Epoch 5990/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 700.6589 - val_loss: 751.8411 - lr: 0.0010\n",
            "Epoch 5991/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 700.5613 - val_loss: 763.2272 - lr: 0.0010\n",
            "Epoch 5992/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 700.4016 - val_loss: 767.2636 - lr: 0.0010\n",
            "Epoch 5993/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 700.2806 - val_loss: 771.2458 - lr: 0.0010\n",
            "Epoch 5994/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 701.1259 - val_loss: 774.1993 - lr: 0.0010\n",
            "Epoch 5995/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 700.2412 - val_loss: 765.6238 - lr: 0.0010\n",
            "Epoch 5996/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 699.3897 - val_loss: 764.7017 - lr: 0.0010\n",
            "Epoch 5997/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 699.7458 - val_loss: 753.9604 - lr: 0.0010\n",
            "Epoch 5998/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 698.7854 - val_loss: 749.4382 - lr: 0.0010\n",
            "Epoch 5999/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 699.5743 - val_loss: 742.9852 - lr: 0.0010\n",
            "Epoch 6000/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 698.4462 - val_loss: 747.1521 - lr: 0.0010\n",
            "Epoch 6001/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 698.0373 - val_loss: 747.8552 - lr: 0.0010\n",
            "Epoch 6002/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 698.6118 - val_loss: 757.2141 - lr: 0.0010\n",
            "Epoch 6003/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 697.5663 - val_loss: 751.3054 - lr: 0.0010\n",
            "Epoch 6004/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 697.9511 - val_loss: 740.8019 - lr: 0.0010\n",
            "Epoch 6005/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 697.4583 - val_loss: 739.9006 - lr: 0.0010\n",
            "Epoch 6006/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 697.6609 - val_loss: 749.8865 - lr: 0.0010\n",
            "Epoch 6007/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 696.5746 - val_loss: 747.7063 - lr: 0.0010\n",
            "Epoch 6008/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 696.6954 - val_loss: 743.5795 - lr: 0.0010\n",
            "Epoch 6009/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 695.8624 - val_loss: 749.6560 - lr: 0.0010\n",
            "Epoch 6010/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 695.6313 - val_loss: 749.8502 - lr: 0.0010\n",
            "Epoch 6011/8000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 696.9207 - val_loss: 762.8920 - lr: 0.0010\n",
            "Epoch 6012/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 697.9369 - val_loss: 773.1035 - lr: 0.0010\n",
            "Epoch 6013/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 696.7173 - val_loss: 749.0421 - lr: 0.0010\n",
            "Epoch 6014/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 694.7194 - val_loss: 745.3327 - lr: 0.0010\n",
            "Epoch 6015/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 694.7346 - val_loss: 743.6707 - lr: 0.0010\n",
            "Epoch 6016/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 694.7525 - val_loss: 745.7263 - lr: 0.0010\n",
            "Epoch 6017/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 694.2421 - val_loss: 748.3744 - lr: 0.0010\n",
            "Epoch 6018/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 695.5667 - val_loss: 749.7943 - lr: 0.0010\n",
            "Epoch 6019/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 694.1523 - val_loss: 729.1782 - lr: 0.0010\n",
            "Epoch 6020/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 693.9851 - val_loss: 721.3235 - lr: 0.0010\n",
            "Epoch 6021/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 694.1556 - val_loss: 727.2646 - lr: 0.0010\n",
            "Epoch 6022/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 693.3061 - val_loss: 730.9257 - lr: 0.0010\n",
            "Epoch 6023/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 692.5366 - val_loss: 736.0751 - lr: 0.0010\n",
            "Epoch 6024/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 692.5078 - val_loss: 743.7612 - lr: 0.0010\n",
            "Epoch 6025/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 692.0411 - val_loss: 744.3439 - lr: 0.0010\n",
            "Epoch 6026/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 692.1907 - val_loss: 751.5358 - lr: 0.0010\n",
            "Epoch 6027/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 691.4648 - val_loss: 746.0134 - lr: 0.0010\n",
            "Epoch 6028/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 691.5556 - val_loss: 748.8825 - lr: 0.0010\n",
            "Epoch 6029/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 690.5681 - val_loss: 739.5910 - lr: 0.0010\n",
            "Epoch 6030/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 690.2365 - val_loss: 734.2410 - lr: 0.0010\n",
            "Epoch 6031/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 690.2936 - val_loss: 727.5890 - lr: 0.0010\n",
            "Epoch 6032/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 690.9019 - val_loss: 713.9323 - lr: 0.0010\n",
            "Epoch 6033/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 691.2482 - val_loss: 706.5925 - lr: 0.0010\n",
            "Epoch 6034/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 691.7595 - val_loss: 709.0475 - lr: 0.0010\n",
            "Epoch 6035/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 689.3459 - val_loss: 727.0737 - lr: 0.0010\n",
            "Epoch 6036/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 689.6650 - val_loss: 751.1007 - lr: 0.0010\n",
            "Epoch 6037/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 688.7253 - val_loss: 756.9586 - lr: 0.0010\n",
            "Epoch 6038/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 689.5923 - val_loss: 760.2816 - lr: 0.0010\n",
            "Epoch 6039/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 688.7574 - val_loss: 743.6169 - lr: 0.0010\n",
            "Epoch 6040/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 688.5308 - val_loss: 732.9962 - lr: 0.0010\n",
            "Epoch 6041/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 687.2652 - val_loss: 734.3676 - lr: 0.0010\n",
            "Epoch 6042/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 687.3630 - val_loss: 736.1277 - lr: 0.0010\n",
            "Epoch 6043/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 686.9229 - val_loss: 743.8581 - lr: 0.0010\n",
            "Epoch 6044/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 686.5854 - val_loss: 745.9592 - lr: 0.0010\n",
            "Epoch 6045/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 686.9083 - val_loss: 746.7030 - lr: 0.0010\n",
            "Epoch 6046/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 685.9011 - val_loss: 740.1910 - lr: 0.0010\n",
            "Epoch 6047/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 685.6011 - val_loss: 731.7454 - lr: 0.0010\n",
            "Epoch 6048/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 685.4175 - val_loss: 723.6441 - lr: 0.0010\n",
            "Epoch 6049/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 685.5940 - val_loss: 718.9847 - lr: 0.0010\n",
            "Epoch 6050/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 685.3917 - val_loss: 722.3801 - lr: 0.0010\n",
            "Epoch 6051/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 685.3173 - val_loss: 723.2195 - lr: 0.0010\n",
            "Epoch 6052/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 684.8431 - val_loss: 727.3481 - lr: 0.0010\n",
            "Epoch 6053/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 684.8075 - val_loss: 730.8051 - lr: 0.0010\n",
            "Epoch 6054/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 685.4604 - val_loss: 718.5056 - lr: 0.0010\n",
            "Epoch 6055/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 684.3735 - val_loss: 725.1837 - lr: 0.0010\n",
            "Epoch 6056/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 685.2077 - val_loss: 732.1547 - lr: 0.0010\n",
            "Epoch 6057/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 682.9529 - val_loss: 721.8354 - lr: 0.0010\n",
            "Epoch 6058/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 685.0888 - val_loss: 710.1288 - lr: 0.0010\n",
            "Epoch 6059/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 684.1785 - val_loss: 714.7191 - lr: 0.0010\n",
            "Epoch 6060/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 682.9371 - val_loss: 725.7136 - lr: 0.0010\n",
            "Epoch 6061/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 682.1840 - val_loss: 731.4864 - lr: 0.0010\n",
            "Epoch 6062/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 682.3542 - val_loss: 734.1024 - lr: 0.0010\n",
            "Epoch 6063/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 682.0949 - val_loss: 742.1198 - lr: 0.0010\n",
            "Epoch 6064/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 681.6340 - val_loss: 742.4192 - lr: 0.0010\n",
            "Epoch 6065/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 681.2635 - val_loss: 742.0184 - lr: 0.0010\n",
            "Epoch 6066/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 681.1008 - val_loss: 741.0768 - lr: 0.0010\n",
            "Epoch 6067/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 680.7408 - val_loss: 738.5466 - lr: 0.0010\n",
            "Epoch 6068/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 680.9890 - val_loss: 738.7367 - lr: 0.0010\n",
            "Epoch 6069/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 680.3727 - val_loss: 730.0076 - lr: 0.0010\n",
            "Epoch 6070/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 680.7463 - val_loss: 735.0620 - lr: 0.0010\n",
            "Epoch 6071/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 680.2316 - val_loss: 734.7121 - lr: 0.0010\n",
            "Epoch 6072/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 679.7897 - val_loss: 733.2291 - lr: 0.0010\n",
            "Epoch 6073/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 679.4073 - val_loss: 732.8414 - lr: 0.0010\n",
            "Epoch 6074/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 678.9514 - val_loss: 733.4392 - lr: 0.0010\n",
            "Epoch 6075/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 679.1123 - val_loss: 734.9990 - lr: 0.0010\n",
            "Epoch 6076/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 679.4695 - val_loss: 735.7704 - lr: 0.0010\n",
            "Epoch 6077/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 678.5530 - val_loss: 728.6651 - lr: 0.0010\n",
            "Epoch 6078/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 677.9584 - val_loss: 724.3888 - lr: 0.0010\n",
            "Epoch 6079/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 680.5243 - val_loss: 709.8474 - lr: 0.0010\n",
            "Epoch 6080/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 678.6628 - val_loss: 718.9596 - lr: 0.0010\n",
            "Epoch 6081/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 677.6340 - val_loss: 722.1451 - lr: 0.0010\n",
            "Epoch 6082/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 677.2612 - val_loss: 728.8020 - lr: 0.0010\n",
            "Epoch 6083/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 679.1588 - val_loss: 737.5592 - lr: 0.0010\n",
            "Epoch 6084/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 678.0935 - val_loss: 736.9233 - lr: 0.0010\n",
            "Epoch 6085/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 676.4147 - val_loss: 728.7702 - lr: 0.0010\n",
            "Epoch 6086/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 676.0659 - val_loss: 723.0723 - lr: 0.0010\n",
            "Epoch 6087/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 676.4473 - val_loss: 710.9735 - lr: 0.0010\n",
            "Epoch 6088/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 677.3198 - val_loss: 706.0751 - lr: 0.0010\n",
            "Epoch 6089/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 677.4392 - val_loss: 723.8097 - lr: 0.0010\n",
            "Epoch 6090/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 676.4043 - val_loss: 733.2946 - lr: 0.0010\n",
            "Epoch 6091/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 675.2058 - val_loss: 730.2961 - lr: 0.0010\n",
            "Epoch 6092/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 674.8672 - val_loss: 723.9929 - lr: 0.0010\n",
            "Epoch 6093/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 674.5526 - val_loss: 713.2294 - lr: 0.0010\n",
            "Epoch 6094/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 675.4339 - val_loss: 705.8449 - lr: 0.0010\n",
            "Epoch 6095/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 674.7295 - val_loss: 705.3708 - lr: 0.0010\n",
            "Epoch 6096/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 674.2454 - val_loss: 709.2369 - lr: 0.0010\n",
            "Epoch 6097/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 673.6733 - val_loss: 706.4966 - lr: 0.0010\n",
            "Epoch 6098/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 673.6774 - val_loss: 706.0433 - lr: 0.0010\n",
            "Epoch 6099/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 672.9514 - val_loss: 715.0040 - lr: 0.0010\n",
            "Epoch 6100/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 672.9865 - val_loss: 730.5889 - lr: 0.0010\n",
            "Epoch 6101/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 673.1451 - val_loss: 738.7188 - lr: 0.0010\n",
            "Epoch 6102/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 671.8738 - val_loss: 730.7073 - lr: 0.0010\n",
            "Epoch 6103/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 671.4253 - val_loss: 724.1216 - lr: 0.0010\n",
            "Epoch 6104/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 671.9943 - val_loss: 713.3334 - lr: 0.0010\n",
            "Epoch 6105/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 671.2654 - val_loss: 712.6038 - lr: 0.0010\n",
            "Epoch 6106/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 671.5491 - val_loss: 714.8976 - lr: 0.0010\n",
            "Epoch 6107/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 671.1854 - val_loss: 710.0812 - lr: 0.0010\n",
            "Epoch 6108/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 670.7426 - val_loss: 717.7583 - lr: 0.0010\n",
            "Epoch 6109/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 669.8007 - val_loss: 719.2178 - lr: 0.0010\n",
            "Epoch 6110/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 670.4070 - val_loss: 724.4380 - lr: 0.0010\n",
            "Epoch 6111/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 669.7736 - val_loss: 723.3668 - lr: 0.0010\n",
            "Epoch 6112/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 671.5209 - val_loss: 706.1631 - lr: 0.0010\n",
            "Epoch 6113/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 669.2860 - val_loss: 709.5783 - lr: 0.0010\n",
            "Epoch 6114/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 669.1730 - val_loss: 712.1853 - lr: 0.0010\n",
            "Epoch 6115/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 668.3445 - val_loss: 727.0345 - lr: 0.0010\n",
            "Epoch 6116/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 669.0815 - val_loss: 733.3605 - lr: 0.0010\n",
            "Epoch 6117/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 668.7065 - val_loss: 721.3685 - lr: 0.0010\n",
            "Epoch 6118/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 668.4940 - val_loss: 711.1179 - lr: 0.0010\n",
            "Epoch 6119/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 667.3224 - val_loss: 715.4803 - lr: 0.0010\n",
            "Epoch 6120/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 667.1013 - val_loss: 713.3876 - lr: 0.0010\n",
            "Epoch 6121/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 666.5743 - val_loss: 715.7193 - lr: 0.0010\n",
            "Epoch 6122/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 668.5042 - val_loss: 711.5071 - lr: 0.0010\n",
            "Epoch 6123/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 666.2032 - val_loss: 726.6346 - lr: 0.0010\n",
            "Epoch 6124/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 669.3027 - val_loss: 745.2076 - lr: 0.0010\n",
            "Epoch 6125/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 667.4207 - val_loss: 743.9962 - lr: 0.0010\n",
            "Epoch 6126/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 665.0966 - val_loss: 724.8113 - lr: 0.0010\n",
            "Epoch 6127/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 665.8840 - val_loss: 708.9921 - lr: 0.0010\n",
            "Epoch 6128/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 664.9941 - val_loss: 708.0579 - lr: 0.0010\n",
            "Epoch 6129/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 665.1536 - val_loss: 704.4700 - lr: 0.0010\n",
            "Epoch 6130/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 665.4524 - val_loss: 711.0605 - lr: 0.0010\n",
            "Epoch 6131/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 665.0281 - val_loss: 706.8677 - lr: 0.0010\n",
            "Epoch 6132/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 663.9714 - val_loss: 707.9597 - lr: 0.0010\n",
            "Epoch 6133/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 663.8622 - val_loss: 709.0483 - lr: 0.0010\n",
            "Epoch 6134/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 663.6265 - val_loss: 704.6390 - lr: 0.0010\n",
            "Epoch 6135/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 663.2749 - val_loss: 704.5250 - lr: 0.0010\n",
            "Epoch 6136/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 663.1355 - val_loss: 704.2024 - lr: 0.0010\n",
            "Epoch 6137/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 662.7527 - val_loss: 701.7365 - lr: 0.0010\n",
            "Epoch 6138/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 662.8811 - val_loss: 703.3992 - lr: 0.0010\n",
            "Epoch 6139/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 662.4410 - val_loss: 701.5504 - lr: 0.0010\n",
            "Epoch 6140/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 662.2185 - val_loss: 696.1453 - lr: 0.0010\n",
            "Epoch 6141/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 663.7313 - val_loss: 705.4651 - lr: 0.0010\n",
            "Epoch 6142/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 661.3459 - val_loss: 708.3362 - lr: 0.0010\n",
            "Epoch 6143/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 661.8992 - val_loss: 704.2941 - lr: 0.0010\n",
            "Epoch 6144/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 661.3056 - val_loss: 701.0620 - lr: 0.0010\n",
            "Epoch 6145/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 662.6217 - val_loss: 715.3275 - lr: 0.0010\n",
            "Epoch 6146/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 662.2879 - val_loss: 706.6544 - lr: 0.0010\n",
            "Epoch 6147/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 660.3970 - val_loss: 705.9578 - lr: 0.0010\n",
            "Epoch 6148/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 660.1425 - val_loss: 716.7177 - lr: 0.0010\n",
            "Epoch 6149/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 659.5273 - val_loss: 718.0303 - lr: 0.0010\n",
            "Epoch 6150/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 659.5767 - val_loss: 714.2594 - lr: 0.0010\n",
            "Epoch 6151/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 659.1809 - val_loss: 712.9581 - lr: 0.0010\n",
            "Epoch 6152/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 658.3124 - val_loss: 719.8252 - lr: 0.0010\n",
            "Epoch 6153/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 658.8693 - val_loss: 734.3322 - lr: 0.0010\n",
            "Epoch 6154/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 658.5374 - val_loss: 730.6097 - lr: 0.0010\n",
            "Epoch 6155/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 657.8652 - val_loss: 717.8511 - lr: 0.0010\n",
            "Epoch 6156/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 657.3754 - val_loss: 714.0486 - lr: 0.0010\n",
            "Epoch 6157/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 657.4316 - val_loss: 706.3721 - lr: 0.0010\n",
            "Epoch 6158/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 656.9287 - val_loss: 707.5120 - lr: 0.0010\n",
            "Epoch 6159/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 658.1727 - val_loss: 719.6204 - lr: 0.0010\n",
            "Epoch 6160/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 656.3291 - val_loss: 711.3757 - lr: 0.0010\n",
            "Epoch 6161/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 656.3090 - val_loss: 705.2102 - lr: 0.0010\n",
            "Epoch 6162/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 656.2133 - val_loss: 705.4563 - lr: 0.0010\n",
            "Epoch 6163/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 656.7528 - val_loss: 721.6792 - lr: 0.0010\n",
            "Epoch 6164/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 656.1795 - val_loss: 726.3422 - lr: 0.0010\n",
            "Epoch 6165/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 655.4178 - val_loss: 722.2343 - lr: 0.0010\n",
            "Epoch 6166/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 655.2928 - val_loss: 707.3442 - lr: 0.0010\n",
            "Epoch 6167/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 656.4863 - val_loss: 699.5717 - lr: 0.0010\n",
            "Epoch 6168/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 654.5618 - val_loss: 719.2546 - lr: 0.0010\n",
            "Epoch 6169/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 653.7535 - val_loss: 726.4805 - lr: 0.0010\n",
            "Epoch 6170/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 654.2526 - val_loss: 725.2354 - lr: 0.0010\n",
            "Epoch 6171/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 653.7988 - val_loss: 727.1150 - lr: 0.0010\n",
            "Epoch 6172/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 653.5733 - val_loss: 722.0682 - lr: 0.0010\n",
            "Epoch 6173/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 652.5530 - val_loss: 701.8361 - lr: 0.0010\n",
            "Epoch 6174/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 653.1977 - val_loss: 686.1785 - lr: 0.0010\n",
            "Epoch 6175/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 654.6653 - val_loss: 679.9333 - lr: 0.0010\n",
            "Epoch 6176/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 652.6664 - val_loss: 695.9396 - lr: 0.0010\n",
            "Epoch 6177/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 651.6323 - val_loss: 709.9380 - lr: 0.0010\n",
            "Epoch 6178/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 651.2347 - val_loss: 719.8904 - lr: 0.0010\n",
            "Epoch 6179/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 651.2393 - val_loss: 721.0291 - lr: 0.0010\n",
            "Epoch 6180/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 650.9860 - val_loss: 714.9047 - lr: 0.0010\n",
            "Epoch 6181/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 650.6277 - val_loss: 714.9303 - lr: 0.0010\n",
            "Epoch 6182/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 650.6102 - val_loss: 719.9964 - lr: 0.0010\n",
            "Epoch 6183/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 650.5269 - val_loss: 718.6125 - lr: 0.0010\n",
            "Epoch 6184/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 649.6445 - val_loss: 715.1192 - lr: 0.0010\n",
            "Epoch 6185/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 649.3860 - val_loss: 708.3513 - lr: 0.0010\n",
            "Epoch 6186/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 649.3005 - val_loss: 707.1615 - lr: 0.0010\n",
            "Epoch 6187/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 648.7859 - val_loss: 711.1490 - lr: 0.0010\n",
            "Epoch 6188/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 650.2141 - val_loss: 724.1450 - lr: 0.0010\n",
            "Epoch 6189/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 648.6351 - val_loss: 720.2188 - lr: 0.0010\n",
            "Epoch 6190/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 649.6661 - val_loss: 705.9408 - lr: 0.0010\n",
            "Epoch 6191/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 647.9901 - val_loss: 709.2505 - lr: 0.0010\n",
            "Epoch 6192/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 647.8265 - val_loss: 710.8519 - lr: 0.0010\n",
            "Epoch 6193/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 647.7025 - val_loss: 712.2903 - lr: 0.0010\n",
            "Epoch 6194/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 647.3497 - val_loss: 714.3636 - lr: 0.0010\n",
            "Epoch 6195/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 646.7318 - val_loss: 709.0887 - lr: 0.0010\n",
            "Epoch 6196/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 646.3370 - val_loss: 709.4637 - lr: 0.0010\n",
            "Epoch 6197/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 649.4773 - val_loss: 697.8499 - lr: 0.0010\n",
            "Epoch 6198/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 646.0433 - val_loss: 711.9324 - lr: 0.0010\n",
            "Epoch 6199/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 646.0476 - val_loss: 728.9800 - lr: 0.0010\n",
            "Epoch 6200/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 645.6533 - val_loss: 737.6312 - lr: 0.0010\n",
            "Epoch 6201/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 649.0217 - val_loss: 750.7828 - lr: 0.0010\n",
            "Epoch 6202/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 646.6811 - val_loss: 737.9921 - lr: 0.0010\n",
            "Epoch 6203/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 647.5441 - val_loss: 710.1982 - lr: 0.0010\n",
            "Epoch 6204/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 646.0741 - val_loss: 694.3316 - lr: 0.0010\n",
            "Epoch 6205/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 645.9034 - val_loss: 685.9111 - lr: 0.0010\n",
            "Epoch 6206/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 643.4136 - val_loss: 698.1057 - lr: 0.0010\n",
            "Epoch 6207/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 644.8027 - val_loss: 715.4324 - lr: 0.0010\n",
            "Epoch 6208/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 642.7549 - val_loss: 714.6282 - lr: 0.0010\n",
            "Epoch 6209/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 642.9480 - val_loss: 716.8120 - lr: 0.0010\n",
            "Epoch 6210/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 643.1575 - val_loss: 715.5764 - lr: 0.0010\n",
            "Epoch 6211/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 641.9822 - val_loss: 725.8220 - lr: 0.0010\n",
            "Epoch 6212/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 642.1938 - val_loss: 723.4220 - lr: 0.0010\n",
            "Epoch 6213/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 642.1453 - val_loss: 719.5571 - lr: 0.0010\n",
            "Epoch 6214/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 641.5466 - val_loss: 713.2864 - lr: 0.0010\n",
            "Epoch 6215/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 640.5327 - val_loss: 707.1663 - lr: 0.0010\n",
            "Epoch 6216/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 640.5875 - val_loss: 697.2820 - lr: 0.0010\n",
            "Epoch 6217/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 640.4441 - val_loss: 698.5491 - lr: 0.0010\n",
            "Epoch 6218/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 640.3965 - val_loss: 699.4692 - lr: 0.0010\n",
            "Epoch 6219/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 640.0710 - val_loss: 698.7782 - lr: 0.0010\n",
            "Epoch 6220/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 640.9293 - val_loss: 710.6429 - lr: 0.0010\n",
            "Epoch 6221/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 639.3466 - val_loss: 711.6832 - lr: 0.0010\n",
            "Epoch 6222/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 638.5173 - val_loss: 706.4363 - lr: 0.0010\n",
            "Epoch 6223/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 639.1478 - val_loss: 701.2242 - lr: 0.0010\n",
            "Epoch 6224/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 639.0262 - val_loss: 703.2732 - lr: 0.0010\n",
            "Epoch 6225/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 637.6505 - val_loss: 696.9741 - lr: 0.0010\n",
            "Epoch 6226/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 638.1581 - val_loss: 684.3558 - lr: 0.0010\n",
            "Epoch 6227/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 639.8065 - val_loss: 676.9598 - lr: 0.0010\n",
            "Epoch 6228/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 638.3987 - val_loss: 677.4088 - lr: 0.0010\n",
            "Epoch 6229/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 638.2145 - val_loss: 688.3248 - lr: 0.0010\n",
            "Epoch 6230/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 637.0271 - val_loss: 690.8848 - lr: 0.0010\n",
            "Epoch 6231/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 636.5115 - val_loss: 701.5737 - lr: 0.0010\n",
            "Epoch 6232/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 636.1575 - val_loss: 699.4177 - lr: 0.0010\n",
            "Epoch 6233/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 635.4699 - val_loss: 705.8503 - lr: 0.0010\n",
            "Epoch 6234/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 635.6998 - val_loss: 706.6650 - lr: 0.0010\n",
            "Epoch 6235/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 635.2292 - val_loss: 719.4796 - lr: 0.0010\n",
            "Epoch 6236/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 635.3744 - val_loss: 722.2480 - lr: 0.0010\n",
            "Epoch 6237/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 635.0947 - val_loss: 719.9915 - lr: 0.0010\n",
            "Epoch 6238/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 634.8060 - val_loss: 711.7886 - lr: 0.0010\n",
            "Epoch 6239/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 633.9563 - val_loss: 693.2166 - lr: 0.0010\n",
            "Epoch 6240/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 633.7082 - val_loss: 680.4701 - lr: 0.0010\n",
            "Epoch 6241/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 634.3420 - val_loss: 677.8763 - lr: 0.0010\n",
            "Epoch 6242/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 633.9436 - val_loss: 682.0725 - lr: 0.0010\n",
            "Epoch 6243/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 632.7605 - val_loss: 688.7914 - lr: 0.0010\n",
            "Epoch 6244/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 632.5388 - val_loss: 699.2732 - lr: 0.0010\n",
            "Epoch 6245/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 632.4416 - val_loss: 697.1107 - lr: 0.0010\n",
            "Epoch 6246/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 631.5217 - val_loss: 701.0209 - lr: 0.0010\n",
            "Epoch 6247/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 632.0338 - val_loss: 709.9894 - lr: 0.0010\n",
            "Epoch 6248/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 631.6785 - val_loss: 710.4155 - lr: 0.0010\n",
            "Epoch 6249/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 631.1891 - val_loss: 695.7219 - lr: 0.0010\n",
            "Epoch 6250/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 631.8630 - val_loss: 685.5599 - lr: 0.0010\n",
            "Epoch 6251/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 630.0262 - val_loss: 688.6931 - lr: 0.0010\n",
            "Epoch 6252/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 629.4392 - val_loss: 693.5514 - lr: 0.0010\n",
            "Epoch 6253/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 629.3875 - val_loss: 707.9574 - lr: 0.0010\n",
            "Epoch 6254/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 629.2945 - val_loss: 706.6992 - lr: 0.0010\n",
            "Epoch 6255/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 628.9649 - val_loss: 711.2778 - lr: 0.0010\n",
            "Epoch 6256/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 628.9425 - val_loss: 703.1638 - lr: 0.0010\n",
            "Epoch 6257/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 628.1893 - val_loss: 700.5646 - lr: 0.0010\n",
            "Epoch 6258/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 627.6791 - val_loss: 701.9144 - lr: 0.0010\n",
            "Epoch 6259/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 627.6780 - val_loss: 699.7719 - lr: 0.0010\n",
            "Epoch 6260/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 628.2128 - val_loss: 709.2080 - lr: 0.0010\n",
            "Epoch 6261/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 627.1689 - val_loss: 704.1511 - lr: 0.0010\n",
            "Epoch 6262/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 626.1880 - val_loss: 699.9294 - lr: 0.0010\n",
            "Epoch 6263/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 626.0644 - val_loss: 691.5349 - lr: 0.0010\n",
            "Epoch 6264/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 626.1993 - val_loss: 694.7220 - lr: 0.0010\n",
            "Epoch 6265/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 625.0159 - val_loss: 689.7210 - lr: 0.0010\n",
            "Epoch 6266/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 624.8182 - val_loss: 683.7379 - lr: 0.0010\n",
            "Epoch 6267/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 624.7407 - val_loss: 679.5654 - lr: 0.0010\n",
            "Epoch 6268/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 624.2405 - val_loss: 682.7661 - lr: 0.0010\n",
            "Epoch 6269/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 624.1462 - val_loss: 685.2013 - lr: 0.0010\n",
            "Epoch 6270/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 623.5657 - val_loss: 685.6031 - lr: 0.0010\n",
            "Epoch 6271/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 623.0902 - val_loss: 691.6591 - lr: 0.0010\n",
            "Epoch 6272/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 623.6348 - val_loss: 700.8911 - lr: 0.0010\n",
            "Epoch 6273/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 623.7487 - val_loss: 688.6519 - lr: 0.0010\n",
            "Epoch 6274/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 621.9023 - val_loss: 692.7932 - lr: 0.0010\n",
            "Epoch 6275/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 621.6440 - val_loss: 706.4097 - lr: 0.0010\n",
            "Epoch 6276/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 621.5054 - val_loss: 704.6448 - lr: 0.0010\n",
            "Epoch 6277/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 621.2628 - val_loss: 709.1643 - lr: 0.0010\n",
            "Epoch 6278/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 621.1261 - val_loss: 709.0851 - lr: 0.0010\n",
            "Epoch 6279/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 621.2973 - val_loss: 707.4092 - lr: 0.0010\n",
            "Epoch 6280/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 620.3174 - val_loss: 710.6746 - lr: 0.0010\n",
            "Epoch 6281/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 620.0112 - val_loss: 705.7053 - lr: 0.0010\n",
            "Epoch 6282/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 620.2661 - val_loss: 684.7388 - lr: 0.0010\n",
            "Epoch 6283/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 618.2817 - val_loss: 677.0459 - lr: 0.0010\n",
            "Epoch 6284/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 618.7177 - val_loss: 671.5583 - lr: 0.0010\n",
            "Epoch 6285/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 618.8397 - val_loss: 673.6825 - lr: 0.0010\n",
            "Epoch 6286/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 618.0577 - val_loss: 673.0787 - lr: 0.0010\n",
            "Epoch 6287/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 617.7073 - val_loss: 686.7001 - lr: 0.0010\n",
            "Epoch 6288/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 616.4153 - val_loss: 693.7535 - lr: 0.0010\n",
            "Epoch 6289/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 616.2706 - val_loss: 703.9871 - lr: 0.0010\n",
            "Epoch 6290/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 617.1082 - val_loss: 716.7524 - lr: 0.0010\n",
            "Epoch 6291/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 616.7793 - val_loss: 709.1114 - lr: 0.0010\n",
            "Epoch 6292/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 615.7404 - val_loss: 694.7761 - lr: 0.0010\n",
            "Epoch 6293/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 615.3839 - val_loss: 684.4011 - lr: 0.0010\n",
            "Epoch 6294/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 614.5633 - val_loss: 683.7627 - lr: 0.0010\n",
            "Epoch 6295/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 614.7588 - val_loss: 675.5186 - lr: 0.0010\n",
            "Epoch 6296/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 613.7186 - val_loss: 680.2769 - lr: 0.0010\n",
            "Epoch 6297/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 613.7001 - val_loss: 682.2841 - lr: 0.0010\n",
            "Epoch 6298/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 614.1951 - val_loss: 676.7917 - lr: 0.0010\n",
            "Epoch 6299/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 612.9031 - val_loss: 676.4568 - lr: 0.0010\n",
            "Epoch 6300/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 612.2139 - val_loss: 683.1935 - lr: 0.0010\n",
            "Epoch 6301/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 613.5319 - val_loss: 692.0686 - lr: 0.0010\n",
            "Epoch 6302/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 612.4045 - val_loss: 683.0343 - lr: 0.0010\n",
            "Epoch 6303/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 611.7854 - val_loss: 678.3083 - lr: 0.0010\n",
            "Epoch 6304/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 610.9968 - val_loss: 680.7163 - lr: 0.0010\n",
            "Epoch 6305/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 612.4038 - val_loss: 687.8477 - lr: 0.0010\n",
            "Epoch 6306/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 610.2584 - val_loss: 676.0743 - lr: 0.0010\n",
            "Epoch 6307/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 609.8593 - val_loss: 671.9385 - lr: 0.0010\n",
            "Epoch 6308/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 611.1467 - val_loss: 663.9472 - lr: 0.0010\n",
            "Epoch 6309/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 609.5287 - val_loss: 672.2396 - lr: 0.0010\n",
            "Epoch 6310/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 609.1642 - val_loss: 681.4245 - lr: 0.0010\n",
            "Epoch 6311/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 608.9348 - val_loss: 684.3087 - lr: 0.0010\n",
            "Epoch 6312/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 609.4650 - val_loss: 690.4392 - lr: 0.0010\n",
            "Epoch 6313/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 609.1071 - val_loss: 686.1006 - lr: 0.0010\n",
            "Epoch 6314/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 606.1740 - val_loss: 664.1926 - lr: 0.0010\n",
            "Epoch 6315/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 608.6227 - val_loss: 644.2712 - lr: 0.0010\n",
            "Epoch 6316/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 608.6025 - val_loss: 642.7988 - lr: 0.0010\n",
            "Epoch 6317/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 607.7775 - val_loss: 652.3372 - lr: 0.0010\n",
            "Epoch 6318/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 606.2978 - val_loss: 663.4998 - lr: 0.0010\n",
            "Epoch 6319/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 606.1703 - val_loss: 684.1770 - lr: 0.0010\n",
            "Epoch 6320/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 606.4948 - val_loss: 693.8344 - lr: 0.0010\n",
            "Epoch 6321/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 606.7068 - val_loss: 682.5226 - lr: 0.0010\n",
            "Epoch 6322/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 604.9136 - val_loss: 678.0996 - lr: 0.0010\n",
            "Epoch 6323/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 604.3382 - val_loss: 672.7565 - lr: 0.0010\n",
            "Epoch 6324/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 603.9975 - val_loss: 668.3597 - lr: 0.0010\n",
            "Epoch 6325/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 603.8448 - val_loss: 670.7775 - lr: 0.0010\n",
            "Epoch 6326/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 603.3660 - val_loss: 669.7072 - lr: 0.0010\n",
            "Epoch 6327/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 603.7511 - val_loss: 663.9141 - lr: 0.0010\n",
            "Epoch 6328/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 603.0684 - val_loss: 666.7449 - lr: 0.0010\n",
            "Epoch 6329/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 602.6508 - val_loss: 666.2711 - lr: 0.0010\n",
            "Epoch 6330/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 602.2542 - val_loss: 663.6556 - lr: 0.0010\n",
            "Epoch 6331/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 601.9456 - val_loss: 660.7730 - lr: 0.0010\n",
            "Epoch 6332/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 601.5608 - val_loss: 662.7805 - lr: 0.0010\n",
            "Epoch 6333/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 601.4121 - val_loss: 663.1099 - lr: 0.0010\n",
            "Epoch 6334/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 600.4871 - val_loss: 670.3885 - lr: 0.0010\n",
            "Epoch 6335/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 600.7512 - val_loss: 674.5747 - lr: 0.0010\n",
            "Epoch 6336/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 600.5812 - val_loss: 674.6689 - lr: 0.0010\n",
            "Epoch 6337/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 599.7864 - val_loss: 667.6211 - lr: 0.0010\n",
            "Epoch 6338/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 599.7905 - val_loss: 664.6635 - lr: 0.0010\n",
            "Epoch 6339/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 599.1577 - val_loss: 654.2239 - lr: 0.0010\n",
            "Epoch 6340/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 599.7074 - val_loss: 648.3619 - lr: 0.0010\n",
            "Epoch 6341/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 598.4748 - val_loss: 655.4256 - lr: 0.0010\n",
            "Epoch 6342/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 598.9207 - val_loss: 668.6006 - lr: 0.0010\n",
            "Epoch 6343/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 597.9102 - val_loss: 667.4631 - lr: 0.0010\n",
            "Epoch 6344/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 597.8093 - val_loss: 665.6091 - lr: 0.0010\n",
            "Epoch 6345/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 596.9944 - val_loss: 669.0803 - lr: 0.0010\n",
            "Epoch 6346/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 596.6260 - val_loss: 668.4750 - lr: 0.0010\n",
            "Epoch 6347/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 596.6592 - val_loss: 661.8265 - lr: 0.0010\n",
            "Epoch 6348/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 597.3622 - val_loss: 650.6082 - lr: 0.0010\n",
            "Epoch 6349/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 595.9769 - val_loss: 649.9343 - lr: 0.0010\n",
            "Epoch 6350/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 595.7137 - val_loss: 647.6714 - lr: 0.0010\n",
            "Epoch 6351/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 596.9277 - val_loss: 662.8575 - lr: 0.0010\n",
            "Epoch 6352/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 594.7994 - val_loss: 660.6711 - lr: 0.0010\n",
            "Epoch 6353/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 595.3331 - val_loss: 670.6749 - lr: 0.0010\n",
            "Epoch 6354/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 594.9056 - val_loss: 660.1702 - lr: 0.0010\n",
            "Epoch 6355/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 593.9911 - val_loss: 656.2000 - lr: 0.0010\n",
            "Epoch 6356/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 595.1134 - val_loss: 668.0260 - lr: 0.0010\n",
            "Epoch 6357/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 594.2778 - val_loss: 670.9050 - lr: 0.0010\n",
            "Epoch 6358/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 593.6161 - val_loss: 656.2020 - lr: 0.0010\n",
            "Epoch 6359/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 592.9407 - val_loss: 650.3862 - lr: 0.0010\n",
            "Epoch 6360/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 592.5499 - val_loss: 650.9857 - lr: 0.0010\n",
            "Epoch 6361/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 592.6190 - val_loss: 646.5857 - lr: 0.0010\n",
            "Epoch 6362/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 591.9265 - val_loss: 646.5247 - lr: 0.0010\n",
            "Epoch 6363/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 591.6847 - val_loss: 652.1275 - lr: 0.0010\n",
            "Epoch 6364/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 591.1885 - val_loss: 651.7102 - lr: 0.0010\n",
            "Epoch 6365/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 590.8749 - val_loss: 654.4230 - lr: 0.0010\n",
            "Epoch 6366/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 592.6038 - val_loss: 668.1718 - lr: 0.0010\n",
            "Epoch 6367/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 590.4631 - val_loss: 665.0724 - lr: 0.0010\n",
            "Epoch 6368/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 589.8636 - val_loss: 655.5623 - lr: 0.0010\n",
            "Epoch 6369/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 589.7649 - val_loss: 652.4872 - lr: 0.0010\n",
            "Epoch 6370/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 590.2767 - val_loss: 660.4120 - lr: 0.0010\n",
            "Epoch 6371/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 588.9588 - val_loss: 651.8470 - lr: 0.0010\n",
            "Epoch 6372/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 589.1731 - val_loss: 644.0701 - lr: 0.0010\n",
            "Epoch 6373/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 589.1141 - val_loss: 644.1285 - lr: 0.0010\n",
            "Epoch 6374/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 588.4548 - val_loss: 647.9362 - lr: 0.0010\n",
            "Epoch 6375/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 588.4153 - val_loss: 653.0210 - lr: 0.0010\n",
            "Epoch 6376/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 588.2720 - val_loss: 650.3923 - lr: 0.0010\n",
            "Epoch 6377/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 587.3920 - val_loss: 648.0159 - lr: 0.0010\n",
            "Epoch 6378/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 587.4772 - val_loss: 650.1658 - lr: 0.0010\n",
            "Epoch 6379/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 587.1790 - val_loss: 653.5411 - lr: 0.0010\n",
            "Epoch 6380/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 586.6641 - val_loss: 652.2363 - lr: 0.0010\n",
            "Epoch 6381/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 586.9916 - val_loss: 646.9296 - lr: 0.0010\n",
            "Epoch 6382/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 586.6223 - val_loss: 648.6086 - lr: 0.0010\n",
            "Epoch 6383/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 585.9313 - val_loss: 644.3088 - lr: 0.0010\n",
            "Epoch 6384/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 585.8901 - val_loss: 645.1154 - lr: 0.0010\n",
            "Epoch 6385/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 585.7800 - val_loss: 653.3826 - lr: 0.0010\n",
            "Epoch 6386/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 585.7421 - val_loss: 650.3000 - lr: 0.0010\n",
            "Epoch 6387/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 585.0009 - val_loss: 652.9039 - lr: 0.0010\n",
            "Epoch 6388/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 584.5496 - val_loss: 657.7610 - lr: 0.0010\n",
            "Epoch 6389/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 584.6292 - val_loss: 660.0652 - lr: 0.0010\n",
            "Epoch 6390/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 589.1794 - val_loss: 673.3852 - lr: 0.0010\n",
            "Epoch 6391/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 585.4791 - val_loss: 651.1313 - lr: 0.0010\n",
            "Epoch 6392/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 585.0677 - val_loss: 638.8159 - lr: 0.0010\n",
            "Epoch 6393/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 583.6550 - val_loss: 641.0233 - lr: 0.0010\n",
            "Epoch 6394/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 584.0043 - val_loss: 653.8369 - lr: 0.0010\n",
            "Epoch 6395/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 583.3785 - val_loss: 651.8824 - lr: 0.0010\n",
            "Epoch 6396/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 582.6853 - val_loss: 647.7823 - lr: 0.0010\n",
            "Epoch 6397/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 582.5501 - val_loss: 647.0936 - lr: 0.0010\n",
            "Epoch 6398/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 582.4377 - val_loss: 651.1193 - lr: 0.0010\n",
            "Epoch 6399/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 581.7771 - val_loss: 652.4792 - lr: 0.0010\n",
            "Epoch 6400/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 582.1406 - val_loss: 655.5724 - lr: 0.0010\n",
            "Epoch 6401/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 581.1433 - val_loss: 647.4700 - lr: 0.0010\n",
            "Epoch 6402/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 581.5084 - val_loss: 641.3586 - lr: 0.0010\n",
            "Epoch 6403/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 581.8070 - val_loss: 638.1909 - lr: 0.0010\n",
            "Epoch 6404/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 581.0963 - val_loss: 645.4885 - lr: 0.0010\n",
            "Epoch 6405/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 580.6167 - val_loss: 641.9905 - lr: 0.0010\n",
            "Epoch 6406/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 580.5757 - val_loss: 639.3752 - lr: 0.0010\n",
            "Epoch 6407/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 580.6465 - val_loss: 638.3552 - lr: 0.0010\n",
            "Epoch 6408/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 580.0750 - val_loss: 638.5505 - lr: 0.0010\n",
            "Epoch 6409/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 579.3184 - val_loss: 630.1086 - lr: 0.0010\n",
            "Epoch 6410/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 580.0948 - val_loss: 629.7070 - lr: 0.0010\n",
            "Epoch 6411/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 579.1123 - val_loss: 628.8518 - lr: 0.0010\n",
            "Epoch 6412/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 578.7910 - val_loss: 635.3450 - lr: 0.0010\n",
            "Epoch 6413/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 578.3732 - val_loss: 639.8479 - lr: 0.0010\n",
            "Epoch 6414/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 578.1613 - val_loss: 639.6008 - lr: 0.0010\n",
            "Epoch 6415/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 578.8835 - val_loss: 633.0475 - lr: 0.0010\n",
            "Epoch 6416/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 577.6268 - val_loss: 637.1167 - lr: 0.0010\n",
            "Epoch 6417/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 577.7429 - val_loss: 634.5797 - lr: 0.0010\n",
            "Epoch 6418/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 578.5950 - val_loss: 647.8542 - lr: 0.0010\n",
            "Epoch 6419/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 577.3753 - val_loss: 652.1300 - lr: 0.0010\n",
            "Epoch 6420/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 577.3542 - val_loss: 648.4228 - lr: 0.0010\n",
            "Epoch 6421/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 576.7829 - val_loss: 635.1126 - lr: 0.0010\n",
            "Epoch 6422/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 575.8122 - val_loss: 632.8768 - lr: 0.0010\n",
            "Epoch 6423/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 576.1295 - val_loss: 634.8611 - lr: 0.0010\n",
            "Epoch 6424/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 576.0491 - val_loss: 639.8788 - lr: 0.0010\n",
            "Epoch 6425/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 574.9232 - val_loss: 636.9866 - lr: 0.0010\n",
            "Epoch 6426/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 574.7688 - val_loss: 638.8291 - lr: 0.0010\n",
            "Epoch 6427/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 574.8679 - val_loss: 632.7676 - lr: 0.0010\n",
            "Epoch 6428/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 574.5967 - val_loss: 628.1935 - lr: 0.0010\n",
            "Epoch 6429/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 573.7879 - val_loss: 627.1360 - lr: 0.0010\n",
            "Epoch 6430/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 573.7148 - val_loss: 633.3154 - lr: 0.0010\n",
            "Epoch 6431/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 573.6790 - val_loss: 628.5382 - lr: 0.0010\n",
            "Epoch 6432/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 573.3788 - val_loss: 634.4426 - lr: 0.0010\n",
            "Epoch 6433/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 573.3461 - val_loss: 628.2238 - lr: 0.0010\n",
            "Epoch 6434/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 572.4139 - val_loss: 630.4019 - lr: 0.0010\n",
            "Epoch 6435/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 572.1628 - val_loss: 644.8450 - lr: 0.0010\n",
            "Epoch 6436/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 571.9611 - val_loss: 647.9163 - lr: 0.0010\n",
            "Epoch 6437/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 575.3256 - val_loss: 656.8745 - lr: 0.0010\n",
            "Epoch 6438/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 570.7420 - val_loss: 641.2905 - lr: 0.0010\n",
            "Epoch 6439/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 571.1982 - val_loss: 622.6271 - lr: 0.0010\n",
            "Epoch 6440/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 571.4579 - val_loss: 615.5965 - lr: 0.0010\n",
            "Epoch 6441/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 572.1030 - val_loss: 611.9111 - lr: 0.0010\n",
            "Epoch 6442/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 570.6160 - val_loss: 618.3760 - lr: 0.0010\n",
            "Epoch 6443/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 570.5834 - val_loss: 633.8798 - lr: 0.0010\n",
            "Epoch 6444/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 569.5552 - val_loss: 642.1967 - lr: 0.0010\n",
            "Epoch 6445/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 570.5819 - val_loss: 646.6788 - lr: 0.0010\n",
            "Epoch 6446/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 568.6909 - val_loss: 635.0323 - lr: 0.0010\n",
            "Epoch 6447/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 568.1252 - val_loss: 626.9656 - lr: 0.0010\n",
            "Epoch 6448/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 569.7761 - val_loss: 610.8271 - lr: 0.0010\n",
            "Epoch 6449/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 568.9169 - val_loss: 614.0590 - lr: 0.0010\n",
            "Epoch 6450/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 568.8873 - val_loss: 615.8798 - lr: 0.0010\n",
            "Epoch 6451/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 568.2291 - val_loss: 636.4316 - lr: 0.0010\n",
            "Epoch 6452/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 569.2025 - val_loss: 656.3060 - lr: 0.0010\n",
            "Epoch 6453/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 568.0603 - val_loss: 660.3997 - lr: 0.0010\n",
            "Epoch 6454/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 567.9927 - val_loss: 653.7560 - lr: 0.0010\n",
            "Epoch 6455/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 567.2860 - val_loss: 641.6898 - lr: 0.0010\n",
            "Epoch 6456/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 566.1780 - val_loss: 641.2781 - lr: 0.0010\n",
            "Epoch 6457/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 566.1949 - val_loss: 632.4364 - lr: 0.0010\n",
            "Epoch 6458/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 566.1426 - val_loss: 634.0483 - lr: 0.0010\n",
            "Epoch 6459/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 565.0883 - val_loss: 627.4006 - lr: 0.0010\n",
            "Epoch 6460/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 565.6898 - val_loss: 620.4058 - lr: 0.0010\n",
            "Epoch 6461/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 565.1849 - val_loss: 618.9385 - lr: 0.0010\n",
            "Epoch 6462/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 564.4633 - val_loss: 625.1440 - lr: 0.0010\n",
            "Epoch 6463/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 564.4139 - val_loss: 627.9645 - lr: 0.0010\n",
            "Epoch 6464/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 563.9193 - val_loss: 631.1570 - lr: 0.0010\n",
            "Epoch 6465/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 564.2031 - val_loss: 635.5679 - lr: 0.0010\n",
            "Epoch 6466/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 563.7413 - val_loss: 628.7932 - lr: 0.0010\n",
            "Epoch 6467/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 565.0264 - val_loss: 613.6477 - lr: 0.0010\n",
            "Epoch 6468/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 563.8806 - val_loss: 611.2393 - lr: 0.0010\n",
            "Epoch 6469/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 563.5258 - val_loss: 625.5800 - lr: 0.0010\n",
            "Epoch 6470/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 562.7169 - val_loss: 632.7126 - lr: 0.0010\n",
            "Epoch 6471/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 563.2298 - val_loss: 629.0727 - lr: 0.0010\n",
            "Epoch 6472/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 562.0261 - val_loss: 634.9272 - lr: 0.0010\n",
            "Epoch 6473/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 562.0685 - val_loss: 628.0649 - lr: 0.0010\n",
            "Epoch 6474/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 562.0285 - val_loss: 634.5774 - lr: 0.0010\n",
            "Epoch 6475/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 561.5710 - val_loss: 632.2296 - lr: 0.0010\n",
            "Epoch 6476/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 561.4110 - val_loss: 638.4152 - lr: 0.0010\n",
            "Epoch 6477/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 560.9152 - val_loss: 627.9568 - lr: 0.0010\n",
            "Epoch 6478/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 560.5886 - val_loss: 629.3132 - lr: 0.0010\n",
            "Epoch 6479/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 560.1873 - val_loss: 621.2953 - lr: 0.0010\n",
            "Epoch 6480/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 561.2017 - val_loss: 610.8884 - lr: 0.0010\n",
            "Epoch 6481/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 559.8381 - val_loss: 610.6004 - lr: 0.0010\n",
            "Epoch 6482/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 560.6351 - val_loss: 616.5530 - lr: 0.0010\n",
            "Epoch 6483/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 559.4193 - val_loss: 609.4758 - lr: 0.0010\n",
            "Epoch 6484/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 558.9136 - val_loss: 613.0673 - lr: 0.0010\n",
            "Epoch 6485/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 558.4221 - val_loss: 621.8105 - lr: 0.0010\n",
            "Epoch 6486/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 558.4319 - val_loss: 624.7869 - lr: 0.0010\n",
            "Epoch 6487/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 558.7155 - val_loss: 620.0150 - lr: 0.0010\n",
            "Epoch 6488/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 558.5808 - val_loss: 625.1570 - lr: 0.0010\n",
            "Epoch 6489/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 557.3171 - val_loss: 617.5999 - lr: 0.0010\n",
            "Epoch 6490/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 557.4085 - val_loss: 612.3532 - lr: 0.0010\n",
            "Epoch 6491/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 557.1848 - val_loss: 613.1755 - lr: 0.0010\n",
            "Epoch 6492/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 556.6046 - val_loss: 627.9688 - lr: 0.0010\n",
            "Epoch 6493/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 556.3820 - val_loss: 634.8551 - lr: 0.0010\n",
            "Epoch 6494/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 556.9601 - val_loss: 636.9529 - lr: 0.0010\n",
            "Epoch 6495/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 556.8938 - val_loss: 634.3409 - lr: 0.0010\n",
            "Epoch 6496/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 555.8706 - val_loss: 620.9158 - lr: 0.0010\n",
            "Epoch 6497/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 557.2023 - val_loss: 609.0257 - lr: 0.0010\n",
            "Epoch 6498/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 555.1531 - val_loss: 612.4733 - lr: 0.0010\n",
            "Epoch 6499/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 555.4620 - val_loss: 610.8287 - lr: 0.0010\n",
            "Epoch 6500/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 554.8340 - val_loss: 609.7924 - lr: 0.0010\n",
            "Epoch 6501/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 554.1137 - val_loss: 621.0538 - lr: 0.0010\n",
            "Epoch 6502/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 553.5911 - val_loss: 630.4092 - lr: 0.0010\n",
            "Epoch 6503/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 554.4549 - val_loss: 629.3849 - lr: 0.0010\n",
            "Epoch 6504/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 554.4387 - val_loss: 637.8052 - lr: 0.0010\n",
            "Epoch 6505/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 554.8001 - val_loss: 638.2393 - lr: 0.0010\n",
            "Epoch 6506/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 554.2179 - val_loss: 639.0663 - lr: 0.0010\n",
            "Epoch 6507/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 552.8973 - val_loss: 621.1851 - lr: 0.0010\n",
            "Epoch 6508/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 554.5994 - val_loss: 604.7302 - lr: 0.0010\n",
            "Epoch 6509/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 554.4537 - val_loss: 599.1780 - lr: 0.0010\n",
            "Epoch 6510/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 551.9335 - val_loss: 608.0521 - lr: 0.0010\n",
            "Epoch 6511/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 552.0233 - val_loss: 626.1767 - lr: 0.0010\n",
            "Epoch 6512/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 551.8264 - val_loss: 629.0809 - lr: 0.0010\n",
            "Epoch 6513/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 551.6873 - val_loss: 631.8353 - lr: 0.0010\n",
            "Epoch 6514/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 553.1663 - val_loss: 618.6130 - lr: 0.0010\n",
            "Epoch 6515/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 550.9443 - val_loss: 619.3666 - lr: 0.0010\n",
            "Epoch 6516/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 550.5723 - val_loss: 624.1270 - lr: 0.0010\n",
            "Epoch 6517/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 550.6172 - val_loss: 621.5317 - lr: 0.0010\n",
            "Epoch 6518/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 550.0519 - val_loss: 623.8927 - lr: 0.0010\n",
            "Epoch 6519/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 550.1064 - val_loss: 625.6573 - lr: 0.0010\n",
            "Epoch 6520/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 549.7758 - val_loss: 615.9736 - lr: 0.0010\n",
            "Epoch 6521/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 549.0562 - val_loss: 610.9913 - lr: 0.0010\n",
            "Epoch 6522/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 548.7285 - val_loss: 605.0862 - lr: 0.0010\n",
            "Epoch 6523/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 549.8845 - val_loss: 594.3585 - lr: 0.0010\n",
            "Epoch 6524/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 549.3046 - val_loss: 601.4382 - lr: 0.0010\n",
            "Epoch 6525/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 549.0745 - val_loss: 609.7018 - lr: 0.0010\n",
            "Epoch 6526/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 548.4525 - val_loss: 612.6861 - lr: 0.0010\n",
            "Epoch 6527/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 547.9531 - val_loss: 609.1682 - lr: 0.0010\n",
            "Epoch 6528/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 548.1064 - val_loss: 606.7695 - lr: 0.0010\n",
            "Epoch 6529/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 546.9963 - val_loss: 614.6531 - lr: 0.0010\n",
            "Epoch 6530/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 546.8235 - val_loss: 625.1302 - lr: 0.0010\n",
            "Epoch 6531/8000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 547.6326 - val_loss: 626.2190 - lr: 0.0010\n",
            "Epoch 6532/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 549.4834 - val_loss: 633.1368 - lr: 0.0010\n",
            "Epoch 6533/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 546.5718 - val_loss: 618.2162 - lr: 0.0010\n",
            "Epoch 6534/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 546.2836 - val_loss: 606.3257 - lr: 0.0010\n",
            "Epoch 6535/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 546.3255 - val_loss: 602.5695 - lr: 0.0010\n",
            "Epoch 6536/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 545.5812 - val_loss: 606.9848 - lr: 0.0010\n",
            "Epoch 6537/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 545.0927 - val_loss: 614.0168 - lr: 0.0010\n",
            "Epoch 6538/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 545.8029 - val_loss: 621.4045 - lr: 0.0010\n",
            "Epoch 6539/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 545.0178 - val_loss: 619.0159 - lr: 0.0010\n",
            "Epoch 6540/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 545.2388 - val_loss: 607.2595 - lr: 0.0010\n",
            "Epoch 6541/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 544.9559 - val_loss: 601.6096 - lr: 0.0010\n",
            "Epoch 6542/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 544.4594 - val_loss: 605.6063 - lr: 0.0010\n",
            "Epoch 6543/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 544.3469 - val_loss: 605.5928 - lr: 0.0010\n",
            "Epoch 6544/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 543.7366 - val_loss: 604.6155 - lr: 0.0010\n",
            "Epoch 6545/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 543.9994 - val_loss: 608.5878 - lr: 0.0010\n",
            "Epoch 6546/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 543.3877 - val_loss: 609.6467 - lr: 0.0010\n",
            "Epoch 6547/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 542.9915 - val_loss: 608.2513 - lr: 0.0010\n",
            "Epoch 6548/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 542.7657 - val_loss: 606.7191 - lr: 0.0010\n",
            "Epoch 6549/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 542.7050 - val_loss: 605.8729 - lr: 0.0010\n",
            "Epoch 6550/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 542.3778 - val_loss: 603.5157 - lr: 0.0010\n",
            "Epoch 6551/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 541.8232 - val_loss: 598.0688 - lr: 0.0010\n",
            "Epoch 6552/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 543.4291 - val_loss: 585.2374 - lr: 0.0010\n",
            "Epoch 6553/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 542.1931 - val_loss: 592.8629 - lr: 0.0010\n",
            "Epoch 6554/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 542.4155 - val_loss: 590.6208 - lr: 0.0010\n",
            "Epoch 6555/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 541.4384 - val_loss: 592.8931 - lr: 0.0010\n",
            "Epoch 6556/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 541.0442 - val_loss: 607.4105 - lr: 0.0010\n",
            "Epoch 6557/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 541.1917 - val_loss: 614.5022 - lr: 0.0010\n",
            "Epoch 6558/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 540.7407 - val_loss: 610.9639 - lr: 0.0010\n",
            "Epoch 6559/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 540.1473 - val_loss: 604.7394 - lr: 0.0010\n",
            "Epoch 6560/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 539.8202 - val_loss: 600.8088 - lr: 0.0010\n",
            "Epoch 6561/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 539.6712 - val_loss: 597.1272 - lr: 0.0010\n",
            "Epoch 6562/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 539.9776 - val_loss: 593.9207 - lr: 0.0010\n",
            "Epoch 6563/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 539.5042 - val_loss: 601.7690 - lr: 0.0010\n",
            "Epoch 6564/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 539.2023 - val_loss: 607.2347 - lr: 0.0010\n",
            "Epoch 6565/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 539.2092 - val_loss: 608.5759 - lr: 0.0010\n",
            "Epoch 6566/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 538.9313 - val_loss: 606.2380 - lr: 0.0010\n",
            "Epoch 6567/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 539.0253 - val_loss: 608.0505 - lr: 0.0010\n",
            "Epoch 6568/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 538.1586 - val_loss: 597.6119 - lr: 0.0010\n",
            "Epoch 6569/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 539.4650 - val_loss: 583.1036 - lr: 0.0010\n",
            "Epoch 6570/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 538.2974 - val_loss: 585.8998 - lr: 0.0010\n",
            "Epoch 6571/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 537.9945 - val_loss: 594.1491 - lr: 0.0010\n",
            "Epoch 6572/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 537.1135 - val_loss: 600.1411 - lr: 0.0010\n",
            "Epoch 6573/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 538.3708 - val_loss: 617.2648 - lr: 0.0010\n",
            "Epoch 6574/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 537.9799 - val_loss: 621.8476 - lr: 0.0010\n",
            "Epoch 6575/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 537.9150 - val_loss: 613.7540 - lr: 0.0010\n",
            "Epoch 6576/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 536.8207 - val_loss: 612.0496 - lr: 0.0010\n",
            "Epoch 6577/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 536.5161 - val_loss: 594.6046 - lr: 0.0010\n",
            "Epoch 6578/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 536.2566 - val_loss: 587.2123 - lr: 0.0010\n",
            "Epoch 6579/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 536.0898 - val_loss: 591.7905 - lr: 0.0010\n",
            "Epoch 6580/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 535.7874 - val_loss: 593.6059 - lr: 0.0010\n",
            "Epoch 6581/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 535.2722 - val_loss: 598.6171 - lr: 0.0010\n",
            "Epoch 6582/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 535.1356 - val_loss: 598.9869 - lr: 0.0010\n",
            "Epoch 6583/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 535.0399 - val_loss: 601.8381 - lr: 0.0010\n",
            "Epoch 6584/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 535.5789 - val_loss: 594.4514 - lr: 0.0010\n",
            "Epoch 6585/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 534.3189 - val_loss: 598.0614 - lr: 0.0010\n",
            "Epoch 6586/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 534.7312 - val_loss: 614.9634 - lr: 0.0010\n",
            "Epoch 6587/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 535.1164 - val_loss: 621.2435 - lr: 0.0010\n",
            "Epoch 6588/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 534.8425 - val_loss: 612.7780 - lr: 0.0010\n",
            "Epoch 6589/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 534.1199 - val_loss: 608.6893 - lr: 0.0010\n",
            "Epoch 6590/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 533.2574 - val_loss: 614.9403 - lr: 0.0010\n",
            "Epoch 6591/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 533.3991 - val_loss: 615.7255 - lr: 0.0010\n",
            "Epoch 6592/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 533.1916 - val_loss: 609.9099 - lr: 0.0010\n",
            "Epoch 6593/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 532.0650 - val_loss: 598.2638 - lr: 0.0010\n",
            "Epoch 6594/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 535.5215 - val_loss: 573.5498 - lr: 0.0010\n",
            "Epoch 6595/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 532.4837 - val_loss: 577.9519 - lr: 0.0010\n",
            "Epoch 6596/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 531.9465 - val_loss: 587.4871 - lr: 0.0010\n",
            "Epoch 6597/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 531.0766 - val_loss: 594.7013 - lr: 0.0010\n",
            "Epoch 6598/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 531.0020 - val_loss: 598.0916 - lr: 0.0010\n",
            "Epoch 6599/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 530.7574 - val_loss: 593.1231 - lr: 0.0010\n",
            "Epoch 6600/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 530.5515 - val_loss: 589.8718 - lr: 0.0010\n",
            "Epoch 6601/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 530.1918 - val_loss: 591.1777 - lr: 0.0010\n",
            "Epoch 6602/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 530.1331 - val_loss: 588.1650 - lr: 0.0010\n",
            "Epoch 6603/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 530.1789 - val_loss: 590.8585 - lr: 0.0010\n",
            "Epoch 6604/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 529.8176 - val_loss: 587.6710 - lr: 0.0010\n",
            "Epoch 6605/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 531.1213 - val_loss: 592.4919 - lr: 0.0010\n",
            "Epoch 6606/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 528.7467 - val_loss: 584.0272 - lr: 0.0010\n",
            "Epoch 6607/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 529.0826 - val_loss: 583.0285 - lr: 0.0010\n",
            "Epoch 6608/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 528.3268 - val_loss: 579.1583 - lr: 0.0010\n",
            "Epoch 6609/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 528.3586 - val_loss: 579.1298 - lr: 0.0010\n",
            "Epoch 6610/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 527.9725 - val_loss: 578.5218 - lr: 0.0010\n",
            "Epoch 6611/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 528.2657 - val_loss: 585.4695 - lr: 0.0010\n",
            "Epoch 6612/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 527.3633 - val_loss: 584.7225 - lr: 0.0010\n",
            "Epoch 6613/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 527.7192 - val_loss: 585.8141 - lr: 0.0010\n",
            "Epoch 6614/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 527.3177 - val_loss: 590.4587 - lr: 0.0010\n",
            "Epoch 6615/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 527.2943 - val_loss: 582.6662 - lr: 0.0010\n",
            "Epoch 6616/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 526.3625 - val_loss: 584.6392 - lr: 0.0010\n",
            "Epoch 6617/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 527.8237 - val_loss: 601.3546 - lr: 0.0010\n",
            "Epoch 6618/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 526.3989 - val_loss: 602.2288 - lr: 0.0010\n",
            "Epoch 6619/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 526.4120 - val_loss: 596.9577 - lr: 0.0010\n",
            "Epoch 6620/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 526.7646 - val_loss: 599.3472 - lr: 0.0010\n",
            "Epoch 6621/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 525.6696 - val_loss: 593.6838 - lr: 0.0010\n",
            "Epoch 6622/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 524.7694 - val_loss: 586.4380 - lr: 0.0010\n",
            "Epoch 6623/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 525.1641 - val_loss: 576.9167 - lr: 0.0010\n",
            "Epoch 6624/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 524.6115 - val_loss: 578.2152 - lr: 0.0010\n",
            "Epoch 6625/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 524.7128 - val_loss: 579.8259 - lr: 0.0010\n",
            "Epoch 6626/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 524.5360 - val_loss: 598.2457 - lr: 0.0010\n",
            "Epoch 6627/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 526.1323 - val_loss: 608.7095 - lr: 0.0010\n",
            "Epoch 6628/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 524.2014 - val_loss: 599.0508 - lr: 0.0010\n",
            "Epoch 6629/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 523.3189 - val_loss: 590.5414 - lr: 0.0010\n",
            "Epoch 6630/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 522.7639 - val_loss: 583.0173 - lr: 0.0010\n",
            "Epoch 6631/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 522.2659 - val_loss: 574.4059 - lr: 0.0010\n",
            "Epoch 6632/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 523.4507 - val_loss: 565.2114 - lr: 0.0010\n",
            "Epoch 6633/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 523.6172 - val_loss: 564.6504 - lr: 0.0010\n",
            "Epoch 6634/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 522.4916 - val_loss: 579.1898 - lr: 0.0010\n",
            "Epoch 6635/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 521.6588 - val_loss: 583.2702 - lr: 0.0010\n",
            "Epoch 6636/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 521.7933 - val_loss: 589.4150 - lr: 0.0010\n",
            "Epoch 6637/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 521.9245 - val_loss: 588.1985 - lr: 0.0010\n",
            "Epoch 6638/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 521.2263 - val_loss: 581.4013 - lr: 0.0010\n",
            "Epoch 6639/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 521.0996 - val_loss: 571.6010 - lr: 0.0010\n",
            "Epoch 6640/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 520.8114 - val_loss: 571.3312 - lr: 0.0010\n",
            "Epoch 6641/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 520.8303 - val_loss: 572.3310 - lr: 0.0010\n",
            "Epoch 6642/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 520.4553 - val_loss: 582.2145 - lr: 0.0010\n",
            "Epoch 6643/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 519.9863 - val_loss: 585.3303 - lr: 0.0010\n",
            "Epoch 6644/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 520.0496 - val_loss: 588.8508 - lr: 0.0010\n",
            "Epoch 6645/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 520.2982 - val_loss: 583.8350 - lr: 0.0010\n",
            "Epoch 6646/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 519.6563 - val_loss: 584.7083 - lr: 0.0010\n",
            "Epoch 6647/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 519.6516 - val_loss: 580.1271 - lr: 0.0010\n",
            "Epoch 6648/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 519.4348 - val_loss: 579.9146 - lr: 0.0010\n",
            "Epoch 6649/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 518.4675 - val_loss: 569.5881 - lr: 0.0010\n",
            "Epoch 6650/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 519.6140 - val_loss: 559.8502 - lr: 0.0010\n",
            "Epoch 6651/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 519.6799 - val_loss: 554.5420 - lr: 0.0010\n",
            "Epoch 6652/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 519.4399 - val_loss: 561.3044 - lr: 0.0010\n",
            "Epoch 6653/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 518.3535 - val_loss: 566.2834 - lr: 0.0010\n",
            "Epoch 6654/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 517.6555 - val_loss: 576.1805 - lr: 0.0010\n",
            "Epoch 6655/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 517.2391 - val_loss: 582.8099 - lr: 0.0010\n",
            "Epoch 6656/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 517.1835 - val_loss: 588.1658 - lr: 0.0010\n",
            "Epoch 6657/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 517.2930 - val_loss: 587.8195 - lr: 0.0010\n",
            "Epoch 6658/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 518.6872 - val_loss: 596.9633 - lr: 0.0010\n",
            "Epoch 6659/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 516.6443 - val_loss: 586.3184 - lr: 0.0010\n",
            "Epoch 6660/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 518.5161 - val_loss: 567.4002 - lr: 0.0010\n",
            "Epoch 6661/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 517.5316 - val_loss: 557.8635 - lr: 0.0010\n",
            "Epoch 6662/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 516.3186 - val_loss: 564.9689 - lr: 0.0010\n",
            "Epoch 6663/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 515.6135 - val_loss: 570.3336 - lr: 0.0010\n",
            "Epoch 6664/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 515.6218 - val_loss: 571.5187 - lr: 0.0010\n",
            "Epoch 6665/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 515.4714 - val_loss: 583.4026 - lr: 0.0010\n",
            "Epoch 6666/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 515.4376 - val_loss: 585.7759 - lr: 0.0010\n",
            "Epoch 6667/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 516.5399 - val_loss: 597.8093 - lr: 0.0010\n",
            "Epoch 6668/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 515.8386 - val_loss: 594.1249 - lr: 0.0010\n",
            "Epoch 6669/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 515.4370 - val_loss: 587.7159 - lr: 0.0010\n",
            "Epoch 6670/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 514.7009 - val_loss: 573.8712 - lr: 0.0010\n",
            "Epoch 6671/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 514.0374 - val_loss: 562.3448 - lr: 0.0010\n",
            "Epoch 6672/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 514.1873 - val_loss: 562.4182 - lr: 0.0010\n",
            "Epoch 6673/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 514.3317 - val_loss: 563.6367 - lr: 0.0010\n",
            "Epoch 6674/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 513.7258 - val_loss: 565.3760 - lr: 0.0010\n",
            "Epoch 6675/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 513.6637 - val_loss: 572.9720 - lr: 0.0010\n",
            "Epoch 6676/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 513.1857 - val_loss: 572.4727 - lr: 0.0010\n",
            "Epoch 6677/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 513.4799 - val_loss: 577.4954 - lr: 0.0010\n",
            "Epoch 6678/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 512.9249 - val_loss: 576.6965 - lr: 0.0010\n",
            "Epoch 6679/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 513.1219 - val_loss: 580.4624 - lr: 0.0010\n",
            "Epoch 6680/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 513.1745 - val_loss: 580.2190 - lr: 0.0010\n",
            "Epoch 6681/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 513.5660 - val_loss: 566.4401 - lr: 0.0010\n",
            "Epoch 6682/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 511.9456 - val_loss: 572.9174 - lr: 0.0010\n",
            "Epoch 6683/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 511.9541 - val_loss: 575.2799 - lr: 0.0010\n",
            "Epoch 6684/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 511.5192 - val_loss: 578.3564 - lr: 0.0010\n",
            "Epoch 6685/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 511.4030 - val_loss: 577.3568 - lr: 0.0010\n",
            "Epoch 6686/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 511.1900 - val_loss: 570.1399 - lr: 0.0010\n",
            "Epoch 6687/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 511.0762 - val_loss: 565.7122 - lr: 0.0010\n",
            "Epoch 6688/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 510.7154 - val_loss: 567.0732 - lr: 0.0010\n",
            "Epoch 6689/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 510.6372 - val_loss: 567.6122 - lr: 0.0010\n",
            "Epoch 6690/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 512.2425 - val_loss: 574.0228 - lr: 0.0010\n",
            "Epoch 6691/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 509.3424 - val_loss: 559.9304 - lr: 0.0010\n",
            "Epoch 6692/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 509.7349 - val_loss: 549.8675 - lr: 0.0010\n",
            "Epoch 6693/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 510.5027 - val_loss: 543.3986 - lr: 0.0010\n",
            "Epoch 6694/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 510.9212 - val_loss: 542.7038 - lr: 0.0010\n",
            "Epoch 6695/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 510.1877 - val_loss: 547.1882 - lr: 0.0010\n",
            "Epoch 6696/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 509.3977 - val_loss: 554.7621 - lr: 0.0010\n",
            "Epoch 6697/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 508.5905 - val_loss: 570.7712 - lr: 0.0010\n",
            "Epoch 6698/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 509.2233 - val_loss: 582.7504 - lr: 0.0010\n",
            "Epoch 6699/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 508.8496 - val_loss: 591.9569 - lr: 0.0010\n",
            "Epoch 6700/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 509.2549 - val_loss: 593.2145 - lr: 0.0010\n",
            "Epoch 6701/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 509.2863 - val_loss: 589.1202 - lr: 0.0010\n",
            "Epoch 6702/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 508.2596 - val_loss: 573.4003 - lr: 0.0010\n",
            "Epoch 6703/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 507.6205 - val_loss: 560.9106 - lr: 0.0010\n",
            "Epoch 6704/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 508.1418 - val_loss: 560.6204 - lr: 0.0010\n",
            "Epoch 6705/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 507.6288 - val_loss: 560.7216 - lr: 0.0010\n",
            "Epoch 6706/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 507.1878 - val_loss: 558.9752 - lr: 0.0010\n",
            "Epoch 6707/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 507.3873 - val_loss: 564.2689 - lr: 0.0010\n",
            "Epoch 6708/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 506.8711 - val_loss: 562.4843 - lr: 0.0010\n",
            "Epoch 6709/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 506.3896 - val_loss: 566.3613 - lr: 0.0010\n",
            "Epoch 6710/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 506.0197 - val_loss: 571.1921 - lr: 0.0010\n",
            "Epoch 6711/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 506.1507 - val_loss: 573.7607 - lr: 0.0010\n",
            "Epoch 6712/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 506.0114 - val_loss: 574.4337 - lr: 0.0010\n",
            "Epoch 6713/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 506.2946 - val_loss: 580.6855 - lr: 0.0010\n",
            "Epoch 6714/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 505.8904 - val_loss: 575.9756 - lr: 0.0010\n",
            "Epoch 6715/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 505.8838 - val_loss: 579.8658 - lr: 0.0010\n",
            "Epoch 6716/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 505.3767 - val_loss: 568.9091 - lr: 0.0010\n",
            "Epoch 6717/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 505.0027 - val_loss: 564.4208 - lr: 0.0010\n",
            "Epoch 6718/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 505.1556 - val_loss: 563.1061 - lr: 0.0010\n",
            "Epoch 6719/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 504.4706 - val_loss: 564.2962 - lr: 0.0010\n",
            "Epoch 6720/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 504.0931 - val_loss: 561.1401 - lr: 0.0010\n",
            "Epoch 6721/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 504.4857 - val_loss: 561.1144 - lr: 0.0010\n",
            "Epoch 6722/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 504.3828 - val_loss: 557.0878 - lr: 0.0010\n",
            "Epoch 6723/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 505.2119 - val_loss: 568.3149 - lr: 0.0010\n",
            "Epoch 6724/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 503.6828 - val_loss: 567.9456 - lr: 0.0010\n",
            "Epoch 6725/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 504.4874 - val_loss: 558.5392 - lr: 0.0010\n",
            "Epoch 6726/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 502.9369 - val_loss: 563.7092 - lr: 0.0010\n",
            "Epoch 6727/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 502.9048 - val_loss: 564.5435 - lr: 0.0010\n",
            "Epoch 6728/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 504.1523 - val_loss: 562.9988 - lr: 0.0010\n",
            "Epoch 6729/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 502.4358 - val_loss: 574.1780 - lr: 0.0010\n",
            "Epoch 6730/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 502.3993 - val_loss: 573.8193 - lr: 0.0010\n",
            "Epoch 6731/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 503.1032 - val_loss: 576.6342 - lr: 0.0010\n",
            "Epoch 6732/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 502.0025 - val_loss: 571.2667 - lr: 0.0010\n",
            "Epoch 6733/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 502.9648 - val_loss: 558.9197 - lr: 0.0010\n",
            "Epoch 6734/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 501.5938 - val_loss: 555.5954 - lr: 0.0010\n",
            "Epoch 6735/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 500.9403 - val_loss: 559.1780 - lr: 0.0010\n",
            "Epoch 6736/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 500.6359 - val_loss: 562.7011 - lr: 0.0010\n",
            "Epoch 6737/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 500.5362 - val_loss: 561.6752 - lr: 0.0010\n",
            "Epoch 6738/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 500.3629 - val_loss: 566.4610 - lr: 0.0010\n",
            "Epoch 6739/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 499.7508 - val_loss: 567.3104 - lr: 0.0010\n",
            "Epoch 6740/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 499.8722 - val_loss: 561.3278 - lr: 0.0010\n",
            "Epoch 6741/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 498.4485 - val_loss: 562.1315 - lr: 0.0010\n",
            "Epoch 6742/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 497.9952 - val_loss: 565.7723 - lr: 0.0010\n",
            "Epoch 6743/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 497.4905 - val_loss: 561.5522 - lr: 0.0010\n",
            "Epoch 6744/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 497.0825 - val_loss: 551.3623 - lr: 0.0010\n",
            "Epoch 6745/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 496.9624 - val_loss: 546.0759 - lr: 0.0010\n",
            "Epoch 6746/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 496.1376 - val_loss: 546.8278 - lr: 0.0010\n",
            "Epoch 6747/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 495.8970 - val_loss: 547.8840 - lr: 0.0010\n",
            "Epoch 6748/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 495.1318 - val_loss: 549.1440 - lr: 0.0010\n",
            "Epoch 6749/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 494.6904 - val_loss: 551.8560 - lr: 0.0010\n",
            "Epoch 6750/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 494.9362 - val_loss: 557.6482 - lr: 0.0010\n",
            "Epoch 6751/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 494.9473 - val_loss: 554.0435 - lr: 0.0010\n",
            "Epoch 6752/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 493.7908 - val_loss: 571.9355 - lr: 0.0010\n",
            "Epoch 6753/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 492.9797 - val_loss: 575.8353 - lr: 0.0010\n",
            "Epoch 6754/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 492.5399 - val_loss: 571.7621 - lr: 0.0010\n",
            "Epoch 6755/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 492.3459 - val_loss: 561.4230 - lr: 0.0010\n",
            "Epoch 6756/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 491.2338 - val_loss: 554.0480 - lr: 0.0010\n",
            "Epoch 6757/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 490.5967 - val_loss: 554.5950 - lr: 0.0010\n",
            "Epoch 6758/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 490.2849 - val_loss: 544.3320 - lr: 0.0010\n",
            "Epoch 6759/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 489.7125 - val_loss: 541.2302 - lr: 0.0010\n",
            "Epoch 6760/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 488.9294 - val_loss: 547.8842 - lr: 0.0010\n",
            "Epoch 6761/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 488.6554 - val_loss: 557.2151 - lr: 0.0010\n",
            "Epoch 6762/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 488.1428 - val_loss: 554.0417 - lr: 0.0010\n",
            "Epoch 6763/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 487.3765 - val_loss: 559.8348 - lr: 0.0010\n",
            "Epoch 6764/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 487.5075 - val_loss: 561.7709 - lr: 0.0010\n",
            "Epoch 6765/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 486.4722 - val_loss: 556.8699 - lr: 0.0010\n",
            "Epoch 6766/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 486.1705 - val_loss: 550.0032 - lr: 0.0010\n",
            "Epoch 6767/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 485.5269 - val_loss: 552.1733 - lr: 0.0010\n",
            "Epoch 6768/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 485.6496 - val_loss: 549.9651 - lr: 0.0010\n",
            "Epoch 6769/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 484.1525 - val_loss: 539.4048 - lr: 0.0010\n",
            "Epoch 6770/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 484.4195 - val_loss: 529.8000 - lr: 0.0010\n",
            "Epoch 6771/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 484.2346 - val_loss: 528.6839 - lr: 0.0010\n",
            "Epoch 6772/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 483.4334 - val_loss: 533.2425 - lr: 0.0010\n",
            "Epoch 6773/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 482.6402 - val_loss: 541.8514 - lr: 0.0010\n",
            "Epoch 6774/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 482.1726 - val_loss: 549.5306 - lr: 0.0010\n",
            "Epoch 6775/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 481.8422 - val_loss: 551.5842 - lr: 0.0010\n",
            "Epoch 6776/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 481.7366 - val_loss: 547.0173 - lr: 0.0010\n",
            "Epoch 6777/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 480.7285 - val_loss: 542.4731 - lr: 0.0010\n",
            "Epoch 6778/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 480.2543 - val_loss: 540.7788 - lr: 0.0010\n",
            "Epoch 6779/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 480.5250 - val_loss: 536.8931 - lr: 0.0010\n",
            "Epoch 6780/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 480.2448 - val_loss: 545.5178 - lr: 0.0010\n",
            "Epoch 6781/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 479.1552 - val_loss: 541.0936 - lr: 0.0010\n",
            "Epoch 6782/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 478.8084 - val_loss: 541.1402 - lr: 0.0010\n",
            "Epoch 6783/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 478.1271 - val_loss: 540.3427 - lr: 0.0010\n",
            "Epoch 6784/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 479.3786 - val_loss: 549.7513 - lr: 0.0010\n",
            "Epoch 6785/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 477.2964 - val_loss: 544.9233 - lr: 0.0010\n",
            "Epoch 6786/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 477.7878 - val_loss: 533.0481 - lr: 0.0010\n",
            "Epoch 6787/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 476.3908 - val_loss: 527.1165 - lr: 0.0010\n",
            "Epoch 6788/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 476.6144 - val_loss: 526.9236 - lr: 0.0010\n",
            "Epoch 6789/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 475.7272 - val_loss: 519.2054 - lr: 0.0010\n",
            "Epoch 6790/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 476.1180 - val_loss: 517.7531 - lr: 0.0010\n",
            "Epoch 6791/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 475.0898 - val_loss: 525.2490 - lr: 0.0010\n",
            "Epoch 6792/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 474.1964 - val_loss: 536.5457 - lr: 0.0010\n",
            "Epoch 6793/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 474.2747 - val_loss: 547.7128 - lr: 0.0010\n",
            "Epoch 6794/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 473.2660 - val_loss: 547.9892 - lr: 0.0010\n",
            "Epoch 6795/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 473.2043 - val_loss: 544.9530 - lr: 0.0010\n",
            "Epoch 6796/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 473.5379 - val_loss: 535.5740 - lr: 0.0010\n",
            "Epoch 6797/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 471.8350 - val_loss: 537.4549 - lr: 0.0010\n",
            "Epoch 6798/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 471.8312 - val_loss: 536.4388 - lr: 0.0010\n",
            "Epoch 6799/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 474.9085 - val_loss: 550.5754 - lr: 0.0010\n",
            "Epoch 6800/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 470.8084 - val_loss: 539.9675 - lr: 0.0010\n",
            "Epoch 6801/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 470.2234 - val_loss: 531.5706 - lr: 0.0010\n",
            "Epoch 6802/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 470.6351 - val_loss: 521.7248 - lr: 0.0010\n",
            "Epoch 6803/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 470.1682 - val_loss: 526.5320 - lr: 0.0010\n",
            "Epoch 6804/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 469.3140 - val_loss: 527.8987 - lr: 0.0010\n",
            "Epoch 6805/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 469.1794 - val_loss: 522.4017 - lr: 0.0010\n",
            "Epoch 6806/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 468.7759 - val_loss: 518.7526 - lr: 0.0010\n",
            "Epoch 6807/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 468.5066 - val_loss: 518.2157 - lr: 0.0010\n",
            "Epoch 6808/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 468.4125 - val_loss: 516.5494 - lr: 0.0010\n",
            "Epoch 6809/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 469.0414 - val_loss: 516.7003 - lr: 0.0010\n",
            "Epoch 6810/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 466.9169 - val_loss: 528.4889 - lr: 0.0010\n",
            "Epoch 6811/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 466.5548 - val_loss: 532.3063 - lr: 0.0010\n",
            "Epoch 6812/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 465.6302 - val_loss: 541.0086 - lr: 0.0010\n",
            "Epoch 6813/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 466.4240 - val_loss: 552.2205 - lr: 0.0010\n",
            "Epoch 6814/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 466.7116 - val_loss: 555.1047 - lr: 0.0010\n",
            "Epoch 6815/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 466.6094 - val_loss: 559.3030 - lr: 0.0010\n",
            "Epoch 6816/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 465.9557 - val_loss: 550.0745 - lr: 0.0010\n",
            "Epoch 6817/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 464.5278 - val_loss: 543.4736 - lr: 0.0010\n",
            "Epoch 6818/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 463.7782 - val_loss: 535.9452 - lr: 0.0010\n",
            "Epoch 6819/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 463.6301 - val_loss: 534.7198 - lr: 0.0010\n",
            "Epoch 6820/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 463.5317 - val_loss: 524.0839 - lr: 0.0010\n",
            "Epoch 6821/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 463.1938 - val_loss: 523.5837 - lr: 0.0010\n",
            "Epoch 6822/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 462.6080 - val_loss: 528.5723 - lr: 0.0010\n",
            "Epoch 6823/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 461.6332 - val_loss: 528.2422 - lr: 0.0010\n",
            "Epoch 6824/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 461.4665 - val_loss: 529.5593 - lr: 0.0010\n",
            "Epoch 6825/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 461.6776 - val_loss: 527.2110 - lr: 0.0010\n",
            "Epoch 6826/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 462.3244 - val_loss: 546.0905 - lr: 0.0010\n",
            "Epoch 6827/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 460.5950 - val_loss: 548.0282 - lr: 0.0010\n",
            "Epoch 6828/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 460.4192 - val_loss: 549.2430 - lr: 0.0010\n",
            "Epoch 6829/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 460.3758 - val_loss: 550.7897 - lr: 0.0010\n",
            "Epoch 6830/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 459.3925 - val_loss: 539.9692 - lr: 0.0010\n",
            "Epoch 6831/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 458.9473 - val_loss: 525.4011 - lr: 0.0010\n",
            "Epoch 6832/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 458.0598 - val_loss: 518.8647 - lr: 0.0010\n",
            "Epoch 6833/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 458.0605 - val_loss: 510.7760 - lr: 0.0010\n",
            "Epoch 6834/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 458.8684 - val_loss: 505.3924 - lr: 0.0010\n",
            "Epoch 6835/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 458.7994 - val_loss: 503.2775 - lr: 0.0010\n",
            "Epoch 6836/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 458.9903 - val_loss: 502.4930 - lr: 0.0010\n",
            "Epoch 6837/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 457.7954 - val_loss: 516.3164 - lr: 0.0010\n",
            "Epoch 6838/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 455.5056 - val_loss: 530.3769 - lr: 0.0010\n",
            "Epoch 6839/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 455.3038 - val_loss: 540.9851 - lr: 0.0010\n",
            "Epoch 6840/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 458.1262 - val_loss: 554.5874 - lr: 0.0010\n",
            "Epoch 6841/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 457.3043 - val_loss: 542.1190 - lr: 0.0010\n",
            "Epoch 6842/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 456.3434 - val_loss: 527.4017 - lr: 0.0010\n",
            "Epoch 6843/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 454.9670 - val_loss: 522.0342 - lr: 0.0010\n",
            "Epoch 6844/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 454.0405 - val_loss: 523.4616 - lr: 0.0010\n",
            "Epoch 6845/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 453.6912 - val_loss: 527.0227 - lr: 0.0010\n",
            "Epoch 6846/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 454.1198 - val_loss: 521.8986 - lr: 0.0010\n",
            "Epoch 6847/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 454.5864 - val_loss: 530.1215 - lr: 0.0010\n",
            "Epoch 6848/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 452.5146 - val_loss: 521.7239 - lr: 0.0010\n",
            "Epoch 6849/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 452.6400 - val_loss: 519.6796 - lr: 0.0010\n",
            "Epoch 6850/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 451.9776 - val_loss: 510.4180 - lr: 0.0010\n",
            "Epoch 6851/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 453.5368 - val_loss: 499.0825 - lr: 0.0010\n",
            "Epoch 6852/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 452.6378 - val_loss: 502.4364 - lr: 0.0010\n",
            "Epoch 6853/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 452.2326 - val_loss: 514.6393 - lr: 0.0010\n",
            "Epoch 6854/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 450.9275 - val_loss: 514.4343 - lr: 0.0010\n",
            "Epoch 6855/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 450.3964 - val_loss: 516.7181 - lr: 0.0010\n",
            "Epoch 6856/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 450.0256 - val_loss: 518.0682 - lr: 0.0010\n",
            "Epoch 6857/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 451.1600 - val_loss: 527.1435 - lr: 0.0010\n",
            "Epoch 6858/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 449.6202 - val_loss: 524.5610 - lr: 0.0010\n",
            "Epoch 6859/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 448.8863 - val_loss: 518.5133 - lr: 0.0010\n",
            "Epoch 6860/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 448.6580 - val_loss: 513.4954 - lr: 0.0010\n",
            "Epoch 6861/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 448.3784 - val_loss: 513.5150 - lr: 0.0010\n",
            "Epoch 6862/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 447.7483 - val_loss: 512.3753 - lr: 0.0010\n",
            "Epoch 6863/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 448.2319 - val_loss: 504.6409 - lr: 0.0010\n",
            "Epoch 6864/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 447.4079 - val_loss: 515.2751 - lr: 0.0010\n",
            "Epoch 6865/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 446.4111 - val_loss: 517.6095 - lr: 0.0010\n",
            "Epoch 6866/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 445.6864 - val_loss: 514.3843 - lr: 0.0010\n",
            "Epoch 6867/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 445.3498 - val_loss: 511.0332 - lr: 0.0010\n",
            "Epoch 6868/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 446.1846 - val_loss: 501.2755 - lr: 0.0010\n",
            "Epoch 6869/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 444.7445 - val_loss: 497.8690 - lr: 0.0010\n",
            "Epoch 6870/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 444.1641 - val_loss: 500.9570 - lr: 0.0010\n",
            "Epoch 6871/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 444.2802 - val_loss: 506.3221 - lr: 0.0010\n",
            "Epoch 6872/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 442.8701 - val_loss: 507.2912 - lr: 0.0010\n",
            "Epoch 6873/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 441.6712 - val_loss: 509.1283 - lr: 0.0010\n",
            "Epoch 6874/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 441.0555 - val_loss: 508.3510 - lr: 0.0010\n",
            "Epoch 6875/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 440.1935 - val_loss: 505.6372 - lr: 0.0010\n",
            "Epoch 6876/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 439.5060 - val_loss: 499.6441 - lr: 0.0010\n",
            "Epoch 6877/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 439.1447 - val_loss: 496.3032 - lr: 0.0010\n",
            "Epoch 6878/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 438.6224 - val_loss: 494.2934 - lr: 0.0010\n",
            "Epoch 6879/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 438.4962 - val_loss: 492.6389 - lr: 0.0010\n",
            "Epoch 6880/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 437.4927 - val_loss: 496.9009 - lr: 0.0010\n",
            "Epoch 6881/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 436.4392 - val_loss: 508.0481 - lr: 0.0010\n",
            "Epoch 6882/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 436.1353 - val_loss: 514.2910 - lr: 0.0010\n",
            "Epoch 6883/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 436.3260 - val_loss: 515.0240 - lr: 0.0010\n",
            "Epoch 6884/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 435.1523 - val_loss: 518.1604 - lr: 0.0010\n",
            "Epoch 6885/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 434.6410 - val_loss: 514.4511 - lr: 0.0010\n",
            "Epoch 6886/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 433.8477 - val_loss: 506.6487 - lr: 0.0010\n",
            "Epoch 6887/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 433.0688 - val_loss: 493.4286 - lr: 0.0010\n",
            "Epoch 6888/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 432.4714 - val_loss: 487.8211 - lr: 0.0010\n",
            "Epoch 6889/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 432.6271 - val_loss: 488.0104 - lr: 0.0010\n",
            "Epoch 6890/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 431.9793 - val_loss: 490.0002 - lr: 0.0010\n",
            "Epoch 6891/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 431.3092 - val_loss: 492.4053 - lr: 0.0010\n",
            "Epoch 6892/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 431.0980 - val_loss: 495.7303 - lr: 0.0010\n",
            "Epoch 6893/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 430.9586 - val_loss: 486.4359 - lr: 0.0010\n",
            "Epoch 6894/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 429.9771 - val_loss: 483.0877 - lr: 0.0010\n",
            "Epoch 6895/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 429.3185 - val_loss: 485.7731 - lr: 0.0010\n",
            "Epoch 6896/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 429.0656 - val_loss: 493.7072 - lr: 0.0010\n",
            "Epoch 6897/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 427.6996 - val_loss: 497.5138 - lr: 0.0010\n",
            "Epoch 6898/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 427.2263 - val_loss: 503.2483 - lr: 0.0010\n",
            "Epoch 6899/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 427.0658 - val_loss: 507.1902 - lr: 0.0010\n",
            "Epoch 6900/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 426.6044 - val_loss: 504.6916 - lr: 0.0010\n",
            "Epoch 6901/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 425.9664 - val_loss: 505.8473 - lr: 0.0010\n",
            "Epoch 6902/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 425.8191 - val_loss: 504.9433 - lr: 0.0010\n",
            "Epoch 6903/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 425.3294 - val_loss: 495.9978 - lr: 0.0010\n",
            "Epoch 6904/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 424.1685 - val_loss: 495.1126 - lr: 0.0010\n",
            "Epoch 6905/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 423.4003 - val_loss: 489.2127 - lr: 0.0010\n",
            "Epoch 6906/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 423.5599 - val_loss: 486.3984 - lr: 0.0010\n",
            "Epoch 6907/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 423.5726 - val_loss: 498.7869 - lr: 0.0010\n",
            "Epoch 6908/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 422.4374 - val_loss: 503.8260 - lr: 0.0010\n",
            "Epoch 6909/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 421.7590 - val_loss: 499.4571 - lr: 0.0010\n",
            "Epoch 6910/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 420.9242 - val_loss: 495.2916 - lr: 0.0010\n",
            "Epoch 6911/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 420.5538 - val_loss: 489.6240 - lr: 0.0010\n",
            "Epoch 6912/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 419.7837 - val_loss: 490.4966 - lr: 0.0010\n",
            "Epoch 6913/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 419.3103 - val_loss: 486.8881 - lr: 0.0010\n",
            "Epoch 6914/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 419.0629 - val_loss: 488.7758 - lr: 0.0010\n",
            "Epoch 6915/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 418.6115 - val_loss: 490.1631 - lr: 0.0010\n",
            "Epoch 6916/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 417.8032 - val_loss: 490.6608 - lr: 0.0010\n",
            "Epoch 6917/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 417.5345 - val_loss: 488.8010 - lr: 0.0010\n",
            "Epoch 6918/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 417.0946 - val_loss: 496.0399 - lr: 0.0010\n",
            "Epoch 6919/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 416.6853 - val_loss: 493.2930 - lr: 0.0010\n",
            "Epoch 6920/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 416.0101 - val_loss: 493.7002 - lr: 0.0010\n",
            "Epoch 6921/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 415.8055 - val_loss: 495.4118 - lr: 0.0010\n",
            "Epoch 6922/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 416.2047 - val_loss: 488.4759 - lr: 0.0010\n",
            "Epoch 6923/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 414.4098 - val_loss: 493.4314 - lr: 0.0010\n",
            "Epoch 6924/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 414.1165 - val_loss: 498.2428 - lr: 0.0010\n",
            "Epoch 6925/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 415.0624 - val_loss: 505.1530 - lr: 0.0010\n",
            "Epoch 6926/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 413.6688 - val_loss: 498.7491 - lr: 0.0010\n",
            "Epoch 6927/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 412.7587 - val_loss: 480.1959 - lr: 0.0010\n",
            "Epoch 6928/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 412.2593 - val_loss: 470.1723 - lr: 0.0010\n",
            "Epoch 6929/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 411.7809 - val_loss: 473.1805 - lr: 0.0010\n",
            "Epoch 6930/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 411.7082 - val_loss: 472.2416 - lr: 0.0010\n",
            "Epoch 6931/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 410.9583 - val_loss: 476.3688 - lr: 0.0010\n",
            "Epoch 6932/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 411.3888 - val_loss: 471.7182 - lr: 0.0010\n",
            "Epoch 6933/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 409.5754 - val_loss: 480.7619 - lr: 0.0010\n",
            "Epoch 6934/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 408.8112 - val_loss: 486.5565 - lr: 0.0010\n",
            "Epoch 6935/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 408.4388 - val_loss: 495.6111 - lr: 0.0010\n",
            "Epoch 6936/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 408.9337 - val_loss: 497.7549 - lr: 0.0010\n",
            "Epoch 6937/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 408.4794 - val_loss: 490.5204 - lr: 0.0010\n",
            "Epoch 6938/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 407.6432 - val_loss: 485.0944 - lr: 0.0010\n",
            "Epoch 6939/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 407.4167 - val_loss: 481.8059 - lr: 0.0010\n",
            "Epoch 6940/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 406.2664 - val_loss: 477.0743 - lr: 0.0010\n",
            "Epoch 6941/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 406.4247 - val_loss: 468.7570 - lr: 0.0010\n",
            "Epoch 6942/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 405.6220 - val_loss: 466.3519 - lr: 0.0010\n",
            "Epoch 6943/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 405.2782 - val_loss: 466.7040 - lr: 0.0010\n",
            "Epoch 6944/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 404.4372 - val_loss: 474.2145 - lr: 0.0010\n",
            "Epoch 6945/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 403.9207 - val_loss: 476.7389 - lr: 0.0010\n",
            "Epoch 6946/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 403.5878 - val_loss: 482.8518 - lr: 0.0010\n",
            "Epoch 6947/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 403.6055 - val_loss: 485.8063 - lr: 0.0010\n",
            "Epoch 6948/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 403.1539 - val_loss: 484.1046 - lr: 0.0010\n",
            "Epoch 6949/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 403.7907 - val_loss: 475.7621 - lr: 0.0010\n",
            "Epoch 6950/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 401.8545 - val_loss: 481.9225 - lr: 0.0010\n",
            "Epoch 6951/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 402.2308 - val_loss: 486.9846 - lr: 0.0010\n",
            "Epoch 6952/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 401.4598 - val_loss: 480.0052 - lr: 0.0010\n",
            "Epoch 6953/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 400.5097 - val_loss: 470.5087 - lr: 0.0010\n",
            "Epoch 6954/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 404.0049 - val_loss: 452.9518 - lr: 0.0010\n",
            "Epoch 6955/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 400.5547 - val_loss: 457.0682 - lr: 0.0010\n",
            "Epoch 6956/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 399.6491 - val_loss: 461.2984 - lr: 0.0010\n",
            "Epoch 6957/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 399.3341 - val_loss: 464.6639 - lr: 0.0010\n",
            "Epoch 6958/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 399.3860 - val_loss: 467.8680 - lr: 0.0010\n",
            "Epoch 6959/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 398.1466 - val_loss: 463.5415 - lr: 0.0010\n",
            "Epoch 6960/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 397.7313 - val_loss: 461.0724 - lr: 0.0010\n",
            "Epoch 6961/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 397.7168 - val_loss: 462.4445 - lr: 0.0010\n",
            "Epoch 6962/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 399.2408 - val_loss: 451.1867 - lr: 0.0010\n",
            "Epoch 6963/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 397.7629 - val_loss: 458.5439 - lr: 0.0010\n",
            "Epoch 6964/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 396.3068 - val_loss: 453.4898 - lr: 0.0010\n",
            "Epoch 6965/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 395.8310 - val_loss: 451.5423 - lr: 0.0010\n",
            "Epoch 6966/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 396.2469 - val_loss: 452.8861 - lr: 0.0010\n",
            "Epoch 6967/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 395.6944 - val_loss: 449.1935 - lr: 0.0010\n",
            "Epoch 6968/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 396.5590 - val_loss: 439.6183 - lr: 0.0010\n",
            "Epoch 6969/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 394.9589 - val_loss: 443.8434 - lr: 0.0010\n",
            "Epoch 6970/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 393.8180 - val_loss: 449.3763 - lr: 0.0010\n",
            "Epoch 6971/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 393.2097 - val_loss: 453.3063 - lr: 0.0010\n",
            "Epoch 6972/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 392.2958 - val_loss: 457.1416 - lr: 0.0010\n",
            "Epoch 6973/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 391.9885 - val_loss: 464.6966 - lr: 0.0010\n",
            "Epoch 6974/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 391.5713 - val_loss: 463.2997 - lr: 0.0010\n",
            "Epoch 6975/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 391.0604 - val_loss: 467.1227 - lr: 0.0010\n",
            "Epoch 6976/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 390.6707 - val_loss: 462.6696 - lr: 0.0010\n",
            "Epoch 6977/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 389.7095 - val_loss: 460.1844 - lr: 0.0010\n",
            "Epoch 6978/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 389.1754 - val_loss: 462.1037 - lr: 0.0010\n",
            "Epoch 6979/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 388.6971 - val_loss: 468.0723 - lr: 0.0010\n",
            "Epoch 6980/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 388.5068 - val_loss: 471.2978 - lr: 0.0010\n",
            "Epoch 6981/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 388.1661 - val_loss: 462.3969 - lr: 0.0010\n",
            "Epoch 6982/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 386.9850 - val_loss: 456.4488 - lr: 0.0010\n",
            "Epoch 6983/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 386.2047 - val_loss: 457.2952 - lr: 0.0010\n",
            "Epoch 6984/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 385.5848 - val_loss: 450.8265 - lr: 0.0010\n",
            "Epoch 6985/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 385.4655 - val_loss: 441.2257 - lr: 0.0010\n",
            "Epoch 6986/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 384.8268 - val_loss: 436.0775 - lr: 0.0010\n",
            "Epoch 6987/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 385.1857 - val_loss: 442.1349 - lr: 0.0010\n",
            "Epoch 6988/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 383.7041 - val_loss: 444.8000 - lr: 0.0010\n",
            "Epoch 6989/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 382.6404 - val_loss: 439.6096 - lr: 0.0010\n",
            "Epoch 6990/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 382.4901 - val_loss: 441.5384 - lr: 0.0010\n",
            "Epoch 6991/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 381.6996 - val_loss: 435.3356 - lr: 0.0010\n",
            "Epoch 6992/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 380.9257 - val_loss: 432.1671 - lr: 0.0010\n",
            "Epoch 6993/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 383.1647 - val_loss: 423.6129 - lr: 0.0010\n",
            "Epoch 6994/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 380.2336 - val_loss: 427.6063 - lr: 0.0010\n",
            "Epoch 6995/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 379.0100 - val_loss: 432.7049 - lr: 0.0010\n",
            "Epoch 6996/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 378.4656 - val_loss: 439.8515 - lr: 0.0010\n",
            "Epoch 6997/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 377.5930 - val_loss: 442.3181 - lr: 0.0010\n",
            "Epoch 6998/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 377.1214 - val_loss: 444.3898 - lr: 0.0010\n",
            "Epoch 6999/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 376.8838 - val_loss: 448.5313 - lr: 0.0010\n",
            "Epoch 7000/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 376.3885 - val_loss: 449.7996 - lr: 0.0010\n",
            "Epoch 7001/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 375.6113 - val_loss: 447.4844 - lr: 0.0010\n",
            "Epoch 7002/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 375.6485 - val_loss: 438.5323 - lr: 0.0010\n",
            "Epoch 7003/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 373.9448 - val_loss: 440.7758 - lr: 0.0010\n",
            "Epoch 7004/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 373.2890 - val_loss: 438.5755 - lr: 0.0010\n",
            "Epoch 7005/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 372.6670 - val_loss: 434.1609 - lr: 0.0010\n",
            "Epoch 7006/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 372.0877 - val_loss: 434.0775 - lr: 0.0010\n",
            "Epoch 7007/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 372.0613 - val_loss: 442.5919 - lr: 0.0010\n",
            "Epoch 7008/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 371.3650 - val_loss: 447.6571 - lr: 0.0010\n",
            "Epoch 7009/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 370.3685 - val_loss: 440.4247 - lr: 0.0010\n",
            "Epoch 7010/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 369.7562 - val_loss: 435.5292 - lr: 0.0010\n",
            "Epoch 7011/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 369.0800 - val_loss: 430.7317 - lr: 0.0010\n",
            "Epoch 7012/8000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 368.7403 - val_loss: 432.1322 - lr: 0.0010\n",
            "Epoch 7013/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 368.0221 - val_loss: 428.9310 - lr: 0.0010\n",
            "Epoch 7014/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 367.2189 - val_loss: 434.1398 - lr: 0.0010\n",
            "Epoch 7015/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 366.7751 - val_loss: 438.2992 - lr: 0.0010\n",
            "Epoch 7016/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 366.5768 - val_loss: 435.0003 - lr: 0.0010\n",
            "Epoch 7017/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 366.0113 - val_loss: 435.9998 - lr: 0.0010\n",
            "Epoch 7018/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 364.9503 - val_loss: 432.4919 - lr: 0.0010\n",
            "Epoch 7019/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 364.5889 - val_loss: 430.6088 - lr: 0.0010\n",
            "Epoch 7020/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 364.1147 - val_loss: 417.3912 - lr: 0.0010\n",
            "Epoch 7021/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 363.4075 - val_loss: 415.5238 - lr: 0.0010\n",
            "Epoch 7022/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 363.9084 - val_loss: 411.9608 - lr: 0.0010\n",
            "Epoch 7023/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 362.6843 - val_loss: 411.7407 - lr: 0.0010\n",
            "Epoch 7024/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 361.9331 - val_loss: 421.6801 - lr: 0.0010\n",
            "Epoch 7025/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 361.2647 - val_loss: 421.1483 - lr: 0.0010\n",
            "Epoch 7026/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 360.4686 - val_loss: 423.8814 - lr: 0.0010\n",
            "Epoch 7027/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 359.7853 - val_loss: 426.7419 - lr: 0.0010\n",
            "Epoch 7028/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 360.5626 - val_loss: 431.8583 - lr: 0.0010\n",
            "Epoch 7029/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 358.8437 - val_loss: 427.4938 - lr: 0.0010\n",
            "Epoch 7030/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 358.0081 - val_loss: 416.6041 - lr: 0.0010\n",
            "Epoch 7031/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 358.1295 - val_loss: 408.5687 - lr: 0.0010\n",
            "Epoch 7032/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 357.4569 - val_loss: 405.8190 - lr: 0.0010\n",
            "Epoch 7033/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 357.0132 - val_loss: 409.9679 - lr: 0.0010\n",
            "Epoch 7034/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 355.7529 - val_loss: 421.7648 - lr: 0.0010\n",
            "Epoch 7035/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 356.6114 - val_loss: 437.4034 - lr: 0.0010\n",
            "Epoch 7036/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 356.1527 - val_loss: 440.4409 - lr: 0.0010\n",
            "Epoch 7037/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 355.1115 - val_loss: 431.9916 - lr: 0.0010\n",
            "Epoch 7038/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 354.0744 - val_loss: 422.9987 - lr: 0.0010\n",
            "Epoch 7039/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 353.5702 - val_loss: 415.2741 - lr: 0.0010\n",
            "Epoch 7040/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 353.2135 - val_loss: 418.0630 - lr: 0.0010\n",
            "Epoch 7041/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 352.1954 - val_loss: 411.7881 - lr: 0.0010\n",
            "Epoch 7042/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 351.8053 - val_loss: 407.2302 - lr: 0.0010\n",
            "Epoch 7043/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 351.9634 - val_loss: 403.0067 - lr: 0.0010\n",
            "Epoch 7044/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 350.9905 - val_loss: 405.2114 - lr: 0.0010\n",
            "Epoch 7045/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 350.4171 - val_loss: 411.0052 - lr: 0.0010\n",
            "Epoch 7046/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 349.4950 - val_loss: 408.3268 - lr: 0.0010\n",
            "Epoch 7047/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 348.9669 - val_loss: 409.7472 - lr: 0.0010\n",
            "Epoch 7048/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 348.3732 - val_loss: 411.5631 - lr: 0.0010\n",
            "Epoch 7049/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 348.5131 - val_loss: 418.1736 - lr: 0.0010\n",
            "Epoch 7050/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 347.3564 - val_loss: 411.7997 - lr: 0.0010\n",
            "Epoch 7051/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 346.7326 - val_loss: 408.7717 - lr: 0.0010\n",
            "Epoch 7052/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 346.1390 - val_loss: 405.7697 - lr: 0.0010\n",
            "Epoch 7053/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 345.8156 - val_loss: 404.0988 - lr: 0.0010\n",
            "Epoch 7054/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 345.7057 - val_loss: 403.1396 - lr: 0.0010\n",
            "Epoch 7055/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 345.0921 - val_loss: 397.0246 - lr: 0.0010\n",
            "Epoch 7056/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 344.8678 - val_loss: 400.0933 - lr: 0.0010\n",
            "Epoch 7057/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 343.6525 - val_loss: 402.5306 - lr: 0.0010\n",
            "Epoch 7058/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 343.3777 - val_loss: 402.6551 - lr: 0.0010\n",
            "Epoch 7059/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 342.5057 - val_loss: 405.7666 - lr: 0.0010\n",
            "Epoch 7060/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 341.9670 - val_loss: 406.1813 - lr: 0.0010\n",
            "Epoch 7061/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 341.5315 - val_loss: 404.7033 - lr: 0.0010\n",
            "Epoch 7062/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 341.0062 - val_loss: 405.4135 - lr: 0.0010\n",
            "Epoch 7063/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 340.7592 - val_loss: 402.6070 - lr: 0.0010\n",
            "Epoch 7064/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 340.3143 - val_loss: 406.2546 - lr: 0.0010\n",
            "Epoch 7065/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 339.6497 - val_loss: 407.7321 - lr: 0.0010\n",
            "Epoch 7066/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 339.2760 - val_loss: 406.5321 - lr: 0.0010\n",
            "Epoch 7067/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 338.2223 - val_loss: 399.1958 - lr: 0.0010\n",
            "Epoch 7068/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 337.9113 - val_loss: 393.0768 - lr: 0.0010\n",
            "Epoch 7069/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 338.0177 - val_loss: 389.7316 - lr: 0.0010\n",
            "Epoch 7070/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 337.6774 - val_loss: 396.9890 - lr: 0.0010\n",
            "Epoch 7071/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 336.1797 - val_loss: 399.1857 - lr: 0.0010\n",
            "Epoch 7072/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 335.7963 - val_loss: 399.8073 - lr: 0.0010\n",
            "Epoch 7073/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 335.1925 - val_loss: 401.4117 - lr: 0.0010\n",
            "Epoch 7074/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 334.9564 - val_loss: 397.9792 - lr: 0.0010\n",
            "Epoch 7075/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 334.6866 - val_loss: 403.9119 - lr: 0.0010\n",
            "Epoch 7076/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 334.0216 - val_loss: 403.1253 - lr: 0.0010\n",
            "Epoch 7077/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 333.3704 - val_loss: 405.0591 - lr: 0.0010\n",
            "Epoch 7078/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 332.8815 - val_loss: 404.2301 - lr: 0.0010\n",
            "Epoch 7079/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 332.2929 - val_loss: 402.2491 - lr: 0.0010\n",
            "Epoch 7080/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 331.7339 - val_loss: 402.7357 - lr: 0.0010\n",
            "Epoch 7081/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 331.4528 - val_loss: 400.2964 - lr: 0.0010\n",
            "Epoch 7082/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 330.5999 - val_loss: 398.3831 - lr: 0.0010\n",
            "Epoch 7083/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 330.0793 - val_loss: 397.0779 - lr: 0.0010\n",
            "Epoch 7084/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 329.8371 - val_loss: 396.7094 - lr: 0.0010\n",
            "Epoch 7085/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 330.0075 - val_loss: 405.7848 - lr: 0.0010\n",
            "Epoch 7086/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 328.7520 - val_loss: 398.4586 - lr: 0.0010\n",
            "Epoch 7087/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 327.9828 - val_loss: 395.9845 - lr: 0.0010\n",
            "Epoch 7088/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 327.7004 - val_loss: 393.9868 - lr: 0.0010\n",
            "Epoch 7089/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 326.8231 - val_loss: 391.5491 - lr: 0.0010\n",
            "Epoch 7090/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 326.4248 - val_loss: 397.4340 - lr: 0.0010\n",
            "Epoch 7091/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 325.6952 - val_loss: 397.1320 - lr: 0.0010\n",
            "Epoch 7092/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 325.0674 - val_loss: 402.1935 - lr: 0.0010\n",
            "Epoch 7093/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 324.6541 - val_loss: 402.2343 - lr: 0.0010\n",
            "Epoch 7094/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 324.2046 - val_loss: 399.9679 - lr: 0.0010\n",
            "Epoch 7095/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 323.7103 - val_loss: 391.1006 - lr: 0.0010\n",
            "Epoch 7096/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 322.7839 - val_loss: 388.1012 - lr: 0.0010\n",
            "Epoch 7097/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 322.3173 - val_loss: 387.8288 - lr: 0.0010\n",
            "Epoch 7098/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 321.6843 - val_loss: 385.7221 - lr: 0.0010\n",
            "Epoch 7099/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 321.0019 - val_loss: 385.8681 - lr: 0.0010\n",
            "Epoch 7100/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 320.4024 - val_loss: 383.2881 - lr: 0.0010\n",
            "Epoch 7101/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 320.4128 - val_loss: 379.7281 - lr: 0.0010\n",
            "Epoch 7102/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 320.2904 - val_loss: 386.0562 - lr: 0.0010\n",
            "Epoch 7103/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 319.4095 - val_loss: 387.5658 - lr: 0.0010\n",
            "Epoch 7104/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 318.3755 - val_loss: 384.4976 - lr: 0.0010\n",
            "Epoch 7105/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 317.7941 - val_loss: 381.8820 - lr: 0.0010\n",
            "Epoch 7106/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 317.4532 - val_loss: 380.6067 - lr: 0.0010\n",
            "Epoch 7107/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 316.7918 - val_loss: 381.0438 - lr: 0.0010\n",
            "Epoch 7108/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 316.0572 - val_loss: 389.3759 - lr: 0.0010\n",
            "Epoch 7109/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 315.8002 - val_loss: 390.9513 - lr: 0.0010\n",
            "Epoch 7110/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 315.3618 - val_loss: 389.0906 - lr: 0.0010\n",
            "Epoch 7111/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 314.8160 - val_loss: 388.6334 - lr: 0.0010\n",
            "Epoch 7112/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 314.4500 - val_loss: 380.6044 - lr: 0.0010\n",
            "Epoch 7113/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 313.7211 - val_loss: 381.9804 - lr: 0.0010\n",
            "Epoch 7114/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 313.0377 - val_loss: 382.0179 - lr: 0.0010\n",
            "Epoch 7115/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 312.4979 - val_loss: 386.6502 - lr: 0.0010\n",
            "Epoch 7116/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 312.0252 - val_loss: 386.2855 - lr: 0.0010\n",
            "Epoch 7117/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 311.6159 - val_loss: 384.3088 - lr: 0.0010\n",
            "Epoch 7118/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 311.1152 - val_loss: 374.6440 - lr: 0.0010\n",
            "Epoch 7119/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 310.7285 - val_loss: 370.2806 - lr: 0.0010\n",
            "Epoch 7120/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 310.2511 - val_loss: 370.0919 - lr: 0.0010\n",
            "Epoch 7121/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 309.6586 - val_loss: 375.7869 - lr: 0.0010\n",
            "Epoch 7122/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 310.1938 - val_loss: 382.0516 - lr: 0.0010\n",
            "Epoch 7123/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 308.7965 - val_loss: 375.1646 - lr: 0.0010\n",
            "Epoch 7124/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 307.9565 - val_loss: 372.3386 - lr: 0.0010\n",
            "Epoch 7125/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 307.6969 - val_loss: 367.5024 - lr: 0.0010\n",
            "Epoch 7126/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 307.4771 - val_loss: 363.7249 - lr: 0.0010\n",
            "Epoch 7127/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 306.7584 - val_loss: 367.6881 - lr: 0.0010\n",
            "Epoch 7128/8000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 306.1864 - val_loss: 371.8498 - lr: 0.0010\n",
            "Epoch 7129/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 305.4287 - val_loss: 373.2390 - lr: 0.0010\n",
            "Epoch 7130/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 305.5592 - val_loss: 375.8325 - lr: 0.0010\n",
            "Epoch 7131/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 304.7152 - val_loss: 373.5980 - lr: 0.0010\n",
            "Epoch 7132/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 305.8373 - val_loss: 364.7106 - lr: 0.0010\n",
            "Epoch 7133/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 303.7293 - val_loss: 365.4796 - lr: 0.0010\n",
            "Epoch 7134/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 303.3544 - val_loss: 367.0867 - lr: 0.0010\n",
            "Epoch 7135/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 302.4332 - val_loss: 371.9734 - lr: 0.0010\n",
            "Epoch 7136/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 302.5711 - val_loss: 377.3016 - lr: 0.0010\n",
            "Epoch 7137/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 302.1308 - val_loss: 380.3578 - lr: 0.0010\n",
            "Epoch 7138/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 301.7432 - val_loss: 378.5815 - lr: 0.0010\n",
            "Epoch 7139/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 300.7268 - val_loss: 372.2194 - lr: 0.0010\n",
            "Epoch 7140/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 300.9887 - val_loss: 365.8349 - lr: 0.0010\n",
            "Epoch 7141/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 299.8354 - val_loss: 369.6351 - lr: 0.0010\n",
            "Epoch 7142/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 299.3160 - val_loss: 371.9955 - lr: 0.0010\n",
            "Epoch 7143/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 299.2480 - val_loss: 373.0961 - lr: 0.0010\n",
            "Epoch 7144/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 298.3015 - val_loss: 370.8769 - lr: 0.0010\n",
            "Epoch 7145/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 298.7653 - val_loss: 371.3250 - lr: 0.0010\n",
            "Epoch 7146/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 297.2313 - val_loss: 366.8469 - lr: 0.0010\n",
            "Epoch 7147/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 296.8724 - val_loss: 361.9373 - lr: 0.0010\n",
            "Epoch 7148/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 296.6570 - val_loss: 359.3647 - lr: 0.0010\n",
            "Epoch 7149/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 296.1818 - val_loss: 363.7024 - lr: 0.0010\n",
            "Epoch 7150/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 295.3579 - val_loss: 366.1167 - lr: 0.0010\n",
            "Epoch 7151/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 295.5098 - val_loss: 370.2335 - lr: 0.0010\n",
            "Epoch 7152/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 294.5065 - val_loss: 363.0146 - lr: 0.0010\n",
            "Epoch 7153/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 294.5975 - val_loss: 357.9028 - lr: 0.0010\n",
            "Epoch 7154/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 293.6664 - val_loss: 362.1563 - lr: 0.0010\n",
            "Epoch 7155/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 293.2320 - val_loss: 362.5164 - lr: 0.0010\n",
            "Epoch 7156/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 292.5039 - val_loss: 360.6986 - lr: 0.0010\n",
            "Epoch 7157/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 291.9667 - val_loss: 357.6344 - lr: 0.0010\n",
            "Epoch 7158/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 292.0184 - val_loss: 357.9120 - lr: 0.0010\n",
            "Epoch 7159/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 291.7071 - val_loss: 353.5598 - lr: 0.0010\n",
            "Epoch 7160/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 291.4506 - val_loss: 351.8875 - lr: 0.0010\n",
            "Epoch 7161/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 290.4509 - val_loss: 356.3514 - lr: 0.0010\n",
            "Epoch 7162/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 291.5624 - val_loss: 363.8663 - lr: 0.0010\n",
            "Epoch 7163/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 289.1975 - val_loss: 358.9900 - lr: 0.0010\n",
            "Epoch 7164/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 289.2835 - val_loss: 352.0946 - lr: 0.0010\n",
            "Epoch 7165/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 288.3930 - val_loss: 349.9489 - lr: 0.0010\n",
            "Epoch 7166/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 288.2531 - val_loss: 351.5406 - lr: 0.0010\n",
            "Epoch 7167/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 287.4304 - val_loss: 352.0743 - lr: 0.0010\n",
            "Epoch 7168/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 287.0488 - val_loss: 353.1266 - lr: 0.0010\n",
            "Epoch 7169/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 286.6504 - val_loss: 356.8834 - lr: 0.0010\n",
            "Epoch 7170/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 285.8918 - val_loss: 353.9828 - lr: 0.0010\n",
            "Epoch 7171/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 285.8490 - val_loss: 348.7827 - lr: 0.0010\n",
            "Epoch 7172/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 285.0772 - val_loss: 346.1347 - lr: 0.0010\n",
            "Epoch 7173/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 285.5248 - val_loss: 350.8372 - lr: 0.0010\n",
            "Epoch 7174/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 284.4428 - val_loss: 353.4111 - lr: 0.0010\n",
            "Epoch 7175/8000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 283.3678 - val_loss: 350.7049 - lr: 0.0010\n",
            "Epoch 7176/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 282.9894 - val_loss: 350.1434 - lr: 0.0010\n",
            "Epoch 7177/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 282.7782 - val_loss: 351.6854 - lr: 0.0010\n",
            "Epoch 7178/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 281.9803 - val_loss: 348.1900 - lr: 0.0010\n",
            "Epoch 7179/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 281.8311 - val_loss: 348.2005 - lr: 0.0010\n",
            "Epoch 7180/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 281.3026 - val_loss: 355.1721 - lr: 0.0010\n",
            "Epoch 7181/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 281.3903 - val_loss: 360.3363 - lr: 0.0010\n",
            "Epoch 7182/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 281.0555 - val_loss: 362.2063 - lr: 0.0010\n",
            "Epoch 7183/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 281.2824 - val_loss: 348.0965 - lr: 0.0010\n",
            "Epoch 7184/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 279.2703 - val_loss: 348.5174 - lr: 0.0010\n",
            "Epoch 7185/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 278.8426 - val_loss: 350.0211 - lr: 0.0010\n",
            "Epoch 7186/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 279.1212 - val_loss: 357.4003 - lr: 0.0010\n",
            "Epoch 7187/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 278.2346 - val_loss: 356.2494 - lr: 0.0010\n",
            "Epoch 7188/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 278.7585 - val_loss: 343.2440 - lr: 0.0010\n",
            "Epoch 7189/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 277.0024 - val_loss: 343.3626 - lr: 0.0010\n",
            "Epoch 7190/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 276.5051 - val_loss: 345.9313 - lr: 0.0010\n",
            "Epoch 7191/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 275.9486 - val_loss: 349.8323 - lr: 0.0010\n",
            "Epoch 7192/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 275.2523 - val_loss: 353.4312 - lr: 0.0010\n",
            "Epoch 7193/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 276.1810 - val_loss: 359.2189 - lr: 0.0010\n",
            "Epoch 7194/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 275.4284 - val_loss: 354.3522 - lr: 0.0010\n",
            "Epoch 7195/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 274.1722 - val_loss: 354.2030 - lr: 0.0010\n",
            "Epoch 7196/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 273.8758 - val_loss: 356.1920 - lr: 0.0010\n",
            "Epoch 7197/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 273.3870 - val_loss: 354.4554 - lr: 0.0010\n",
            "Epoch 7198/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 273.4589 - val_loss: 347.1276 - lr: 0.0010\n",
            "Epoch 7199/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 272.4196 - val_loss: 345.5851 - lr: 0.0010\n",
            "Epoch 7200/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 271.9260 - val_loss: 345.7169 - lr: 0.0010\n",
            "Epoch 7201/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 271.9908 - val_loss: 351.0948 - lr: 0.0010\n",
            "Epoch 7202/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 271.0544 - val_loss: 350.1070 - lr: 0.0010\n",
            "Epoch 7203/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 270.4811 - val_loss: 345.7682 - lr: 0.0010\n",
            "Epoch 7204/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 270.0207 - val_loss: 342.1671 - lr: 0.0010\n",
            "Epoch 7205/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 270.0174 - val_loss: 339.3390 - lr: 0.0010\n",
            "Epoch 7206/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 269.9298 - val_loss: 338.5416 - lr: 0.0010\n",
            "Epoch 7207/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 268.7790 - val_loss: 343.1801 - lr: 0.0010\n",
            "Epoch 7208/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 268.2077 - val_loss: 350.6127 - lr: 0.0010\n",
            "Epoch 7209/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 268.4809 - val_loss: 355.4035 - lr: 0.0010\n",
            "Epoch 7210/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 267.8651 - val_loss: 348.7349 - lr: 0.0010\n",
            "Epoch 7211/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 267.0581 - val_loss: 344.5162 - lr: 0.0010\n",
            "Epoch 7212/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 266.7358 - val_loss: 342.8215 - lr: 0.0010\n",
            "Epoch 7213/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 266.4412 - val_loss: 340.5058 - lr: 0.0010\n",
            "Epoch 7214/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 265.7231 - val_loss: 343.6877 - lr: 0.0010\n",
            "Epoch 7215/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 265.3007 - val_loss: 347.8764 - lr: 0.0010\n",
            "Epoch 7216/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 265.0209 - val_loss: 348.6873 - lr: 0.0010\n",
            "Epoch 7217/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 264.7888 - val_loss: 347.5756 - lr: 0.0010\n",
            "Epoch 7218/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 264.3156 - val_loss: 343.6692 - lr: 0.0010\n",
            "Epoch 7219/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 263.9568 - val_loss: 342.6289 - lr: 0.0010\n",
            "Epoch 7220/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 263.3322 - val_loss: 337.9995 - lr: 0.0010\n",
            "Epoch 7221/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 263.3844 - val_loss: 338.5195 - lr: 0.0010\n",
            "Epoch 7222/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 263.0604 - val_loss: 331.1327 - lr: 0.0010\n",
            "Epoch 7223/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 262.7354 - val_loss: 333.5854 - lr: 0.0010\n",
            "Epoch 7224/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 261.9601 - val_loss: 333.2458 - lr: 0.0010\n",
            "Epoch 7225/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 261.4520 - val_loss: 328.3999 - lr: 0.0010\n",
            "Epoch 7226/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 261.3597 - val_loss: 325.4730 - lr: 0.0010\n",
            "Epoch 7227/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 261.0769 - val_loss: 327.4747 - lr: 0.0010\n",
            "Epoch 7228/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 260.4504 - val_loss: 334.7784 - lr: 0.0010\n",
            "Epoch 7229/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 259.6803 - val_loss: 337.5743 - lr: 0.0010\n",
            "Epoch 7230/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 259.2930 - val_loss: 341.5097 - lr: 0.0010\n",
            "Epoch 7231/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 259.9069 - val_loss: 345.8496 - lr: 0.0010\n",
            "Epoch 7232/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 258.5640 - val_loss: 337.5697 - lr: 0.0010\n",
            "Epoch 7233/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 258.0507 - val_loss: 331.1526 - lr: 0.0010\n",
            "Epoch 7234/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 258.3012 - val_loss: 326.9818 - lr: 0.0010\n",
            "Epoch 7235/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 258.5421 - val_loss: 333.1891 - lr: 0.0010\n",
            "Epoch 7236/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 257.7486 - val_loss: 327.0504 - lr: 0.0010\n",
            "Epoch 7237/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 256.5156 - val_loss: 331.0248 - lr: 0.0010\n",
            "Epoch 7238/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 255.8373 - val_loss: 333.3625 - lr: 0.0010\n",
            "Epoch 7239/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 255.7295 - val_loss: 336.3805 - lr: 0.0010\n",
            "Epoch 7240/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 255.3236 - val_loss: 336.0577 - lr: 0.0010\n",
            "Epoch 7241/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 255.6090 - val_loss: 326.5669 - lr: 0.0010\n",
            "Epoch 7242/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 254.3183 - val_loss: 326.9128 - lr: 0.0010\n",
            "Epoch 7243/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 254.2038 - val_loss: 328.6074 - lr: 0.0010\n",
            "Epoch 7244/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 253.3601 - val_loss: 328.8905 - lr: 0.0010\n",
            "Epoch 7245/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 253.1699 - val_loss: 327.3231 - lr: 0.0010\n",
            "Epoch 7246/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 252.9859 - val_loss: 332.5605 - lr: 0.0010\n",
            "Epoch 7247/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 252.0508 - val_loss: 334.5081 - lr: 0.0010\n",
            "Epoch 7248/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 251.6725 - val_loss: 329.6578 - lr: 0.0010\n",
            "Epoch 7249/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 251.1367 - val_loss: 327.9360 - lr: 0.0010\n",
            "Epoch 7250/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 250.5835 - val_loss: 322.5807 - lr: 0.0010\n",
            "Epoch 7251/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 250.5970 - val_loss: 319.8118 - lr: 0.0010\n",
            "Epoch 7252/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 250.3991 - val_loss: 321.5565 - lr: 0.0010\n",
            "Epoch 7253/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 249.6385 - val_loss: 323.0670 - lr: 0.0010\n",
            "Epoch 7254/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 250.2723 - val_loss: 328.5552 - lr: 0.0010\n",
            "Epoch 7255/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 248.7974 - val_loss: 328.8361 - lr: 0.0010\n",
            "Epoch 7256/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 248.5099 - val_loss: 322.2571 - lr: 0.0010\n",
            "Epoch 7257/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 247.8672 - val_loss: 321.3859 - lr: 0.0010\n",
            "Epoch 7258/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 247.4577 - val_loss: 322.4715 - lr: 0.0010\n",
            "Epoch 7259/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 246.7030 - val_loss: 327.0493 - lr: 0.0010\n",
            "Epoch 7260/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 246.5768 - val_loss: 333.5224 - lr: 0.0010\n",
            "Epoch 7261/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 246.7721 - val_loss: 333.6066 - lr: 0.0010\n",
            "Epoch 7262/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 246.2000 - val_loss: 330.4115 - lr: 0.0010\n",
            "Epoch 7263/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 245.7137 - val_loss: 324.1637 - lr: 0.0010\n",
            "Epoch 7264/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 245.0459 - val_loss: 321.6107 - lr: 0.0010\n",
            "Epoch 7265/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 244.7126 - val_loss: 321.7517 - lr: 0.0010\n",
            "Epoch 7266/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 244.2751 - val_loss: 323.2014 - lr: 0.0010\n",
            "Epoch 7267/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 243.8160 - val_loss: 321.5255 - lr: 0.0010\n",
            "Epoch 7268/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 243.2689 - val_loss: 323.0719 - lr: 0.0010\n",
            "Epoch 7269/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 243.6444 - val_loss: 320.2358 - lr: 0.0010\n",
            "Epoch 7270/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 243.4078 - val_loss: 329.2470 - lr: 0.0010\n",
            "Epoch 7271/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 242.3006 - val_loss: 326.7942 - lr: 0.0010\n",
            "Epoch 7272/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 241.6640 - val_loss: 320.9486 - lr: 0.0010\n",
            "Epoch 7273/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 241.0904 - val_loss: 316.3401 - lr: 0.0010\n",
            "Epoch 7274/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 240.9703 - val_loss: 312.9087 - lr: 0.0010\n",
            "Epoch 7275/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 242.6661 - val_loss: 304.8755 - lr: 0.0010\n",
            "Epoch 7276/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 241.3640 - val_loss: 312.3548 - lr: 0.0010\n",
            "Epoch 7277/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 239.7458 - val_loss: 316.0934 - lr: 0.0010\n",
            "Epoch 7278/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 238.6708 - val_loss: 326.2808 - lr: 0.0010\n",
            "Epoch 7279/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 240.6040 - val_loss: 336.8196 - lr: 0.0010\n",
            "Epoch 7280/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 239.9382 - val_loss: 335.9756 - lr: 0.0010\n",
            "Epoch 7281/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 239.4701 - val_loss: 328.2772 - lr: 0.0010\n",
            "Epoch 7282/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 238.3360 - val_loss: 322.1097 - lr: 0.0010\n",
            "Epoch 7283/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 237.6469 - val_loss: 320.8802 - lr: 0.0010\n",
            "Epoch 7284/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 237.1437 - val_loss: 315.1709 - lr: 0.0010\n",
            "Epoch 7285/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 236.6129 - val_loss: 313.5408 - lr: 0.0010\n",
            "Epoch 7286/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 236.6070 - val_loss: 312.7312 - lr: 0.0010\n",
            "Epoch 7287/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 236.0974 - val_loss: 318.3713 - lr: 0.0010\n",
            "Epoch 7288/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 235.8854 - val_loss: 314.4201 - lr: 0.0010\n",
            "Epoch 7289/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 235.3362 - val_loss: 315.6368 - lr: 0.0010\n",
            "Epoch 7290/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 234.6318 - val_loss: 312.9091 - lr: 0.0010\n",
            "Epoch 7291/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 234.5402 - val_loss: 310.1644 - lr: 0.0010\n",
            "Epoch 7292/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 235.9532 - val_loss: 303.2848 - lr: 0.0010\n",
            "Epoch 7293/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 234.1925 - val_loss: 305.2580 - lr: 0.0010\n",
            "Epoch 7294/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 233.9981 - val_loss: 312.6848 - lr: 0.0010\n",
            "Epoch 7295/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 233.1554 - val_loss: 313.4572 - lr: 0.0010\n",
            "Epoch 7296/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 233.7595 - val_loss: 321.4607 - lr: 0.0010\n",
            "Epoch 7297/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 232.7077 - val_loss: 319.0118 - lr: 0.0010\n",
            "Epoch 7298/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 232.5178 - val_loss: 314.4314 - lr: 0.0010\n",
            "Epoch 7299/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 231.9320 - val_loss: 306.0807 - lr: 0.0010\n",
            "Epoch 7300/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 231.4059 - val_loss: 305.5353 - lr: 0.0010\n",
            "Epoch 7301/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 232.9149 - val_loss: 312.7956 - lr: 0.0010\n",
            "Epoch 7302/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 230.7545 - val_loss: 308.9337 - lr: 0.0010\n",
            "Epoch 7303/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 230.4682 - val_loss: 308.7545 - lr: 0.0010\n",
            "Epoch 7304/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 230.1090 - val_loss: 313.7975 - lr: 0.0010\n",
            "Epoch 7305/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 230.3293 - val_loss: 317.4931 - lr: 0.0010\n",
            "Epoch 7306/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 229.5500 - val_loss: 312.8166 - lr: 0.0010\n",
            "Epoch 7307/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 229.2399 - val_loss: 307.8714 - lr: 0.0010\n",
            "Epoch 7308/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 228.5061 - val_loss: 302.4438 - lr: 0.0010\n",
            "Epoch 7309/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 228.5573 - val_loss: 299.8029 - lr: 0.0010\n",
            "Epoch 7310/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 228.4133 - val_loss: 301.0689 - lr: 0.0010\n",
            "Epoch 7311/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 227.6618 - val_loss: 304.4198 - lr: 0.0010\n",
            "Epoch 7312/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 227.5026 - val_loss: 309.1847 - lr: 0.0010\n",
            "Epoch 7313/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 227.1749 - val_loss: 310.2393 - lr: 0.0010\n",
            "Epoch 7314/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 227.4014 - val_loss: 305.6842 - lr: 0.0010\n",
            "Epoch 7315/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 226.6548 - val_loss: 303.8538 - lr: 0.0010\n",
            "Epoch 7316/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 226.2774 - val_loss: 303.8944 - lr: 0.0010\n",
            "Epoch 7317/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 226.0605 - val_loss: 303.2916 - lr: 0.0010\n",
            "Epoch 7318/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 225.6158 - val_loss: 302.7924 - lr: 0.0010\n",
            "Epoch 7319/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 226.3611 - val_loss: 296.6276 - lr: 0.0010\n",
            "Epoch 7320/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 225.1232 - val_loss: 301.1316 - lr: 0.0010\n",
            "Epoch 7321/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 224.7197 - val_loss: 305.2650 - lr: 0.0010\n",
            "Epoch 7322/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 224.6414 - val_loss: 306.8135 - lr: 0.0010\n",
            "Epoch 7323/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 224.8277 - val_loss: 310.4323 - lr: 0.0010\n",
            "Epoch 7324/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 224.1121 - val_loss: 307.1619 - lr: 0.0010\n",
            "Epoch 7325/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 223.4302 - val_loss: 298.2240 - lr: 0.0010\n",
            "Epoch 7326/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 223.1365 - val_loss: 295.0662 - lr: 0.0010\n",
            "Epoch 7327/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 222.9968 - val_loss: 290.9223 - lr: 0.0010\n",
            "Epoch 7328/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 223.4802 - val_loss: 288.4810 - lr: 0.0010\n",
            "Epoch 7329/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 222.7383 - val_loss: 293.0648 - lr: 0.0010\n",
            "Epoch 7330/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 222.4164 - val_loss: 298.4941 - lr: 0.0010\n",
            "Epoch 7331/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 222.0900 - val_loss: 301.7072 - lr: 0.0010\n",
            "Epoch 7332/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 221.6131 - val_loss: 303.2924 - lr: 0.0010\n",
            "Epoch 7333/8000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 221.5314 - val_loss: 303.1471 - lr: 0.0010\n",
            "Epoch 7334/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 220.8187 - val_loss: 298.0827 - lr: 0.0010\n",
            "Epoch 7335/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 220.0882 - val_loss: 287.8459 - lr: 0.0010\n",
            "Epoch 7336/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 220.8146 - val_loss: 285.7776 - lr: 0.0010\n",
            "Epoch 7337/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 221.0773 - val_loss: 283.7760 - lr: 0.0010\n",
            "Epoch 7338/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 220.6057 - val_loss: 287.7442 - lr: 0.0010\n",
            "Epoch 7339/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 219.5882 - val_loss: 289.9987 - lr: 0.0010\n",
            "Epoch 7340/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 219.2314 - val_loss: 297.2835 - lr: 0.0010\n",
            "Epoch 7341/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 218.9802 - val_loss: 300.9403 - lr: 0.0010\n",
            "Epoch 7342/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 218.7422 - val_loss: 302.5365 - lr: 0.0010\n",
            "Epoch 7343/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 218.7479 - val_loss: 297.8785 - lr: 0.0010\n",
            "Epoch 7344/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 217.9647 - val_loss: 297.3866 - lr: 0.0010\n",
            "Epoch 7345/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 217.8168 - val_loss: 297.8860 - lr: 0.0010\n",
            "Epoch 7346/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 217.5939 - val_loss: 290.6400 - lr: 0.0010\n",
            "Epoch 7347/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 216.9142 - val_loss: 289.6481 - lr: 0.0010\n",
            "Epoch 7348/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 217.3987 - val_loss: 286.1459 - lr: 0.0010\n",
            "Epoch 7349/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 216.5164 - val_loss: 286.6822 - lr: 0.0010\n",
            "Epoch 7350/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 216.0188 - val_loss: 290.7130 - lr: 0.0010\n",
            "Epoch 7351/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 215.9728 - val_loss: 293.7426 - lr: 0.0010\n",
            "Epoch 7352/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 215.5537 - val_loss: 295.4182 - lr: 0.0010\n",
            "Epoch 7353/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 215.3889 - val_loss: 297.7898 - lr: 0.0010\n",
            "Epoch 7354/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 215.0973 - val_loss: 294.4164 - lr: 0.0010\n",
            "Epoch 7355/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 214.6051 - val_loss: 291.7056 - lr: 0.0010\n",
            "Epoch 7356/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 214.3393 - val_loss: 289.8847 - lr: 0.0010\n",
            "Epoch 7357/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 213.8571 - val_loss: 286.2399 - lr: 0.0010\n",
            "Epoch 7358/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 213.7168 - val_loss: 284.4508 - lr: 0.0010\n",
            "Epoch 7359/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 213.5283 - val_loss: 284.6045 - lr: 0.0010\n",
            "Epoch 7360/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 213.2094 - val_loss: 285.1409 - lr: 0.0010\n",
            "Epoch 7361/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 213.2878 - val_loss: 288.6182 - lr: 0.0010\n",
            "Epoch 7362/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 212.6731 - val_loss: 290.4419 - lr: 0.0010\n",
            "Epoch 7363/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 212.3566 - val_loss: 291.0163 - lr: 0.0010\n",
            "Epoch 7364/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 212.0207 - val_loss: 289.9318 - lr: 0.0010\n",
            "Epoch 7365/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 211.7553 - val_loss: 288.9527 - lr: 0.0010\n",
            "Epoch 7366/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 211.4726 - val_loss: 287.5104 - lr: 0.0010\n",
            "Epoch 7367/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 211.7531 - val_loss: 281.2889 - lr: 0.0010\n",
            "Epoch 7368/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 210.8908 - val_loss: 282.4427 - lr: 0.0010\n",
            "Epoch 7369/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 210.4427 - val_loss: 285.6315 - lr: 0.0010\n",
            "Epoch 7370/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 210.4959 - val_loss: 288.7291 - lr: 0.0010\n",
            "Epoch 7371/8000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 209.9851 - val_loss: 286.9430 - lr: 0.0010\n",
            "Epoch 7372/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 209.7157 - val_loss: 284.6148 - lr: 0.0010\n",
            "Epoch 7373/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 210.3375 - val_loss: 276.7047 - lr: 0.0010\n",
            "Epoch 7374/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 209.4741 - val_loss: 275.8214 - lr: 0.0010\n",
            "Epoch 7375/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 209.1516 - val_loss: 283.2423 - lr: 0.0010\n",
            "Epoch 7376/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 208.5600 - val_loss: 285.7978 - lr: 0.0010\n",
            "Epoch 7377/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 208.4180 - val_loss: 285.0538 - lr: 0.0010\n",
            "Epoch 7378/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 208.0447 - val_loss: 285.9588 - lr: 0.0010\n",
            "Epoch 7379/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 208.0737 - val_loss: 289.5403 - lr: 0.0010\n",
            "Epoch 7380/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 207.7249 - val_loss: 285.5679 - lr: 0.0010\n",
            "Epoch 7381/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 207.1771 - val_loss: 283.0387 - lr: 0.0010\n",
            "Epoch 7382/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 206.8557 - val_loss: 279.6524 - lr: 0.0010\n",
            "Epoch 7383/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 206.2945 - val_loss: 274.7982 - lr: 0.0010\n",
            "Epoch 7384/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 206.2777 - val_loss: 272.4009 - lr: 0.0010\n",
            "Epoch 7385/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 206.1934 - val_loss: 274.3185 - lr: 0.0010\n",
            "Epoch 7386/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 206.3583 - val_loss: 277.8355 - lr: 0.0010\n",
            "Epoch 7387/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 205.4146 - val_loss: 274.4950 - lr: 0.0010\n",
            "Epoch 7388/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 205.8439 - val_loss: 269.7574 - lr: 0.0010\n",
            "Epoch 7389/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 205.0846 - val_loss: 274.0991 - lr: 0.0010\n",
            "Epoch 7390/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 204.5287 - val_loss: 278.9265 - lr: 0.0010\n",
            "Epoch 7391/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 205.1047 - val_loss: 283.9315 - lr: 0.0010\n",
            "Epoch 7392/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 204.3859 - val_loss: 279.0148 - lr: 0.0010\n",
            "Epoch 7393/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 204.2796 - val_loss: 280.6021 - lr: 0.0010\n",
            "Epoch 7394/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 203.2522 - val_loss: 276.3380 - lr: 0.0010\n",
            "Epoch 7395/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 202.9217 - val_loss: 272.1342 - lr: 0.0010\n",
            "Epoch 7396/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 202.9016 - val_loss: 268.7625 - lr: 0.0010\n",
            "Epoch 7397/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 202.7895 - val_loss: 268.0567 - lr: 0.0010\n",
            "Epoch 7398/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 202.4880 - val_loss: 269.3903 - lr: 0.0010\n",
            "Epoch 7399/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 201.8285 - val_loss: 273.5598 - lr: 0.0010\n",
            "Epoch 7400/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 201.6372 - val_loss: 278.7760 - lr: 0.0010\n",
            "Epoch 7401/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 201.6385 - val_loss: 279.9519 - lr: 0.0010\n",
            "Epoch 7402/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 201.3548 - val_loss: 275.5862 - lr: 0.0010\n",
            "Epoch 7403/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 201.5040 - val_loss: 268.1917 - lr: 0.0010\n",
            "Epoch 7404/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 200.9655 - val_loss: 264.2471 - lr: 0.0010\n",
            "Epoch 7405/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 200.7746 - val_loss: 264.8985 - lr: 0.0010\n",
            "Epoch 7406/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 200.3940 - val_loss: 270.4383 - lr: 0.0010\n",
            "Epoch 7407/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 199.8385 - val_loss: 272.9591 - lr: 0.0010\n",
            "Epoch 7408/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 199.7622 - val_loss: 271.3138 - lr: 0.0010\n",
            "Epoch 7409/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 200.0592 - val_loss: 274.8951 - lr: 0.0010\n",
            "Epoch 7410/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 199.3447 - val_loss: 268.5170 - lr: 0.0010\n",
            "Epoch 7411/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 198.9743 - val_loss: 265.1942 - lr: 0.0010\n",
            "Epoch 7412/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 198.4556 - val_loss: 266.8414 - lr: 0.0010\n",
            "Epoch 7413/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 198.5687 - val_loss: 271.9353 - lr: 0.0010\n",
            "Epoch 7414/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 197.8579 - val_loss: 272.5485 - lr: 0.0010\n",
            "Epoch 7415/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 197.7366 - val_loss: 270.5153 - lr: 0.0010\n",
            "Epoch 7416/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 197.3343 - val_loss: 266.4866 - lr: 0.0010\n",
            "Epoch 7417/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 197.0294 - val_loss: 264.2055 - lr: 0.0010\n",
            "Epoch 7418/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 196.8501 - val_loss: 262.7776 - lr: 0.0010\n",
            "Epoch 7419/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 196.6228 - val_loss: 263.8442 - lr: 0.0010\n",
            "Epoch 7420/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 196.2742 - val_loss: 263.8593 - lr: 0.0010\n",
            "Epoch 7421/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 196.1548 - val_loss: 269.6824 - lr: 0.0010\n",
            "Epoch 7422/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 197.2824 - val_loss: 273.9609 - lr: 0.0010\n",
            "Epoch 7423/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 195.6077 - val_loss: 264.8533 - lr: 0.0010\n",
            "Epoch 7424/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 195.0076 - val_loss: 260.7147 - lr: 0.0010\n",
            "Epoch 7425/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 194.9986 - val_loss: 257.8554 - lr: 0.0010\n",
            "Epoch 7426/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 194.9292 - val_loss: 261.3210 - lr: 0.0010\n",
            "Epoch 7427/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 194.3496 - val_loss: 261.2686 - lr: 0.0010\n",
            "Epoch 7428/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 194.0458 - val_loss: 256.2544 - lr: 0.0010\n",
            "Epoch 7429/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 193.9792 - val_loss: 254.4100 - lr: 0.0010\n",
            "Epoch 7430/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 193.8219 - val_loss: 259.0658 - lr: 0.0010\n",
            "Epoch 7431/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 193.1988 - val_loss: 261.0579 - lr: 0.0010\n",
            "Epoch 7432/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 193.1858 - val_loss: 258.5468 - lr: 0.0010\n",
            "Epoch 7433/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 192.5539 - val_loss: 258.5755 - lr: 0.0010\n",
            "Epoch 7434/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 192.2156 - val_loss: 257.4182 - lr: 0.0010\n",
            "Epoch 7435/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 191.9338 - val_loss: 255.4508 - lr: 0.0010\n",
            "Epoch 7436/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 191.7227 - val_loss: 256.7944 - lr: 0.0010\n",
            "Epoch 7437/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 191.3310 - val_loss: 256.3056 - lr: 0.0010\n",
            "Epoch 7438/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 191.5739 - val_loss: 252.7986 - lr: 0.0010\n",
            "Epoch 7439/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 191.8611 - val_loss: 259.2639 - lr: 0.0010\n",
            "Epoch 7440/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 190.9074 - val_loss: 261.2520 - lr: 0.0010\n",
            "Epoch 7441/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 191.6591 - val_loss: 254.4935 - lr: 0.0010\n",
            "Epoch 7442/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 190.3794 - val_loss: 256.6869 - lr: 0.0010\n",
            "Epoch 7443/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 190.1449 - val_loss: 253.9821 - lr: 0.0010\n",
            "Epoch 7444/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 189.5163 - val_loss: 254.8699 - lr: 0.0010\n",
            "Epoch 7445/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 189.1552 - val_loss: 260.3011 - lr: 0.0010\n",
            "Epoch 7446/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 189.1633 - val_loss: 261.2388 - lr: 0.0010\n",
            "Epoch 7447/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 189.0959 - val_loss: 258.0797 - lr: 0.0010\n",
            "Epoch 7448/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 188.6079 - val_loss: 260.4812 - lr: 0.0010\n",
            "Epoch 7449/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 188.4463 - val_loss: 261.3512 - lr: 0.0010\n",
            "Epoch 7450/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 188.1235 - val_loss: 259.6744 - lr: 0.0010\n",
            "Epoch 7451/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 187.6913 - val_loss: 258.1736 - lr: 0.0010\n",
            "Epoch 7452/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 187.2284 - val_loss: 254.9711 - lr: 0.0010\n",
            "Epoch 7453/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 187.3768 - val_loss: 249.4509 - lr: 0.0010\n",
            "Epoch 7454/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 186.9513 - val_loss: 251.0656 - lr: 0.0010\n",
            "Epoch 7455/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 186.4352 - val_loss: 254.5667 - lr: 0.0010\n",
            "Epoch 7456/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 186.2151 - val_loss: 256.0357 - lr: 0.0010\n",
            "Epoch 7457/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 186.2253 - val_loss: 256.6146 - lr: 0.0010\n",
            "Epoch 7458/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 185.9993 - val_loss: 254.0042 - lr: 0.0010\n",
            "Epoch 7459/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 185.5578 - val_loss: 256.0707 - lr: 0.0010\n",
            "Epoch 7460/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 185.2966 - val_loss: 253.7278 - lr: 0.0010\n",
            "Epoch 7461/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 184.8686 - val_loss: 251.7821 - lr: 0.0010\n",
            "Epoch 7462/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 184.9449 - val_loss: 248.3882 - lr: 0.0010\n",
            "Epoch 7463/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 184.5213 - val_loss: 248.2982 - lr: 0.0010\n",
            "Epoch 7464/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 184.4168 - val_loss: 248.1728 - lr: 0.0010\n",
            "Epoch 7465/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 184.0210 - val_loss: 246.2113 - lr: 0.0010\n",
            "Epoch 7466/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 184.2229 - val_loss: 240.2613 - lr: 0.0010\n",
            "Epoch 7467/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 184.0935 - val_loss: 242.4308 - lr: 0.0010\n",
            "Epoch 7468/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 183.3995 - val_loss: 245.2395 - lr: 0.0010\n",
            "Epoch 7469/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 182.9258 - val_loss: 249.4369 - lr: 0.0010\n",
            "Epoch 7470/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 182.6600 - val_loss: 251.1484 - lr: 0.0010\n",
            "Epoch 7471/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 182.4645 - val_loss: 251.9771 - lr: 0.0010\n",
            "Epoch 7472/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 182.2316 - val_loss: 252.9476 - lr: 0.0010\n",
            "Epoch 7473/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 182.2400 - val_loss: 253.3526 - lr: 0.0010\n",
            "Epoch 7474/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 181.6806 - val_loss: 248.5450 - lr: 0.0010\n",
            "Epoch 7475/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 181.7463 - val_loss: 243.9884 - lr: 0.0010\n",
            "Epoch 7476/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 181.5268 - val_loss: 241.6252 - lr: 0.0010\n",
            "Epoch 7477/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 181.2303 - val_loss: 244.2012 - lr: 0.0010\n",
            "Epoch 7478/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 180.7449 - val_loss: 246.1586 - lr: 0.0010\n",
            "Epoch 7479/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 180.4219 - val_loss: 248.2137 - lr: 0.0010\n",
            "Epoch 7480/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 180.2659 - val_loss: 251.3972 - lr: 0.0010\n",
            "Epoch 7481/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 180.1580 - val_loss: 249.4146 - lr: 0.0010\n",
            "Epoch 7482/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 179.6109 - val_loss: 247.2273 - lr: 0.0010\n",
            "Epoch 7483/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 179.2429 - val_loss: 243.4062 - lr: 0.0010\n",
            "Epoch 7484/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 180.1378 - val_loss: 238.1581 - lr: 0.0010\n",
            "Epoch 7485/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 179.5553 - val_loss: 241.6489 - lr: 0.0010\n",
            "Epoch 7486/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 178.9766 - val_loss: 241.0781 - lr: 0.0010\n",
            "Epoch 7487/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 178.7340 - val_loss: 240.8386 - lr: 0.0010\n",
            "Epoch 7488/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 178.2938 - val_loss: 246.0218 - lr: 0.0010\n",
            "Epoch 7489/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 178.0324 - val_loss: 245.9159 - lr: 0.0010\n",
            "Epoch 7490/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 177.9663 - val_loss: 244.1265 - lr: 0.0010\n",
            "Epoch 7491/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 178.0135 - val_loss: 239.2830 - lr: 0.0010\n",
            "Epoch 7492/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 178.0314 - val_loss: 236.2021 - lr: 0.0010\n",
            "Epoch 7493/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 177.1972 - val_loss: 240.0403 - lr: 0.0010\n",
            "Epoch 7494/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 177.1108 - val_loss: 241.9196 - lr: 0.0010\n",
            "Epoch 7495/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 176.6790 - val_loss: 239.3069 - lr: 0.0010\n",
            "Epoch 7496/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 176.4160 - val_loss: 238.6629 - lr: 0.0010\n",
            "Epoch 7497/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 176.6429 - val_loss: 241.2765 - lr: 0.0010\n",
            "Epoch 7498/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 176.4823 - val_loss: 235.9602 - lr: 0.0010\n",
            "Epoch 7499/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 175.5881 - val_loss: 237.3636 - lr: 0.0010\n",
            "Epoch 7500/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 175.5275 - val_loss: 239.0595 - lr: 0.0010\n",
            "Epoch 7501/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 175.0033 - val_loss: 240.0047 - lr: 0.0010\n",
            "Epoch 7502/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 175.0183 - val_loss: 239.9464 - lr: 0.0010\n",
            "Epoch 7503/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 174.5824 - val_loss: 241.4017 - lr: 0.0010\n",
            "Epoch 7504/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 174.4647 - val_loss: 240.7307 - lr: 0.0010\n",
            "Epoch 7505/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 174.2072 - val_loss: 240.0232 - lr: 0.0010\n",
            "Epoch 7506/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 173.9662 - val_loss: 240.4473 - lr: 0.0010\n",
            "Epoch 7507/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 173.6937 - val_loss: 239.0758 - lr: 0.0010\n",
            "Epoch 7508/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 173.5360 - val_loss: 237.6501 - lr: 0.0010\n",
            "Epoch 7509/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 173.5359 - val_loss: 240.0242 - lr: 0.0010\n",
            "Epoch 7510/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 173.2916 - val_loss: 237.1636 - lr: 0.0010\n",
            "Epoch 7511/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 172.7468 - val_loss: 233.3495 - lr: 0.0010\n",
            "Epoch 7512/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 172.5332 - val_loss: 232.2901 - lr: 0.0010\n",
            "Epoch 7513/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 172.2259 - val_loss: 232.2629 - lr: 0.0010\n",
            "Epoch 7514/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 172.1410 - val_loss: 231.8257 - lr: 0.0010\n",
            "Epoch 7515/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 172.2768 - val_loss: 235.2646 - lr: 0.0010\n",
            "Epoch 7516/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 171.5492 - val_loss: 234.4973 - lr: 0.0010\n",
            "Epoch 7517/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 170.9704 - val_loss: 230.7757 - lr: 0.0010\n",
            "Epoch 7518/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 171.6237 - val_loss: 226.6830 - lr: 0.0010\n",
            "Epoch 7519/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 171.1905 - val_loss: 228.6209 - lr: 0.0010\n",
            "Epoch 7520/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 171.0587 - val_loss: 229.1017 - lr: 0.0010\n",
            "Epoch 7521/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 171.3105 - val_loss: 234.1069 - lr: 0.0010\n",
            "Epoch 7522/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 170.1389 - val_loss: 230.5605 - lr: 0.0010\n",
            "Epoch 7523/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 169.8457 - val_loss: 228.9797 - lr: 0.0010\n",
            "Epoch 7524/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 169.6666 - val_loss: 229.8703 - lr: 0.0010\n",
            "Epoch 7525/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 169.3475 - val_loss: 231.4660 - lr: 0.0010\n",
            "Epoch 7526/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 169.1035 - val_loss: 234.3631 - lr: 0.0010\n",
            "Epoch 7527/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 169.0205 - val_loss: 236.9952 - lr: 0.0010\n",
            "Epoch 7528/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 169.1681 - val_loss: 235.0430 - lr: 0.0010\n",
            "Epoch 7529/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 168.3495 - val_loss: 232.0299 - lr: 0.0010\n",
            "Epoch 7530/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 168.2290 - val_loss: 228.5085 - lr: 0.0010\n",
            "Epoch 7531/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 168.7096 - val_loss: 226.2572 - lr: 0.0010\n",
            "Epoch 7532/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 168.9595 - val_loss: 234.2141 - lr: 0.0010\n",
            "Epoch 7533/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 167.6555 - val_loss: 232.8842 - lr: 0.0010\n",
            "Epoch 7534/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 167.3152 - val_loss: 231.1572 - lr: 0.0010\n",
            "Epoch 7535/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 167.5388 - val_loss: 225.1438 - lr: 0.0010\n",
            "Epoch 7536/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 167.0518 - val_loss: 227.1402 - lr: 0.0010\n",
            "Epoch 7537/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 166.8728 - val_loss: 230.0961 - lr: 0.0010\n",
            "Epoch 7538/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 166.4157 - val_loss: 229.9689 - lr: 0.0010\n",
            "Epoch 7539/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 166.1139 - val_loss: 228.1145 - lr: 0.0010\n",
            "Epoch 7540/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 166.4000 - val_loss: 225.2310 - lr: 0.0010\n",
            "Epoch 7541/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 165.7953 - val_loss: 226.5972 - lr: 0.0010\n",
            "Epoch 7542/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 165.8663 - val_loss: 230.6667 - lr: 0.0010\n",
            "Epoch 7543/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 165.5920 - val_loss: 232.9436 - lr: 0.0010\n",
            "Epoch 7544/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 165.3071 - val_loss: 229.3792 - lr: 0.0010\n",
            "Epoch 7545/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 164.8898 - val_loss: 227.2289 - lr: 0.0010\n",
            "Epoch 7546/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 164.9072 - val_loss: 223.2483 - lr: 0.0010\n",
            "Epoch 7547/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 164.6661 - val_loss: 222.0481 - lr: 0.0010\n",
            "Epoch 7548/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 164.3970 - val_loss: 225.0166 - lr: 0.0010\n",
            "Epoch 7549/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 164.0356 - val_loss: 226.1153 - lr: 0.0010\n",
            "Epoch 7550/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 163.7936 - val_loss: 226.2958 - lr: 0.0010\n",
            "Epoch 7551/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 163.8726 - val_loss: 225.7126 - lr: 0.0010\n",
            "Epoch 7552/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 163.4725 - val_loss: 227.7864 - lr: 0.0010\n",
            "Epoch 7553/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 163.3683 - val_loss: 228.6698 - lr: 0.0010\n",
            "Epoch 7554/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 163.2116 - val_loss: 227.2354 - lr: 0.0010\n",
            "Epoch 7555/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 163.5693 - val_loss: 221.2006 - lr: 0.0010\n",
            "Epoch 7556/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 162.6004 - val_loss: 222.4526 - lr: 0.0010\n",
            "Epoch 7557/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 162.2889 - val_loss: 224.3604 - lr: 0.0010\n",
            "Epoch 7558/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 162.3491 - val_loss: 228.0818 - lr: 0.0010\n",
            "Epoch 7559/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 162.2339 - val_loss: 228.9941 - lr: 0.0010\n",
            "Epoch 7560/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 162.2283 - val_loss: 225.3335 - lr: 0.0010\n",
            "Epoch 7561/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 163.0136 - val_loss: 221.3844 - lr: 0.0010\n",
            "Epoch 7562/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 161.1586 - val_loss: 226.3264 - lr: 0.0010\n",
            "Epoch 7563/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 161.4784 - val_loss: 229.6963 - lr: 0.0010\n",
            "Epoch 7564/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 161.6289 - val_loss: 229.2601 - lr: 0.0010\n",
            "Epoch 7565/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 161.2453 - val_loss: 227.4149 - lr: 0.0010\n",
            "Epoch 7566/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 161.1184 - val_loss: 223.0806 - lr: 0.0010\n",
            "Epoch 7567/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 160.6790 - val_loss: 221.4789 - lr: 0.0010\n",
            "Epoch 7568/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 160.4600 - val_loss: 218.5542 - lr: 0.0010\n",
            "Epoch 7569/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 160.4169 - val_loss: 218.0466 - lr: 0.0010\n",
            "Epoch 7570/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 160.2377 - val_loss: 218.7627 - lr: 0.0010\n",
            "Epoch 7571/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 160.5317 - val_loss: 226.0688 - lr: 0.0010\n",
            "Epoch 7572/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 159.9418 - val_loss: 227.4046 - lr: 0.0010\n",
            "Epoch 7573/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 159.9059 - val_loss: 227.7694 - lr: 0.0010\n",
            "Epoch 7574/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 159.4147 - val_loss: 223.7868 - lr: 0.0010\n",
            "Epoch 7575/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 159.3516 - val_loss: 219.3021 - lr: 0.0010\n",
            "Epoch 7576/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 158.9606 - val_loss: 220.2562 - lr: 0.0010\n",
            "Epoch 7577/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 158.7017 - val_loss: 221.2583 - lr: 0.0010\n",
            "Epoch 7578/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 158.4866 - val_loss: 220.0628 - lr: 0.0010\n",
            "Epoch 7579/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 158.4937 - val_loss: 217.9050 - lr: 0.0010\n",
            "Epoch 7580/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 158.2011 - val_loss: 219.2818 - lr: 0.0010\n",
            "Epoch 7581/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 159.8488 - val_loss: 226.8284 - lr: 0.0010\n",
            "Epoch 7582/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 158.0818 - val_loss: 221.5795 - lr: 0.0010\n",
            "Epoch 7583/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 157.6754 - val_loss: 219.9464 - lr: 0.0010\n",
            "Epoch 7584/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 157.4007 - val_loss: 216.0637 - lr: 0.0010\n",
            "Epoch 7585/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 157.6398 - val_loss: 214.6503 - lr: 0.0010\n",
            "Epoch 7586/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 157.0685 - val_loss: 216.7748 - lr: 0.0010\n",
            "Epoch 7587/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 156.8406 - val_loss: 220.3502 - lr: 0.0010\n",
            "Epoch 7588/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 156.7429 - val_loss: 221.7917 - lr: 0.0010\n",
            "Epoch 7589/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 156.6194 - val_loss: 221.7805 - lr: 0.0010\n",
            "Epoch 7590/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 156.4563 - val_loss: 221.4138 - lr: 0.0010\n",
            "Epoch 7591/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 156.0915 - val_loss: 217.5997 - lr: 0.0010\n",
            "Epoch 7592/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 156.6858 - val_loss: 214.2980 - lr: 0.0010\n",
            "Epoch 7593/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 155.8367 - val_loss: 216.2091 - lr: 0.0010\n",
            "Epoch 7594/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 155.7826 - val_loss: 219.2539 - lr: 0.0010\n",
            "Epoch 7595/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 155.5416 - val_loss: 219.3013 - lr: 0.0010\n",
            "Epoch 7596/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 155.0638 - val_loss: 216.5651 - lr: 0.0010\n",
            "Epoch 7597/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 155.1623 - val_loss: 213.2094 - lr: 0.0010\n",
            "Epoch 7598/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 155.6494 - val_loss: 209.7581 - lr: 0.0010\n",
            "Epoch 7599/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 155.5676 - val_loss: 210.2992 - lr: 0.0010\n",
            "Epoch 7600/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 155.0738 - val_loss: 215.1194 - lr: 0.0010\n",
            "Epoch 7601/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 155.1205 - val_loss: 218.5214 - lr: 0.0010\n",
            "Epoch 7602/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 154.2004 - val_loss: 217.5065 - lr: 0.0010\n",
            "Epoch 7603/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 154.3449 - val_loss: 215.6096 - lr: 0.0010\n",
            "Epoch 7604/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 153.8639 - val_loss: 216.2079 - lr: 0.0010\n",
            "Epoch 7605/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 153.5652 - val_loss: 217.3636 - lr: 0.0010\n",
            "Epoch 7606/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 153.9340 - val_loss: 218.7876 - lr: 0.0010\n",
            "Epoch 7607/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 153.1919 - val_loss: 215.4082 - lr: 0.0010\n",
            "Epoch 7608/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 153.6873 - val_loss: 211.2529 - lr: 0.0010\n",
            "Epoch 7609/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 153.1984 - val_loss: 212.2536 - lr: 0.0010\n",
            "Epoch 7610/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 153.1743 - val_loss: 217.9985 - lr: 0.0010\n",
            "Epoch 7611/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 153.1830 - val_loss: 219.2844 - lr: 0.0010\n",
            "Epoch 7612/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 152.2930 - val_loss: 213.7039 - lr: 0.0010\n",
            "Epoch 7613/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 151.8997 - val_loss: 210.1446 - lr: 0.0010\n",
            "Epoch 7614/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 152.3458 - val_loss: 209.0214 - lr: 0.0010\n",
            "Epoch 7615/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 152.6014 - val_loss: 212.9092 - lr: 0.0010\n",
            "Epoch 7616/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 151.6770 - val_loss: 212.3159 - lr: 0.0010\n",
            "Epoch 7617/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 151.4778 - val_loss: 212.3589 - lr: 0.0010\n",
            "Epoch 7618/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 151.5761 - val_loss: 211.3549 - lr: 0.0010\n",
            "Epoch 7619/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 151.1027 - val_loss: 214.7302 - lr: 0.0010\n",
            "Epoch 7620/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 151.2966 - val_loss: 216.0043 - lr: 0.0010\n",
            "Epoch 7621/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 150.6971 - val_loss: 213.8538 - lr: 0.0010\n",
            "Epoch 7622/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 150.9035 - val_loss: 211.3101 - lr: 0.0010\n",
            "Epoch 7623/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 150.5183 - val_loss: 213.9393 - lr: 0.0010\n",
            "Epoch 7624/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 151.0310 - val_loss: 212.7042 - lr: 0.0010\n",
            "Epoch 7625/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 149.8738 - val_loss: 216.3534 - lr: 0.0010\n",
            "Epoch 7626/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 150.5078 - val_loss: 218.5089 - lr: 0.0010\n",
            "Epoch 7627/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 149.7364 - val_loss: 215.6214 - lr: 0.0010\n",
            "Epoch 7628/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 149.3739 - val_loss: 211.3666 - lr: 0.0010\n",
            "Epoch 7629/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 150.4764 - val_loss: 208.4613 - lr: 0.0010\n",
            "Epoch 7630/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 149.4004 - val_loss: 211.1204 - lr: 0.0010\n",
            "Epoch 7631/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 149.8724 - val_loss: 213.7156 - lr: 0.0010\n",
            "Epoch 7632/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 148.8054 - val_loss: 212.3906 - lr: 0.0010\n",
            "Epoch 7633/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 148.5421 - val_loss: 210.6950 - lr: 0.0010\n",
            "Epoch 7634/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 148.8310 - val_loss: 208.5841 - lr: 0.0010\n",
            "Epoch 7635/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 148.4517 - val_loss: 208.4214 - lr: 0.0010\n",
            "Epoch 7636/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 148.2003 - val_loss: 208.9604 - lr: 0.0010\n",
            "Epoch 7637/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 147.9567 - val_loss: 210.6159 - lr: 0.0010\n",
            "Epoch 7638/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 147.9646 - val_loss: 210.3874 - lr: 0.0010\n",
            "Epoch 7639/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 147.3722 - val_loss: 213.1517 - lr: 0.0010\n",
            "Epoch 7640/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 147.6246 - val_loss: 213.3849 - lr: 0.0010\n",
            "Epoch 7641/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 148.3500 - val_loss: 216.0339 - lr: 0.0010\n",
            "Epoch 7642/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 147.3902 - val_loss: 213.6233 - lr: 0.0010\n",
            "Epoch 7643/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 147.0536 - val_loss: 211.7421 - lr: 0.0010\n",
            "Epoch 7644/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 146.7793 - val_loss: 208.0094 - lr: 0.0010\n",
            "Epoch 7645/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 147.7819 - val_loss: 205.2253 - lr: 0.0010\n",
            "Epoch 7646/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 147.2156 - val_loss: 208.2228 - lr: 0.0010\n",
            "Epoch 7647/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 146.2696 - val_loss: 208.9993 - lr: 0.0010\n",
            "Epoch 7648/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 146.6077 - val_loss: 210.7883 - lr: 0.0010\n",
            "Epoch 7649/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 146.1143 - val_loss: 211.3263 - lr: 0.0010\n",
            "Epoch 7650/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 145.9332 - val_loss: 210.0963 - lr: 0.0010\n",
            "Epoch 7651/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 145.7339 - val_loss: 208.5208 - lr: 0.0010\n",
            "Epoch 7652/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 145.6182 - val_loss: 207.3929 - lr: 0.0010\n",
            "Epoch 7653/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 145.4036 - val_loss: 207.8614 - lr: 0.0010\n",
            "Epoch 7654/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 145.2435 - val_loss: 208.2762 - lr: 0.0010\n",
            "Epoch 7655/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 144.9964 - val_loss: 209.9069 - lr: 0.0010\n",
            "Epoch 7656/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 144.8515 - val_loss: 210.3857 - lr: 0.0010\n",
            "Epoch 7657/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 144.8013 - val_loss: 211.0473 - lr: 0.0010\n",
            "Epoch 7658/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 144.5766 - val_loss: 213.0660 - lr: 0.0010\n",
            "Epoch 7659/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 144.9516 - val_loss: 211.1624 - lr: 0.0010\n",
            "Epoch 7660/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 144.6818 - val_loss: 209.5247 - lr: 0.0010\n",
            "Epoch 7661/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 144.7055 - val_loss: 214.1868 - lr: 0.0010\n",
            "Epoch 7662/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 144.4525 - val_loss: 209.9769 - lr: 0.0010\n",
            "Epoch 7663/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 143.6558 - val_loss: 209.0358 - lr: 0.0010\n",
            "Epoch 7664/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 143.9250 - val_loss: 209.7295 - lr: 0.0010\n",
            "Epoch 7665/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 143.4578 - val_loss: 205.8930 - lr: 0.0010\n",
            "Epoch 7666/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 143.5220 - val_loss: 204.1802 - lr: 0.0010\n",
            "Epoch 7667/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 143.4346 - val_loss: 205.9869 - lr: 0.0010\n",
            "Epoch 7668/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.9736 - val_loss: 208.5664 - lr: 0.0010\n",
            "Epoch 7669/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.7882 - val_loss: 211.5307 - lr: 0.0010\n",
            "Epoch 7670/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.7696 - val_loss: 211.3653 - lr: 0.0010\n",
            "Epoch 7671/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.6932 - val_loss: 209.2594 - lr: 0.0010\n",
            "Epoch 7672/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.3555 - val_loss: 209.2776 - lr: 0.0010\n",
            "Epoch 7673/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 142.1702 - val_loss: 210.0563 - lr: 0.0010\n",
            "Epoch 7674/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 142.3288 - val_loss: 208.5159 - lr: 0.0010\n",
            "Epoch 7675/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 141.8288 - val_loss: 210.2167 - lr: 0.0010\n",
            "Epoch 7676/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 142.1254 - val_loss: 210.8075 - lr: 0.0010\n",
            "Epoch 7677/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 141.8795 - val_loss: 212.3378 - lr: 0.0010\n",
            "Epoch 7678/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 141.9119 - val_loss: 209.8164 - lr: 0.0010\n",
            "Epoch 7679/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 141.2699 - val_loss: 210.1815 - lr: 0.0010\n",
            "Epoch 7680/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 141.2546 - val_loss: 209.6252 - lr: 0.0010\n",
            "Epoch 7681/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 140.9966 - val_loss: 208.5469 - lr: 0.0010\n",
            "Epoch 7682/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 140.8344 - val_loss: 209.2654 - lr: 0.0010\n",
            "Epoch 7683/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 140.8372 - val_loss: 209.1848 - lr: 0.0010\n",
            "Epoch 7684/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 141.0963 - val_loss: 205.6830 - lr: 0.0010\n",
            "Epoch 7685/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 140.3443 - val_loss: 206.6640 - lr: 0.0010\n",
            "Epoch 7686/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 140.3032 - val_loss: 207.0185 - lr: 0.0010\n",
            "Epoch 7687/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 140.0979 - val_loss: 206.1807 - lr: 0.0010\n",
            "Epoch 7688/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 140.3312 - val_loss: 202.5924 - lr: 0.0010\n",
            "Epoch 7689/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 140.2881 - val_loss: 202.1564 - lr: 0.0010\n",
            "Epoch 7690/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 139.6613 - val_loss: 205.0413 - lr: 0.0010\n",
            "Epoch 7691/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 139.2665 - val_loss: 207.7304 - lr: 0.0010\n",
            "Epoch 7692/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 139.4489 - val_loss: 210.3276 - lr: 0.0010\n",
            "Epoch 7693/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 139.4362 - val_loss: 211.1901 - lr: 0.0010\n",
            "Epoch 7694/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 139.3525 - val_loss: 209.9806 - lr: 0.0010\n",
            "Epoch 7695/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 139.0500 - val_loss: 207.7175 - lr: 0.0010\n",
            "Epoch 7696/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 138.6004 - val_loss: 205.7075 - lr: 0.0010\n",
            "Epoch 7697/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 138.4330 - val_loss: 203.6490 - lr: 0.0010\n",
            "Epoch 7698/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 138.3535 - val_loss: 202.5093 - lr: 0.0010\n",
            "Epoch 7699/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 138.3060 - val_loss: 201.8104 - lr: 0.0010\n",
            "Epoch 7700/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 138.0843 - val_loss: 202.7420 - lr: 0.0010\n",
            "Epoch 7701/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 137.7757 - val_loss: 204.8571 - lr: 0.0010\n",
            "Epoch 7702/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 137.7698 - val_loss: 204.8296 - lr: 0.0010\n",
            "Epoch 7703/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 137.9465 - val_loss: 202.8993 - lr: 0.0010\n",
            "Epoch 7704/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 137.3201 - val_loss: 203.0663 - lr: 0.0010\n",
            "Epoch 7705/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 137.7883 - val_loss: 205.5991 - lr: 0.0010\n",
            "Epoch 7706/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 137.0764 - val_loss: 201.8530 - lr: 0.0010\n",
            "Epoch 7707/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 136.8468 - val_loss: 199.5782 - lr: 0.0010\n",
            "Epoch 7708/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 137.1211 - val_loss: 197.6943 - lr: 0.0010\n",
            "Epoch 7709/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 137.1351 - val_loss: 197.5440 - lr: 0.0010\n",
            "Epoch 7710/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 136.8528 - val_loss: 199.7424 - lr: 0.0010\n",
            "Epoch 7711/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 136.3194 - val_loss: 201.8373 - lr: 0.0010\n",
            "Epoch 7712/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 136.0716 - val_loss: 204.1887 - lr: 0.0010\n",
            "Epoch 7713/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 136.6890 - val_loss: 206.2409 - lr: 0.0010\n",
            "Epoch 7714/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 136.0193 - val_loss: 202.5850 - lr: 0.0010\n",
            "Epoch 7715/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 135.8976 - val_loss: 200.8108 - lr: 0.0010\n",
            "Epoch 7716/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 135.8522 - val_loss: 198.2803 - lr: 0.0010\n",
            "Epoch 7717/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 135.4921 - val_loss: 199.3978 - lr: 0.0010\n",
            "Epoch 7718/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 135.2922 - val_loss: 199.3271 - lr: 0.0010\n",
            "Epoch 7719/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 135.1296 - val_loss: 199.9400 - lr: 0.0010\n",
            "Epoch 7720/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 134.8726 - val_loss: 199.3380 - lr: 0.0010\n",
            "Epoch 7721/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 134.9250 - val_loss: 199.8792 - lr: 0.0010\n",
            "Epoch 7722/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 134.5524 - val_loss: 198.7195 - lr: 0.0010\n",
            "Epoch 7723/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 134.8522 - val_loss: 196.2084 - lr: 0.0010\n",
            "Epoch 7724/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 134.6817 - val_loss: 197.2154 - lr: 0.0010\n",
            "Epoch 7725/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 134.5590 - val_loss: 199.9344 - lr: 0.0010\n",
            "Epoch 7726/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 134.4011 - val_loss: 200.8884 - lr: 0.0010\n",
            "Epoch 7727/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 134.1773 - val_loss: 201.8735 - lr: 0.0010\n",
            "Epoch 7728/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 133.7716 - val_loss: 198.3347 - lr: 0.0010\n",
            "Epoch 7729/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 133.5724 - val_loss: 196.7569 - lr: 0.0010\n",
            "Epoch 7730/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 133.5667 - val_loss: 195.0780 - lr: 0.0010\n",
            "Epoch 7731/8000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 133.4853 - val_loss: 196.5095 - lr: 0.0010\n",
            "Epoch 7732/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 133.3929 - val_loss: 200.9335 - lr: 0.0010\n",
            "Epoch 7733/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 133.3564 - val_loss: 203.0727 - lr: 0.0010\n",
            "Epoch 7734/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 133.0985 - val_loss: 200.8140 - lr: 0.0010\n",
            "Epoch 7735/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 133.0920 - val_loss: 197.4921 - lr: 0.0010\n",
            "Epoch 7736/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 132.5314 - val_loss: 197.8593 - lr: 0.0010\n",
            "Epoch 7737/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 132.4772 - val_loss: 200.6196 - lr: 0.0010\n",
            "Epoch 7738/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 132.2258 - val_loss: 199.6722 - lr: 0.0010\n",
            "Epoch 7739/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 132.5822 - val_loss: 196.3254 - lr: 0.0010\n",
            "Epoch 7740/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 132.0302 - val_loss: 197.8815 - lr: 0.0010\n",
            "Epoch 7741/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 131.7150 - val_loss: 197.7470 - lr: 0.0010\n",
            "Epoch 7742/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 131.7650 - val_loss: 198.8882 - lr: 0.0010\n",
            "Epoch 7743/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 131.4680 - val_loss: 197.1511 - lr: 0.0010\n",
            "Epoch 7744/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 131.3299 - val_loss: 195.9585 - lr: 0.0010\n",
            "Epoch 7745/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 131.3222 - val_loss: 196.1604 - lr: 0.0010\n",
            "Epoch 7746/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 131.1104 - val_loss: 196.5962 - lr: 0.0010\n",
            "Epoch 7747/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 130.8177 - val_loss: 198.3782 - lr: 0.0010\n",
            "Epoch 7748/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 130.8632 - val_loss: 200.2033 - lr: 0.0010\n",
            "Epoch 7749/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 131.0132 - val_loss: 199.2368 - lr: 0.0010\n",
            "Epoch 7750/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 130.3118 - val_loss: 196.0007 - lr: 0.0010\n",
            "Epoch 7751/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 130.4081 - val_loss: 191.6884 - lr: 0.0010\n",
            "Epoch 7752/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 130.6655 - val_loss: 192.3824 - lr: 0.0010\n",
            "Epoch 7753/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 130.3062 - val_loss: 193.1163 - lr: 0.0010\n",
            "Epoch 7754/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 129.9506 - val_loss: 193.4043 - lr: 0.0010\n",
            "Epoch 7755/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 129.6467 - val_loss: 196.0891 - lr: 0.0010\n",
            "Epoch 7756/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 129.7704 - val_loss: 197.6953 - lr: 0.0010\n",
            "Epoch 7757/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 129.7341 - val_loss: 199.1974 - lr: 0.0010\n",
            "Epoch 7758/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 129.5893 - val_loss: 198.7638 - lr: 0.0010\n",
            "Epoch 7759/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 129.4044 - val_loss: 197.2012 - lr: 0.0010\n",
            "Epoch 7760/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 129.1756 - val_loss: 196.3350 - lr: 0.0010\n",
            "Epoch 7761/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 129.1233 - val_loss: 198.2776 - lr: 0.0010\n",
            "Epoch 7762/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 129.1680 - val_loss: 197.6183 - lr: 0.0010\n",
            "Epoch 7763/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 128.2963 - val_loss: 193.8770 - lr: 0.0010\n",
            "Epoch 7764/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 128.7330 - val_loss: 190.2675 - lr: 0.0010\n",
            "Epoch 7765/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 128.8286 - val_loss: 190.2995 - lr: 0.0010\n",
            "Epoch 7766/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 128.5033 - val_loss: 191.7395 - lr: 0.0010\n",
            "Epoch 7767/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 128.4769 - val_loss: 198.2790 - lr: 0.0010\n",
            "Epoch 7768/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 129.7376 - val_loss: 202.5429 - lr: 0.0010\n",
            "Epoch 7769/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 128.4454 - val_loss: 196.4164 - lr: 0.0010\n",
            "Epoch 7770/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 127.8149 - val_loss: 190.9953 - lr: 0.0010\n",
            "Epoch 7771/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 127.7169 - val_loss: 189.8506 - lr: 0.0010\n",
            "Epoch 7772/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 127.7483 - val_loss: 189.2810 - lr: 0.0010\n",
            "Epoch 7773/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 128.1591 - val_loss: 188.9632 - lr: 0.0010\n",
            "Epoch 7774/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 127.1808 - val_loss: 190.9790 - lr: 0.0010\n",
            "Epoch 7775/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 127.2954 - val_loss: 195.6222 - lr: 0.0010\n",
            "Epoch 7776/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 127.1577 - val_loss: 196.0942 - lr: 0.0010\n",
            "Epoch 7777/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 127.1689 - val_loss: 194.9564 - lr: 0.0010\n",
            "Epoch 7778/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 126.9546 - val_loss: 194.0479 - lr: 0.0010\n",
            "Epoch 7779/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 127.0128 - val_loss: 196.0878 - lr: 0.0010\n",
            "Epoch 7780/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 127.6753 - val_loss: 197.7477 - lr: 0.0010\n",
            "Epoch 7781/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 126.7119 - val_loss: 192.1479 - lr: 0.0010\n",
            "Epoch 7782/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 126.2807 - val_loss: 189.6756 - lr: 0.0010\n",
            "Epoch 7783/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 126.1232 - val_loss: 189.3973 - lr: 0.0010\n",
            "Epoch 7784/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 126.0663 - val_loss: 190.5954 - lr: 0.0010\n",
            "Epoch 7785/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 125.7484 - val_loss: 190.8643 - lr: 0.0010\n",
            "Epoch 7786/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 125.7259 - val_loss: 190.6435 - lr: 0.0010\n",
            "Epoch 7787/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 125.4797 - val_loss: 189.8048 - lr: 0.0010\n",
            "Epoch 7788/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 125.5961 - val_loss: 189.1832 - lr: 0.0010\n",
            "Epoch 7789/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 125.2404 - val_loss: 190.3863 - lr: 0.0010\n",
            "Epoch 7790/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 125.3280 - val_loss: 190.0519 - lr: 0.0010\n",
            "Epoch 7791/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 125.4446 - val_loss: 193.2998 - lr: 0.0010\n",
            "Epoch 7792/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 125.1228 - val_loss: 192.0541 - lr: 0.0010\n",
            "Epoch 7793/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 125.1096 - val_loss: 191.3876 - lr: 0.0010\n",
            "Epoch 7794/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 124.7939 - val_loss: 190.8686 - lr: 0.0010\n",
            "Epoch 7795/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 124.9632 - val_loss: 188.6408 - lr: 0.0010\n",
            "Epoch 7796/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 124.5353 - val_loss: 190.1721 - lr: 0.0010\n",
            "Epoch 7797/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 124.8086 - val_loss: 192.1637 - lr: 0.0010\n",
            "Epoch 7798/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 124.4386 - val_loss: 189.6723 - lr: 0.0010\n",
            "Epoch 7799/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 124.3853 - val_loss: 189.8504 - lr: 0.0010\n",
            "Epoch 7800/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 124.8466 - val_loss: 187.3384 - lr: 0.0010\n",
            "Epoch 7801/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 123.6616 - val_loss: 190.1452 - lr: 0.0010\n",
            "Epoch 7802/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 124.1869 - val_loss: 192.6906 - lr: 0.0010\n",
            "Epoch 7803/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 124.4515 - val_loss: 189.0099 - lr: 0.0010\n",
            "Epoch 7804/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 123.3985 - val_loss: 189.1281 - lr: 0.0010\n",
            "Epoch 7805/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 123.2946 - val_loss: 188.5157 - lr: 0.0010\n",
            "Epoch 7806/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 123.1377 - val_loss: 189.0941 - lr: 0.0010\n",
            "Epoch 7807/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 123.2030 - val_loss: 189.6892 - lr: 0.0010\n",
            "Epoch 7808/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 123.0796 - val_loss: 189.4370 - lr: 0.0010\n",
            "Epoch 7809/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 123.0338 - val_loss: 188.2679 - lr: 0.0010\n",
            "Epoch 7810/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.7131 - val_loss: 185.8929 - lr: 0.0010\n",
            "Epoch 7811/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 122.7402 - val_loss: 185.2480 - lr: 0.0010\n",
            "Epoch 7812/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 122.6526 - val_loss: 185.9314 - lr: 0.0010\n",
            "Epoch 7813/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 122.4891 - val_loss: 187.9287 - lr: 0.0010\n",
            "Epoch 7814/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.5127 - val_loss: 189.1779 - lr: 0.0010\n",
            "Epoch 7815/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 122.2215 - val_loss: 188.0436 - lr: 0.0010\n",
            "Epoch 7816/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.1329 - val_loss: 186.8718 - lr: 0.0010\n",
            "Epoch 7817/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.4255 - val_loss: 185.3711 - lr: 0.0010\n",
            "Epoch 7818/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.2016 - val_loss: 188.5367 - lr: 0.0010\n",
            "Epoch 7819/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 121.9506 - val_loss: 188.8700 - lr: 0.0010\n",
            "Epoch 7820/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 122.1145 - val_loss: 189.4478 - lr: 0.0010\n",
            "Epoch 7821/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 121.6501 - val_loss: 188.2640 - lr: 0.0010\n",
            "Epoch 7822/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 121.9675 - val_loss: 185.0105 - lr: 0.0010\n",
            "Epoch 7823/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 121.4482 - val_loss: 185.9503 - lr: 0.0010\n",
            "Epoch 7824/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 121.2897 - val_loss: 185.5088 - lr: 0.0010\n",
            "Epoch 7825/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 121.2203 - val_loss: 188.6126 - lr: 0.0010\n",
            "Epoch 7826/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 121.6905 - val_loss: 189.7282 - lr: 0.0010\n",
            "Epoch 7827/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 121.3769 - val_loss: 185.6680 - lr: 0.0010\n",
            "Epoch 7828/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 120.6941 - val_loss: 184.6666 - lr: 0.0010\n",
            "Epoch 7829/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 120.6367 - val_loss: 183.9203 - lr: 0.0010\n",
            "Epoch 7830/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 120.6695 - val_loss: 182.4180 - lr: 0.0010\n",
            "Epoch 7831/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 120.8312 - val_loss: 181.9383 - lr: 0.0010\n",
            "Epoch 7832/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 120.5886 - val_loss: 182.6602 - lr: 0.0010\n",
            "Epoch 7833/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 120.4835 - val_loss: 182.4666 - lr: 0.0010\n",
            "Epoch 7834/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 120.6230 - val_loss: 184.2132 - lr: 0.0010\n",
            "Epoch 7835/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 120.0895 - val_loss: 182.6308 - lr: 0.0010\n",
            "Epoch 7836/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 119.8921 - val_loss: 182.6792 - lr: 0.0010\n",
            "Epoch 7837/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 119.9592 - val_loss: 183.4180 - lr: 0.0010\n",
            "Epoch 7838/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 119.6340 - val_loss: 183.4767 - lr: 0.0010\n",
            "Epoch 7839/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 119.6152 - val_loss: 184.0019 - lr: 0.0010\n",
            "Epoch 7840/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 119.6298 - val_loss: 181.6064 - lr: 0.0010\n",
            "Epoch 7841/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 119.5063 - val_loss: 182.7268 - lr: 0.0010\n",
            "Epoch 7842/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 119.8022 - val_loss: 184.6981 - lr: 0.0010\n",
            "Epoch 7843/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 119.3034 - val_loss: 183.1030 - lr: 0.0010\n",
            "Epoch 7844/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 119.1131 - val_loss: 184.6151 - lr: 0.0010\n",
            "Epoch 7845/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 118.9252 - val_loss: 183.2177 - lr: 0.0010\n",
            "Epoch 7846/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 118.8286 - val_loss: 183.1402 - lr: 0.0010\n",
            "Epoch 7847/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 118.7514 - val_loss: 184.3439 - lr: 0.0010\n",
            "Epoch 7848/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 118.6201 - val_loss: 184.3957 - lr: 0.0010\n",
            "Epoch 7849/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 118.5365 - val_loss: 183.4084 - lr: 0.0010\n",
            "Epoch 7850/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 118.2450 - val_loss: 181.3909 - lr: 0.0010\n",
            "Epoch 7851/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 118.1651 - val_loss: 179.9983 - lr: 0.0010\n",
            "Epoch 7852/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 118.9790 - val_loss: 178.9242 - lr: 0.0010\n",
            "Epoch 7853/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 118.1030 - val_loss: 184.3321 - lr: 0.0010\n",
            "Epoch 7854/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 118.0272 - val_loss: 187.4531 - lr: 0.0010\n",
            "Epoch 7855/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 118.3499 - val_loss: 187.3133 - lr: 0.0010\n",
            "Epoch 7856/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 118.9714 - val_loss: 182.9046 - lr: 0.0010\n",
            "Epoch 7857/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 117.5479 - val_loss: 182.3943 - lr: 0.0010\n",
            "Epoch 7858/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 117.4456 - val_loss: 182.3157 - lr: 0.0010\n",
            "Epoch 7859/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 117.9843 - val_loss: 183.6068 - lr: 0.0010\n",
            "Epoch 7860/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 116.9130 - val_loss: 179.7733 - lr: 0.0010\n",
            "Epoch 7861/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 117.3288 - val_loss: 177.3258 - lr: 0.0010\n",
            "Epoch 7862/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 117.3349 - val_loss: 177.7414 - lr: 0.0010\n",
            "Epoch 7863/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 117.1726 - val_loss: 179.6372 - lr: 0.0010\n",
            "Epoch 7864/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 116.8401 - val_loss: 180.0933 - lr: 0.0010\n",
            "Epoch 7865/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 116.7962 - val_loss: 179.0776 - lr: 0.0010\n",
            "Epoch 7866/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 116.8044 - val_loss: 179.0111 - lr: 0.0010\n",
            "Epoch 7867/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 116.5230 - val_loss: 178.8386 - lr: 0.0010\n",
            "Epoch 7868/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 116.5753 - val_loss: 180.1433 - lr: 0.0010\n",
            "Epoch 7869/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 116.3953 - val_loss: 178.7998 - lr: 0.0010\n",
            "Epoch 7870/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 116.1390 - val_loss: 178.8031 - lr: 0.0010\n",
            "Epoch 7871/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 116.0599 - val_loss: 179.6123 - lr: 0.0010\n",
            "Epoch 7872/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 116.1172 - val_loss: 179.2829 - lr: 0.0010\n",
            "Epoch 7873/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 115.9296 - val_loss: 179.5251 - lr: 0.0010\n",
            "Epoch 7874/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 116.3505 - val_loss: 183.0452 - lr: 0.0010\n",
            "Epoch 7875/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 116.0177 - val_loss: 180.0443 - lr: 0.0010\n",
            "Epoch 7876/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 115.6495 - val_loss: 179.2390 - lr: 0.0010\n",
            "Epoch 7877/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 115.5141 - val_loss: 179.1913 - lr: 0.0010\n",
            "Epoch 7878/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 115.3896 - val_loss: 178.3658 - lr: 0.0010\n",
            "Epoch 7879/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 115.3545 - val_loss: 177.8415 - lr: 0.0010\n",
            "Epoch 7880/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 115.3430 - val_loss: 177.3978 - lr: 0.0010\n",
            "Epoch 7881/8000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 115.0054 - val_loss: 178.7071 - lr: 0.0010\n",
            "Epoch 7882/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 115.6249 - val_loss: 181.8178 - lr: 0.0010\n",
            "Epoch 7883/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 115.1040 - val_loss: 182.0067 - lr: 0.0010\n",
            "Epoch 7884/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 115.2316 - val_loss: 181.0058 - lr: 0.0010\n",
            "Epoch 7885/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.8964 - val_loss: 181.9106 - lr: 0.0010\n",
            "Epoch 7886/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.7268 - val_loss: 180.9694 - lr: 0.0010\n",
            "Epoch 7887/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.5152 - val_loss: 178.9342 - lr: 0.0010\n",
            "Epoch 7888/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.3615 - val_loss: 178.3188 - lr: 0.0010\n",
            "Epoch 7889/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.5934 - val_loss: 178.6095 - lr: 0.0010\n",
            "Epoch 7890/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 114.1793 - val_loss: 178.5744 - lr: 0.0010\n",
            "Epoch 7891/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 114.2194 - val_loss: 178.3877 - lr: 0.0010\n",
            "Epoch 7892/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.1153 - val_loss: 178.9166 - lr: 0.0010\n",
            "Epoch 7893/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 114.0427 - val_loss: 179.8033 - lr: 0.0010\n",
            "Epoch 7894/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.1187 - val_loss: 178.6097 - lr: 0.0010\n",
            "Epoch 7895/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 114.4572 - val_loss: 175.0438 - lr: 0.0010\n",
            "Epoch 7896/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 113.8857 - val_loss: 175.3086 - lr: 0.0010\n",
            "Epoch 7897/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 113.7820 - val_loss: 176.9153 - lr: 0.0010\n",
            "Epoch 7898/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 113.6801 - val_loss: 177.5004 - lr: 0.0010\n",
            "Epoch 7899/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 113.5032 - val_loss: 176.2930 - lr: 0.0010\n",
            "Epoch 7900/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 113.7191 - val_loss: 176.8838 - lr: 0.0010\n",
            "Epoch 7901/8000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 113.4674 - val_loss: 174.5245 - lr: 0.0010\n",
            "Epoch 7902/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 113.4571 - val_loss: 174.2029 - lr: 0.0010\n",
            "Epoch 7903/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 113.3885 - val_loss: 174.6317 - lr: 0.0010\n",
            "Epoch 7904/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 113.1506 - val_loss: 177.2435 - lr: 0.0010\n",
            "Epoch 7905/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 113.0314 - val_loss: 177.7637 - lr: 0.0010\n",
            "Epoch 7906/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.8988 - val_loss: 178.0011 - lr: 0.0010\n",
            "Epoch 7907/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.8089 - val_loss: 178.6367 - lr: 0.0010\n",
            "Epoch 7908/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.7466 - val_loss: 178.6716 - lr: 0.0010\n",
            "Epoch 7909/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.7754 - val_loss: 178.8159 - lr: 0.0010\n",
            "Epoch 7910/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 113.0083 - val_loss: 175.4231 - lr: 0.0010\n",
            "Epoch 7911/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 112.5720 - val_loss: 175.2400 - lr: 0.0010\n",
            "Epoch 7912/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 112.6563 - val_loss: 177.9935 - lr: 0.0010\n",
            "Epoch 7913/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.2526 - val_loss: 179.4490 - lr: 0.0010\n",
            "Epoch 7914/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.5481 - val_loss: 179.5893 - lr: 0.0010\n",
            "Epoch 7915/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.3458 - val_loss: 176.6019 - lr: 0.0010\n",
            "Epoch 7916/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.0623 - val_loss: 176.3918 - lr: 0.0010\n",
            "Epoch 7917/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.0249 - val_loss: 174.9924 - lr: 0.0010\n",
            "Epoch 7918/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 112.1693 - val_loss: 175.6374 - lr: 0.0010\n",
            "Epoch 7919/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 111.9300 - val_loss: 174.6771 - lr: 0.0010\n",
            "Epoch 7920/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 111.7465 - val_loss: 175.4875 - lr: 0.0010\n",
            "Epoch 7921/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 111.8273 - val_loss: 177.2819 - lr: 0.0010\n",
            "Epoch 7922/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.6836 - val_loss: 177.2193 - lr: 0.0010\n",
            "Epoch 7923/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.6581 - val_loss: 174.6175 - lr: 0.0010\n",
            "Epoch 7924/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.7128 - val_loss: 173.6675 - lr: 0.0010\n",
            "Epoch 7925/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.3350 - val_loss: 174.7389 - lr: 0.0010\n",
            "Epoch 7926/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.7058 - val_loss: 177.4684 - lr: 0.0010\n",
            "Epoch 7927/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 111.3727 - val_loss: 176.6182 - lr: 0.0010\n",
            "Epoch 7928/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 111.4286 - val_loss: 174.5019 - lr: 0.0010\n",
            "Epoch 7929/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 111.4679 - val_loss: 177.3620 - lr: 0.0010\n",
            "Epoch 7930/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 111.0432 - val_loss: 177.8610 - lr: 0.0010\n",
            "Epoch 7931/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 110.9303 - val_loss: 175.9007 - lr: 0.0010\n",
            "Epoch 7932/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 110.6288 - val_loss: 174.2276 - lr: 0.0010\n",
            "Epoch 7933/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 111.3858 - val_loss: 172.6616 - lr: 0.0010\n",
            "Epoch 7934/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 110.6319 - val_loss: 175.2984 - lr: 0.0010\n",
            "Epoch 7935/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 110.4891 - val_loss: 177.0987 - lr: 0.0010\n",
            "Epoch 7936/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 110.8356 - val_loss: 175.9287 - lr: 0.0010\n",
            "Epoch 7937/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 110.3711 - val_loss: 174.8291 - lr: 0.0010\n",
            "Epoch 7938/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 110.3129 - val_loss: 173.7427 - lr: 0.0010\n",
            "Epoch 7939/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 110.2440 - val_loss: 173.7684 - lr: 0.0010\n",
            "Epoch 7940/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 110.4672 - val_loss: 173.7804 - lr: 0.0010\n",
            "Epoch 7941/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 110.1716 - val_loss: 173.1181 - lr: 0.0010\n",
            "Epoch 7942/8000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 110.2810 - val_loss: 172.6349 - lr: 0.0010\n",
            "Epoch 7943/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 110.7393 - val_loss: 175.5491 - lr: 0.0010\n",
            "Epoch 7944/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 110.0014 - val_loss: 174.4909 - lr: 0.0010\n",
            "Epoch 7945/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 109.6980 - val_loss: 172.4806 - lr: 0.0010\n",
            "Epoch 7946/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 109.9658 - val_loss: 173.0537 - lr: 0.0010\n",
            "Epoch 7947/8000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 111.4131 - val_loss: 169.8418 - lr: 0.0010\n",
            "Epoch 7948/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 109.9899 - val_loss: 171.4057 - lr: 0.0010\n",
            "Epoch 7949/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 109.6908 - val_loss: 174.0369 - lr: 0.0010\n",
            "Epoch 7950/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 109.4424 - val_loss: 174.0241 - lr: 0.0010\n",
            "Epoch 7951/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 109.4386 - val_loss: 173.3384 - lr: 0.0010\n",
            "Epoch 7952/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 109.1770 - val_loss: 172.7614 - lr: 0.0010\n",
            "Epoch 7953/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 109.2527 - val_loss: 172.4926 - lr: 0.0010\n",
            "Epoch 7954/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 109.5046 - val_loss: 171.7175 - lr: 0.0010\n",
            "Epoch 7955/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 108.8472 - val_loss: 175.3810 - lr: 0.0010\n",
            "Epoch 7956/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 110.4398 - val_loss: 179.0237 - lr: 0.0010\n",
            "Epoch 7957/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 109.2938 - val_loss: 176.7418 - lr: 0.0010\n",
            "Epoch 7958/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.9558 - val_loss: 171.7256 - lr: 0.0010\n",
            "Epoch 7959/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.9393 - val_loss: 170.1980 - lr: 0.0010\n",
            "Epoch 7960/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 109.1615 - val_loss: 170.3962 - lr: 0.0010\n",
            "Epoch 7961/8000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 108.4112 - val_loss: 174.2975 - lr: 0.0010\n",
            "Epoch 7962/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.5850 - val_loss: 177.8344 - lr: 0.0010\n",
            "Epoch 7963/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.8779 - val_loss: 176.9064 - lr: 0.0010\n",
            "Epoch 7964/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.7266 - val_loss: 175.6966 - lr: 0.0010\n",
            "Epoch 7965/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 108.5667 - val_loss: 173.7028 - lr: 0.0010\n",
            "Epoch 7966/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 108.3408 - val_loss: 174.1505 - lr: 0.0010\n",
            "Epoch 7967/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 108.0992 - val_loss: 172.8801 - lr: 0.0010\n",
            "Epoch 7968/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 108.2401 - val_loss: 172.9975 - lr: 0.0010\n",
            "Epoch 7969/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 108.0563 - val_loss: 172.0180 - lr: 0.0010\n",
            "Epoch 7970/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.9922 - val_loss: 172.0853 - lr: 0.0010\n",
            "Epoch 7971/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 107.9600 - val_loss: 170.8660 - lr: 0.0010\n",
            "Epoch 7972/8000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 107.7887 - val_loss: 172.0434 - lr: 0.0010\n",
            "Epoch 7973/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.5669 - val_loss: 173.6620 - lr: 0.0010\n",
            "Epoch 7974/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 107.8784 - val_loss: 174.4580 - lr: 0.0010\n",
            "Epoch 7975/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 107.6635 - val_loss: 172.3950 - lr: 0.0010\n",
            "Epoch 7976/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.9056 - val_loss: 168.7937 - lr: 0.0010\n",
            "Epoch 7977/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 108.0022 - val_loss: 169.1298 - lr: 0.0010\n",
            "Epoch 7978/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.3990 - val_loss: 172.6449 - lr: 0.0010\n",
            "Epoch 7979/8000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 107.2419 - val_loss: 174.7874 - lr: 0.0010\n",
            "Epoch 7980/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 107.9272 - val_loss: 175.7066 - lr: 0.0010\n",
            "Epoch 7981/8000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 107.1021 - val_loss: 172.3254 - lr: 0.0010\n",
            "Epoch 7982/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 107.1205 - val_loss: 169.4914 - lr: 0.0010\n",
            "Epoch 7983/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.3567 - val_loss: 168.9721 - lr: 0.0010\n",
            "Epoch 7984/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 107.0453 - val_loss: 171.3234 - lr: 0.0010\n",
            "Epoch 7985/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 106.8148 - val_loss: 172.8705 - lr: 0.0010\n",
            "Epoch 7986/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.3668 - val_loss: 174.9902 - lr: 0.0010\n",
            "Epoch 7987/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 107.3491 - val_loss: 171.9142 - lr: 0.0010\n",
            "Epoch 7988/8000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 106.5841 - val_loss: 170.1940 - lr: 0.0010\n",
            "Epoch 7989/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 106.5972 - val_loss: 169.3063 - lr: 0.0010\n",
            "Epoch 7990/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 106.7061 - val_loss: 168.9900 - lr: 0.0010\n",
            "Epoch 7991/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 106.7051 - val_loss: 169.9880 - lr: 0.0010\n",
            "Epoch 7992/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 106.4728 - val_loss: 170.8672 - lr: 0.0010\n",
            "Epoch 7993/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 106.4274 - val_loss: 170.7956 - lr: 0.0010\n",
            "Epoch 7994/8000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 106.4288 - val_loss: 169.8567 - lr: 0.0010\n",
            "Epoch 7995/8000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 106.1315 - val_loss: 170.6455 - lr: 0.0010\n",
            "Epoch 7996/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 106.1368 - val_loss: 170.4062 - lr: 0.0010\n",
            "Epoch 7997/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 106.0724 - val_loss: 171.0401 - lr: 0.0010\n",
            "Epoch 7998/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 106.0744 - val_loss: 169.7164 - lr: 0.0010\n",
            "Epoch 7999/8000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 106.0735 - val_loss: 168.3262 - lr: 0.0010\n",
            "Epoch 8000/8000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 105.9663 - val_loss: 169.7526 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "#lat_history = nu_model_lat.fit(X_train_norm, y_train_lat, validation_split=0.2, batch_size=32, epochs=8000, callbacks=[lrd, mcp, es])\n",
        "lat_history = nu_model_lat.fit(X_train_norm, y_train_lat, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[lrd, mcp, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTLs2OEtWXBb",
        "outputId": "48e18683-585f-4c28-c4fb-7ee6a58b36f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step - loss: 68.3637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.36370849609375"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "nu_model_lat.evaluate(X_test_norm, y_test_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEFOeq7Xei3U",
        "outputId": "6f4d035d-af5f-4b1c-db8e-49672a8e778b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[190.75131]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "nu_model_lat.predict([[3,13,1,0,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbAYhXsgaY-1"
      },
      "outputs": [],
      "source": [
        "y_pred_lat = nu_model_lat.predict(X_test_norm)\n",
        "# y_pred_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RCwlmwvYPh3",
        "outputId": "883a0679-dfde-4276-dd9a-310d0c827208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score is 0.9987453442808188\n",
            "RMSE is 8.268253437116082\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "RMSE = (((y_pred_lat[:,0]-y_test_lat)**2).mean())**.5\n",
        "print('R2 score is',r2_score(y_test_lat, y_pred_lat))\n",
        "print('RMSE is',RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "5TXzQWsSbEMx",
        "outputId": "76eca538-d866-457a-f77d-72d00a7430b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(lat_history.history['loss'])\n",
        "plt.plot(lat_history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljt3nWfWbjcq",
        "outputId": "d72aee74-15b7-465c-b84f-78f2aa8ff984"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[190.75131]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "nu_model_lat.predict([[3,13,1,0,0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-TgKxGGtPz"
      },
      "source": [
        "## Extra Tree Regressor for Latency\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqF1P4Vo3p8f",
        "outputId": "902e28f5-2078-41f3-9866-a254417759bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for this model is 0.9996465470549297\n",
            "RMSE score for this model is 4.3885120694726645\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "reg_lat = ExtraTreesRegressor(n_estimators=100, random_state=0, bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                    n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_lat, y_train_lat)\n",
        "\n",
        "R2_score = reg_lat.score(X_test_lat, y_test_lat)\n",
        "print(\"R2 score for this model is\", R2_score)\n",
        "\n",
        "y_pred_lat = reg_lat.predict(X_test_lat)\n",
        "MSE = ((y_pred_lat-y_test_lat)**2).mean()\n",
        "RMSE = (((y_pred_lat-y_test_lat)**2).mean())**.5\n",
        "print(\"RMSE score for this model is\", RMSE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNBawuMSuNT2"
      },
      "outputs": [],
      "source": [
        "y_pred_all = reg_lat.predict(x_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Na3-KpWuTtg",
        "outputId": "761d69e2-ed82-4156-b85f-6140f9de9bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 1.0067963635085624\n"
          ]
        }
      ],
      "source": [
        "# RMSE for all data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse_all = mean_squared_error(y_lat, y_pred_all)\n",
        "sk_rmse_all = sk_mse_all**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNId8zgaFKBZ",
        "outputId": "b15d8922-bb79-44ee-c1d5-38ecfc2d6b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 4.388512069472664\n"
          ]
        }
      ],
      "source": [
        "# RMSE for validation data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse = mean_squared_error(y_test_lat, y_pred_lat)\n",
        "sk_rmse = sk_mse**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGwAP5B-3qyb"
      },
      "outputs": [],
      "source": [
        "# y_pred_lat = reg.predict(X_test_lat)\n",
        "# y_pred_lat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_UPadyH3qF_"
      },
      "outputs": [],
      "source": [
        "# MSE = ((y_pred_lat-y_test_lat)**2).mean()\n",
        "# RMSE = (((y_pred_lat-y_test_lat)**2).mean())**.5\n",
        "# RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT6JoVKB5i-F",
        "outputId": "7ff5aec8-8c7a-4976-d66f-4d6c1e6f411b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.284453 using {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#define your own mse and set greater_is_better=False\n",
        "# mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
        "\n",
        "etr_lat = ExtraTreesRegressor(n_estimators=100,random_state=0, bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                    n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_lat, y_train_lat)\n",
        "\n",
        "                            \n",
        "param_grid = {\n",
        "    'n_estimators': [50,100],\n",
        "    # 'criterion': ['mse', 'mae'],\n",
        "    'max_depth': [50,60,80],\n",
        "    # 'oob_score': [True, False],\n",
        "    'max_features': ['auto','sqrt','log2'],    \n",
        "    # 'bootstrap': [True, False],\n",
        "    # 'warm_start': [True, False],\n",
        "}\n",
        "\n",
        "gcv = GridSearchCV(etr_lat,param_grid,scoring='neg_root_mean_squared_error',cv=20,n_jobs=-1).fit(x_lat,y_lat)\n",
        "#gcv = GridSearchCV(etr_lat,param_grid,scoring='r2',cv=20,n_jobs=-1).fit(x_lat,y_lat)\n",
        "\n",
        "# grid_result = gsc.fit(x_output, y_output)\n",
        "\n",
        "print(\"Best: %f using %s\" % (gcv.best_score_, gcv.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CXljZRBWovcf",
        "outputId": "1402c301-769c-46c3-a58e-864420d1d75f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11656ff5-cadb-44c1-8825-66fadc974033\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity_High</th>\n",
              "      <th>Intensity_Low</th>\n",
              "      <th>Intensity_Medium</th>\n",
              "      <th>actual_latency</th>\n",
              "      <th>prdicted_latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>71.048</td>\n",
              "      <td>71.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146.048</td>\n",
              "      <td>146.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>218.549</td>\n",
              "      <td>218.549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>291.848</td>\n",
              "      <td>291.848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>365.552</td>\n",
              "      <td>365.552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11656ff5-cadb-44c1-8825-66fadc974033')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11656ff5-cadb-44c1-8825-66fadc974033 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11656ff5-cadb-44c1-8825-66fadc974033');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  ...  actual_latency  prdicted_latency\n",
              "0             1          13  ...          71.048            71.048\n",
              "1             2          13  ...         146.048           146.048\n",
              "2             3          13  ...         218.549           218.549\n",
              "3             4          13  ...         291.848           291.848\n",
              "4             5          13  ...         365.552           365.552\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "#combine x_test,y_test and y_pred on one table to be able to visualise it\n",
        "df_vis_lat = x_lat.copy()\n",
        "df_vis_lat['actual_latency'] = y_lat\n",
        "df_vis_lat['prdicted_latency'] = y_pred_all\n",
        "df_vis_lat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assess Performance of the ExtraTreeRegressor model for Latency\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "To5eBXAUbGRX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "zdfu9vxhEeGF",
        "outputId": "f65cef4e-085b-41d2-f31c-ace74127a04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Error: 9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa6040d3710>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = [20, 10])\n",
        "base_color = sns.color_palette()[0]\n",
        " \n",
        "# plt.subplot(1, 2, 1)\n",
        "# # plot Block_period VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_period', y='actual_latency', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_period', y='prdicted_latency', color='red')\n",
        "# plt.title('Block period vs actual and prdicted latency')\n",
        "# plt.ylabel('Latency')\n",
        "# plt.xlabel('Block_period')\n",
        "# plt.legend(['y_test_lat', 'y_pred_lat'], loc='upper left')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plot Block_size VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_size', y='actual_latency', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_size', y='prdicted_latency', color='red')\n",
        "# plt.title('Block size vs actual and prdicted latency')\n",
        "# plt.ylabel('Latency')\n",
        "# plt.xlabel('Block_size')\n",
        "# plt.legend(['actual_latency', 'prdicted_latency'], loc='upper right')\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "## residuals\n",
        "residuals = y_test_lat - y_pred_lat\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true  = y_test_lat.get(max_idx)\n",
        "max_pred = y_pred_lat[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))\n",
        "\n",
        "from statsmodels.graphics.api import abline_plot\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "ax.scatter(y_pred_lat, y_test_lat, color=\"black\")\n",
        "abline_plot(intercept=0, slope=1, color=\"red\", ax=ax)\n",
        "#ax[0].vlines(x=max_pred, ymin=max_true, ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "ax.grid(True)\n",
        "ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs Actual Latency\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dALaE9iln-vz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BXL4m2xtRDfd"
      ],
      "name": "ExtraTreeRegressor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f88f2eb67204b459949d5115f5751e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f27a94f3f884e6dabdb11887cbaefc3",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fed08ffa8d54478947f230646ff6cb6"
          }
        },
        "3f27a94f3f884e6dabdb11887cbaefc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fed08ffa8d54478947f230646ff6cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f21af9ca86345148c1d5ca6eed4e5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_09ed1d21d50643599350dfa868146b39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29d55a132fdb4e75a10d66d5d0c61bf4"
          }
        },
        "09ed1d21d50643599350dfa868146b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29d55a132fdb4e75a10d66d5d0c61bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c3738e4159042778f6cea4eb5c03955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e16571292da4f9eb8771b5ad2e766d8",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cff73513a624e09ad11ff2f12f8499f"
          }
        },
        "5e16571292da4f9eb8771b5ad2e766d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cff73513a624e09ad11ff2f12f8499f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b107ed261ec4a35a17c322abaff5a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97ff2c17fafc46fbbf8ea9e775adf937",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59744b085bac4551adcf37ed16c1fbc5"
          }
        },
        "97ff2c17fafc46fbbf8ea9e775adf937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59744b085bac4551adcf37ed16c1fbc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4728f1154984a239b31f64130ee41a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_9dda01900c0b46aab0fe57d0f9346457",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f77836c6dc964b979405b723a0d717d5"
          }
        },
        "9dda01900c0b46aab0fe57d0f9346457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f77836c6dc964b979405b723a0d717d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "794f4f6304014c0ea2aabc020f22da8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07414a6ddf344a6d902a040765fa376f",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f844722b2e9d409fb706624d75418d1a"
          }
        },
        "07414a6ddf344a6d902a040765fa376f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f844722b2e9d409fb706624d75418d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}