{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hma23/MachineLearning/blob/main/ExtraTreeRegressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3x5EA9gOl5fl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54L_PuJzoP34",
        "outputId": "531ec1d0-e1b8-42b5-e40b-e07fe9136a8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#To show all records for our data frame\n",
        "pd.set_option(\"display.min_rows\", 200)\n",
        "pd.set_option(\"display.max_rows\", 500)\n",
        "pd.get_option(\"display.max_rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j4rI5RQmhqD",
        "outputId": "6746551d-8810-42f0-e908-1009ac4118c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KCddeJ5RXtE"
      },
      "source": [
        "## Data Exploration and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4DXWrO5Mmhso",
        "outputId": "9c2f330e-af59-4f18-f803-f5cc9d9c7478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf6b3346-a367-460e-82c3-36f61e0d576f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>box_output</th>\n",
              "      <th>Latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>89</td>\n",
              "      <td>71.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>43</td>\n",
              "      <td>146.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>28</td>\n",
              "      <td>218.549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>20</td>\n",
              "      <td>291.848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>High</td>\n",
              "      <td>17</td>\n",
              "      <td>365.552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6b3346-a367-460e-82c3-36f61e0d576f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf6b3346-a367-460e-82c3-36f61e0d576f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf6b3346-a367-460e-82c3-36f61e0d576f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size Intensity  box_output  Latency\n",
              "0             1          13      High          89   71.048\n",
              "1             2          13      High          43  146.048\n",
              "2             3          13      High          28  218.549\n",
              "3             4          13      High          20  291.848\n",
              "4             5          13      High          17  365.552"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/data/Book1_new.xlsx')\n",
        "#uncomment next line to show all values\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "uIS8XkNpZKl8",
        "outputId": "ea854536-d61f-4b7f-91f5-9519a4340bc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e75a1bd9-9c81-4312-a54f-d82a2b05a3e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>box_output</th>\n",
              "      <th>Latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>190.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.631579</td>\n",
              "      <td>12.226316</td>\n",
              "      <td>46.052632</td>\n",
              "      <td>412.643607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.824324</td>\n",
              "      <td>3.342265</td>\n",
              "      <td>62.498824</td>\n",
              "      <td>387.241382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>11.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.250000</td>\n",
              "      <td>104.718917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>251.401000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>659.292825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>1645.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e75a1bd9-9c81-4312-a54f-d82a2b05a3e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e75a1bd9-9c81-4312-a54f-d82a2b05a3e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e75a1bd9-9c81-4312-a54f-d82a2b05a3e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Block_period  Block_size  box_output      Latency\n",
              "count    190.000000  190.000000  190.000000   190.000000\n",
              "mean       6.631579   12.226316   46.052632   412.643607\n",
              "std        3.824324    3.342265   62.498824   387.241382\n",
              "min        1.000000    7.000000    3.000000    11.035000\n",
              "25%        4.000000   10.000000    9.250000   104.718917\n",
              "50%        5.000000   13.000000   26.000000   251.401000\n",
              "75%       10.000000   14.000000   62.000000   659.292825\n",
              "max       14.000000   21.000000  589.000000  1645.100000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S9TfswLHRh5L"
      },
      "outputs": [],
      "source": [
        "#sns.pairplot(df, height=3, aspect=1.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2PevyUGkUDXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b6cc0290-484b-49b8-e0fb-e37c3afac503"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa40b346ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.heatmap(df.corr(), annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XYxNrC70VkB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "e710ab50-5569-4680-b4dd-8e8f3ac245f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEDCAYAAADTIbj3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3xcd3ng+88jKRkrSEo8Dh4bjRONg0Zdj4rEWEVRo9gCE5pSb8NrtyCzSwksa+4Gli3L5bXQcHfb0l0ubG/Lj8s25VKgYX/EKty2pCkEUhPZFSiikrCCR8GjRGPiMbIcPHYsYVtE0rN/zJGikWR5LGl05sx53q+XXp5zvt85epQno0ff8+P7FVXFGGOMP5W5HYAxxhj3WBEwxhgfsyJgjDE+ZkXAGGN8zIqAMcb4mBUBY4zxsQq3A7het956q9bV1bkdRkH84he/4MYbb3Q7DLNKlj9vK+X8DQwM/ExVX7lcm+eKQF1dHf39/W6HURDd3d10dHS4HYZZJcuft5Vy/kTkJ1drK+jpIBG5RUS+LiI/FpFnRKRNRIIi8oSIjDj/bnb6ioh8TkSeFZGnRSReyNiMMcYU/prAZ4HHVfWXgCbgGeCjwGFVrQcOO9sAvw7UO1/vBR4qcGzGGON7BSsCInIzsAf4EoCq/kJVLwD3AQ873R4G3uK8vg/4qmY9BdwiItsLFZ8xxpjCjgQiwAvAV0TkhyLy5yLyCiCkqmNOnzNAyHldC5xa8P60s883SvWCt19Y/rzNr/kr5IXhCiAOfEBV+0Tks7x86gcAVVURua4Z7MbGxmhoaJjf3r9/PwcPHiQSiZBMJonFYhw9enTJ+9ra2kilUoTDYcbHxzl16lROe21tLeFwmFQqRTQapaenZ8kx2tvbSSaTRCIR0uk0p0+fzmnfsWMHoVCIdDpNJBKht7d3yTH27NlDIpEgGo2SSqU4c+bMfNvs7CwAwWCQ8fFxwuEwfX19Oe8XEfbu3cvQ0BCxWIxkMsnZs2dz+uzcuZPq6moymQyhUGjJhfSKigra29sZHBykubmZRCLBuXPncvrU19cTCASYnJwkGAwyODiY0x4IBGhra2NgYIDdu3czNDTE+fPnc/o0NDRQXl7OlStXqK6uZmhoKKe9srKS1tbW+WMMDg5y8eLFnD67du1iZmaG2dlZAoEAx48fz2mvqqqipaVl/hj9/f1MTk7m9GlsbGRqaoqysjLKy8sZHh7Oaa+pqSEej88fo6+vj8uXL+f0aWpqYmJigk2bNjEzM8OJEydy2jdv3kwkEpk/Rm9vL1NTUzl94vE4mUyGqqoqpqamGBkZyWnfsmULsViMY8eOEY/H6enpYXp6OqdPS0sL4+PjBINBJiYmGB0dzWnfunUr0WiURCJBU1MTR44cYfEkka2traTTaUKhEJlMhpMnT+a0b9u2rSQ+T5D9xZ7P56mnp4e/+Zu/4a1vfeuS3JfS52k5UqhZREVkG/CUqtY523eTLQKvBjpUdcw53dOtqg0i8gXn9SNO/xNz/RYet6WlRUv17qCRkRHq6+vdDsOskuXPux566CEef/xx7r33Xh544AG3w1l3IjKgqi3LtRXsdJCqngFOicjcn+37gGHgUeB+Z9/9wDec148C73TuEroTeHFxASh14XDY7RDMGlj+vCmTyXD48GFUlcOHDy/5C7zUFfruoA8A/1NEngaagU8AnwTuEZER4I3ONsA3gVHgWeCLwPsKHFvRWTxUNd5i+fOmrq6u+VOxs7OzHDp0yOWINlZBHxZT1WPAckOQfcv0VeD9hYzHGGMW6+7unr/2Mj09TXd3d0meEroamzvIGONrHR0dVFRk/x6uqKgo2aeGr8aKgDHG1zo7Oykry/4qLCsr48CBAy5HtLGsCBQREXE7BLMGlj9vCgaD7NuXPUO9b98+Nm/e7HJEG8tzE8iVsr1797odglkDy593dXZ28vzzz/tuFAA2Eigqix/+MN5i+fOuYDDIgQMHfDcKACsCRSUWi7kdglkDy5+3+TV/VgSKSDKZdDsEswaWP2/za/6sCBSRxXMAGW+x/HmbX/NnRcAYY3zMioAxxviYFQFjjPExKwJFZOfOnW6HYNbA8udtfs2fFYEiUl1d7XYIZg0sf97m1/xZESgimUzG7RDMGlj+vM2v+bMiUERCodC1O5miZfnzNr/mz4pAESnVZTP9wvLnbX7NnxUBY4zxMSsCxhjjY1YEjDHGx6wIFJG5Je6MN1n+vM2v+ZPs+u7e0dLSon69gGOMMashIgOq2rJcm40Eisjg4KDbIZg1sPx5m1/zZ0WgiDQ3N7sdglkDy5+3+TV/VgSKSCKRcDsEswaWP2/za/6sCBSRc+fOuR2CWQPLn7f5NX8FLQIiclJEfiQix0Sk39kXFJEnRGTE+Xezs19E5HMi8qyIPC0i8ULGZowxZmNGAq9X1eYFV6Y/ChxW1XrgsLMN8OtAvfP1XuChDYjNGGN8zY3TQfcBDzuvHwbesmD/VzXrKeAWEdnuQnzGGOMbhS4CCnxHRAZE5L3OvpCqjjmvzwBzU/fVAqcWvDft7PON+vp6t0Mwa2D58za/5q/Qj8i1q+ppEdkKPCEiP17YqKoqItf1tNrY2BgNDQ3z2/v37+fgwYNEIhGSySSxWIyjR48ueV9bWxupVIpwOMz4+DinTp3Kaa+trSUcDpNKpYhGo/T09Cz9YdrbSSaTRCIR0uk0p0+fzmnfsWMHoVCIdDpNJBKht7d3yTH27NlDIpEgGo2SSqU4c+bMfNv09DQvvfQSwWCQ8fFxwuEwfX19Oe8XEfbu3cvQ0BCxWIxkMsnZs2dz+uzcuZPq6moymQyhUGjJ7IgVFRW0t7czODhIc3MziURiyUWx+vp6AoEAk5OTBIPBJfdQBwIB2traGBgYYPfu3QwNDXH+/PmcPg0NDZSXl3PlyhWqq6sZGhrKaa+srKS1tXX+GIODg1y8eDGnz65du5iZmWF2dpZAIMDx48dz2quqqmhpaZk/Rn9/P5OTkzl9GhsbmZqaoqysjPLycoaHh3Paa2pqiMfj88fo6+vj8uXLOX2ampqYmJhg06ZNzMzMcOLEiZz2zZs3U1tbO3+M3t5epqamcvrE43EymQxVVVVMTU0xMjKS075lyxZisRjHjh0jHo/T09PD9PR0Tp+WlhbGx8cJBoNMTEwwOjqa075161ai0SiJRIKmpiaOHDnC4gdCW1tbSafThEIhMpkMJ0+ezGnftm1bSXyeAOrq6vL+PG3bto3h4eGS/jwtZ8OeGBaR3wcmgYNAh6qOOad7ulW1QUS+4Lx+xOl/Yq7fwuOU8hPDJ0+epK6uzu0wzCpZ/rytlPPnyhPDIvIKEameew28CTgOPArc73S7H/iG8/pR4J3OXUJ3Ai8uLgClLhgMuh2CWQPLn7f5NX+FvCYQAnpEZAj4AfB3qvo48EngHhEZAd7obAN8ExgFngW+CLyvgLEVJb8+tl4qLH/e5tf8FeyagKqOAk3L7D8H7FtmvwLvL1Q8xhhjlrInho0xxsesCBhjjI9ZESgigUDA7RDMGlj+vM2v+bNFZYwxpsTZojIeMTAw4HYIZg0sf97m1/zZSMAYY0qcjQQ8YvFj4MZbLH/e5tf8WREoIovnCjHeYvnzNr/mz4qAMcb4mBUBY4zxMSsCxhjjY1YEisjCdRKM91j+vM2v+bMiUETKy8vdDsGsgeXP2/yaPysCReTKlStuh2DWwPLnbX7NnxWBIlJdXe12CGYNLH/e5tf8WREoIn59WKVUWP68za/5syJgjDE+ZkXAGGN8zIqAMcb4mBWBIlJZWel2CGYNLH/e5tf82VTSxhhT4tY8lbSIbBaRmIjsFBEbPRSIXxe1KBWWP2/za/6uOhIQkZuB9wNvB24EXgA2ASHgKeBPVfXJDYpzno0EjDHm+qx2JPB14BRwt6o2qGq7qrao6g7gk8B9IvKeAsTrW4ODg26HYNbA8udtfs1fxdUaVPWeFdoGAH+OnQro4sWLbodg1sDy521+zd9VRwIicrtzSmhu+/Ui8lkR+ZCI3JjvNxCRchH5oYg85mxHRKRPRJ4Vka65Y4lIwNl+1mmvW/2PZYwxJh8rnQ76S+AVACLSDHwNeB5oAv70Or7H7wDPLNj+FPBpVX01cB6YO6X0HuC8s//TTj9jjDEFtFIRqFTVnzqv3wF8WVX/GHg38Lp8Di4iYeA3gD93tgV4A9nrDQAPA29xXt/nbOO073P6G2OMKZCrXhMAFv4CfgPwuwCqOnsdv5s/A/wHYG56vi3ABVWddrbTQK3zupbshWhUdVpEXnT6/2zhAcfGxnIWf9i/fz8HDx4kEomQTCaJxWIcPXp0SSBtbW2kUinC4TDj4+OcOnUqp722tpZwOEwqlSIajdLT07PkGO3t7SSTSSKRCOl0mtOnT+e079ixg1AoRDqdJhKJ0Nvbu+QYe/bsIZFIEI1GSaVSnDlzZr5tenqakydPEgwGGR8fJxwO09fXl/N+EWHv3r0MDQ0Ri8VIJpOcPXs2p8/OnTuprq4mk8kQCoVYfDdVRUUF7e3tDA4O0tzcTCKR4Ny5czl96uvrCQQCTE5OEgwGl1w0CwQCtLW1MTAwwO7duxkaGlqyUHdDQwPl5eVcuXKF6urqJRN0VVZW0traOn+MwcHBJedld+3axczMDLOzswQCAY4fP57TXlVVRUtLy/wx+vv7mZyczOnT2NjI1NQUZWVllJeXMzw8nNNeU1NDPB6fP0ZfXx+XL1/O6dPU1MTExASbNm1iZmaGEydO5LRv3ryZXbt2zR+jt7eXqampnD7xeJxMJkNVVRVTU1OMjIzktG/ZsoVYLMaxY8eIx+P09PQwPT2d06elpYXx8XGCwSATExOMjo7mtG/dupVoNEoikaCpqYkjR46w+A7A1tZW0uk0oVCITCbDyZMnc9q3bdtWEp8ngLq6urw/Tw0NDQwPD5f052k5K90i+llgOzAG/CYQVdWXRGQ78LdXu91owfv3A29W1feJSAfwYeBdwFPOKR9EZAfwLVVtFJHjwL2qmnbangNaVTWnCJTyLaJjY2Ns377d7TDMKln+vK2U87fSLaIrjQQ+CHSSLQTtqvqSs38b8LE8vu9dwG+KyJvJPl9QA3wWuEVEKpzRQBiYK/+ngR1AWkQqgJuBc0sPW7pmZ2fdDsGsgeXP2/yav6teE9DsEOEKUA40Ltj/Q1X99rUOrKq/q6phVa0DDgDfVdV/CTwJ/JbT7X7gG87rR51tnPbvqtfmtFijQCDgdghmDSx/3ubX/K10i+hDwL8ne17+D0XkP67T9/wI8CERedY59pec/V8Ctjj7PwR8dJ2+n2csPt9tvMXy521+zd9Kp4PuBppUdUZEbgL+AfjD1XwTVe0Gup3Xoyxzd5GqXgHeuprjG2OMWZ2VbhH9harOAKjqJXLvFjLGGFMCVhoJ/JKIPO28FuAOZ1vIXjJ4TcGjM8YYU1ArFYF/smFRGCB7z7vxLsuft/k1fys9J/AdVX3TBsdzTaX8nIAxxhTCaqeSfmWB4jFX4ddFLUqF5c/b/Jq/lU4H3Swi/+xqjar6VwWIx9d2797tdghmDSx/3ubX/K00ErgZ2A/802W+9hc+NP+x01zeZvnzNr/mb6WRwE9U9V9tWCRmycRnxlssf97m1/ytNBKw5wKMMabErVQE3nmtN9t8/8YY420rFYH/V0Q+ICK3LdwpIjeKyBtE5GFenvDNGF/LZDJ0dXUtmQPemGK3UhG4F5gBHhGRn4rIsIiMAiPA24HPqOpfbECMvtHY2HjtTqYodXV18dOf/pRDhw65HYpZJb9+/laaSvqKqv6pqt4F3A7sA+KqeruqHlTVH25YlD6xeCUq4w2ZTIbDhw+jqhw+fNhGAx7l18/fSiOBear6kqqOqeqFQgfkZ2VleaXDFJmurq75BUlmZ2dtNOBRfv38+fOnLlLl5eVuh2BWobu7e34t4Onpabq7u90NyKyKXz9/VgSKyOIF0I03dHR0UFGRfeSmoqKCjo4OdwMyq+LXz981i4CIfCqffcb4VWdn5/yphLKyMg4cOOByRMbkL5+RwD3L7Pv19Q7EGK8KBoPs27cPgH379rF582aXIzImfyutMfyAiPwIaBCRpxd8pYCnr/Y+Y/yos7OT2tpaGwUYz1lp7qD/BXwL+L/JXfR9QlUzBY3Kp2pqatwOwaxSMBjk4MGDNgrwML9+/q66qMx8h0VPDM9R1ecLEtE12KIyxhhzfVa7qMycvwMec/49DIySHSGYdebXRS1KheXP2/yav5VOBwGgqr+8cFtE4sD7ChaRj/l1UYtSYfnzNr/m77qfE1DVQaC1ALH4Xl9fn9shmDWw/HmbX/N3zZGAiHxowWYZEAd+WrCIfOzy5ctuh2DWwPLnbX7NXz4jgeoFXwGy1wbuu9abRGSTiPxARIZEJCEif+Dsj4hIn4g8KyJdInKjsz/gbD/rtNet9ocyxhiTn3yuCcz98q7JbupEnseeAt6gqpMicgPQIyLfAj4EfFpVD4nInwHvAR5y/j2vqq8WkQPAp4DO6/+RjDHG5CufaSNanIfGngZ+5Pxlv+ytRgtp1tyinTc4Xwq8Afi6s/9h4C3O6/ucbZz2fbZymTHGFNY1RwLAl4H3qeo/AIhIu7PvNdd6o4iUAwPAq4H/BjwHXFDVaadLGqh1XtcCpwBUdVpEXgS2AD9beMyxsTEaGhrmt/fv38/BgweJRCIkk0lisRhHjx5dEktbWxupVIpwOMz4+DinTp3Kaa+trSUcDpNKpYhGo/T09Cw5Rnt7O8lkkkgkQjqd5vTp0zntO3bsIBQKkU6niUQi9Pb2LjnGnj17SCQSRKNRUqkUZ86cmW+bmZnh5MmTBINBxsfHCYfDSy5WiQh79+5laGiIWCxGMpnk7NmzOX127txJdXU1mUyGUCjE4ucqKioqaG9vZ3BwkObmZhKJBOfOncvpU19fTyAQYHJykmAwyODgYE57IBCgra2NgYEBdu/ezdDQ0JJ59BsaGigvL+fKlStUV1czNDSU015ZWUlra+v8MQYHB7l48WJOn127djEzM8Ps7CyBQIDjx4/ntFdVVdHS0jJ/jP7+/iULhjc2NjI1NUVZWRnl5eVLJgqrqakhHo/PH6Ovr2/J+eGmpiYmJibYtGkTMzMznDhxIqd98+bNNDU1zR+jt7d3yfz08XicTCZDVVUVU1NTjIyM5LRv2bKFWCzGsWPHiMfj9PT0zM9OOqelpYXx8XGCwSATExOMjo7mtG/dupVoNEoikaCpqYkjR46w+Fmg1tZW0uk0oVCITCbDyZMnc9q3bdtWEp8ngLq6urw/T42NjQwPD5f052k5+Tws9kNVfe2ifYOqGr/m0V/ufwvw18B/BP5CVV/t7N8BfEtVG0XkOHCvqqadtueAVlXNKQKl/LDY888/z223LftsnvEAy5+3lXL+VnpYLJ+RwBER+QLwCNnTOZ1At/O8wNwtoytS1Qsi8iTQBtwiIhXOaCAMzJX/08AOIC0iFcDNwLllD1iiNm3a5HYIZg0sf97m1/zlUwSanH9/b9H+1/LyOf4lROSVwEtOAagkOxvpp4Angd8CDpFdqP4bzlsedbZ7nfbv6rWGKSVmZmbG7RDMGlj+vM2v+cvn7qDXr/LY24GHnesCZcBfqupjIjIMHBKR/wz8EPiS0/9LwH8XkWeBDOC76RhPnDjB9u3b3Q7DrJLlz9v8mr98HhYLAP8cqFvYX1U/vtL7VPVpsqOFxftHgdcts/8K8NZrRmyMMWbd5HM66BvAi2Tv8pm6Rl9jjDEekk8RCKvqvQWPxBhjzIbLZ9qI74vIL1+7m1krW5DE2yx/3ubX/F31OQHnKWElO1qoJ7uOwBQgZB8IvubDYoVQys8JGGNMIax2UZn9wD8lu6j8q4E3Odtz+8068+uiFqXC8uddmUyGD3zgA0ue0vWDqxYBVf2Jqv4EmFjmy6aSLgC/LmpRKix/3tXV1cXzzz/PoUOH3A5lw+VzTWAQeAFIAiPO65MiMigi9n/9OlpubhTjHZY/b8pkMhw+fBhV5fDhw74bDeRTBJ4A3qyqt6rqFrKnhx4ju8TknxYyOL9ZPOGY8RbLnzd1dXUxOzsLwOzsrO9GA/kUgTtV9dtzG6r6HaBNVZ8iu8iMMcZ4Vnd39/xsrdPT03R3d7sb0AbLpwiMichHROR25+s/AOPOdBCzBY7PGGMKqqOjg4qK7CNTFRUVdHR0uBvQBsunCPwLsrN9/o3zdZuzrxx4W+FCM8aYwuvs7KSsLPursKysjAMH/DVtWT4TyP0M+MBVmp9d33D8LR7Pe4kGU4Qsf94UDAbZt28fjz/+OPv27fPdQ2P5TCD3JNmHxnKo6rJTSJvVy2Qy1NTUuB2GWSXLn3d1dnaSTCZ9NwqA/OYO+vCC15vIzig6fZW+Zg2qqqrcDsGsgeXPu4LBIB/72Md8NwqA/E4HLX4M8nsi8oMCxeNrdouht1n+vM2v+bvmhWERCS74ulVEfo3s0o9mnS1eeNx4i+XP2/yav3xOBw2QvSYgZE8DpYD3FDIoY4wxGyOf00GRjQjEGGPMxsvn7qAbgAeAPc6ubuALqvpSAeMyxhizAfI5HfQQcAMvzxP0286+f12ooPxqy5Ytbodg1sDy521+zV8+ReBXVLVpwfZ3RWSoUAH5WSwWczsEswaWP2/za/7ymTZiRkTumNsQkZ3ATOFC8q9jx465HYJZA8uft/k1f/k+LPakiIySvUPoduDdBY3Kp2zaAW+z/HmbX/O34kjAmSm0iewaw/+O7BxCDar65AbE5js9PT1uh2DWwPLnbX7N34pFQFVngLer6pSqPu185fVYnYjsEJEnRWRYRBIi8jvO/qCIPCEiI86/m539IiKfE5FnReRpEfFdWZ6b09x4k+XP2/yav3yuCXxPRD4vIneLSHzuK4/3TQP/p6ruAu4E3i8iu4CPAodVtR447GxDdsWyeufrvWTvQDLGGFNA+VwTaHb+/fiCfQqsOIuoqo4BY87rCRF5BqgF7gM6nG4Pk33u4CPO/q+qqgJPicgtIrLdOY4xRS2TydDV1UVTU5MvJyEz3pXPE8OvX+s3EZE64LVAHxBa8Iv9DBByXtcCpxa8Le3ssyJgil5XVxenT5/m0KFDPPDAA26HY0ze8nliOEB2+ui6hf1V9eNXe8+i91cB/z/wQVW9KCLzbaqqIrJkrYKVjI2N0dDQML+9f/9+Dh48SCQSIZlMEovFOHr06JL3tbW1kUqlCIfDjI+Pc+rUqZz22tpawuEwqVSKaDS67EWi9vZ2kskkkUiEdDrN6dOnc9p37NhBKBQinU4TiUTo7e1dcow9e/aQSCSIRqOkUinOnDkz3zY7O8vJkycJBoOMj48TDofp6+vLeb+IsHfvXoaGhojFYiSTSc6ePZvTZ+fOnVRXV5PJZAiFQvT39+e0V1RU0N7ezuDgIM3NzSQSCc6dO5fTp76+nkAgwOTkJMFgkMHBwZz2QCBAW1sbAwMD7N69m6GhIc6fP5/Tp6GhgfLycq5cuUJ1dTVDQ7mPl1RWVtLa2jp/jMHBQS5evJjTZ9euXczMzDA7O0sgEOD48eM57VVVVbS0tMwfo7+/n8nJyZw+jY2NTE1NUVZWRnl5OcPDwzntNTU1xOPx+WP09fVx+fLlnD5NTU1MTEywadMmZmZmOHHixHzb5OQkTzzxBABPPPEEBw4c4Mc//vGSWSnj8TiZTIaqqiqmpqaWTFi2ZcsWYrEYx44dIx6P09PTs+Q8dUtLC+Pj4wSDQSYmJhgdHc1p37p1K9FolEQiQVNTE0eOHCE7uH5Za2sr6XSaUChEJpPh5MmTOe3btm0ric8TQF1dXd6fp+bmZoaHh0v687QcWfw/yJIOIo8DL5KdSG7++QBV/eNrHjw75cRjwLdV9U+cfSeADlUdE5HtQLeqNojIF5zXjyzut/CYLS0tujgJpeK5557jjjvuuHZHU1QeeughnnjiCaanp6moqOCee+6x0YAHlfLnT0QGVLVlubZ8LgyHVbVTVf+rqv7x3Fce31SALwHPzBUAx6PA/c7r+4FvLNj/TucuoTuBF/12PSAYDLodglmF7u7u+b/Yp6en6e7udjcgsyp+/fzlUwS+LyK/vIpj30V2nqE3iMgx5+vNwCeBe0RkBHijsw3wTWCU7LrFXwTet4rv6WkTExNuh2BWoaOjg4qK7JnSiooKOjo63A3IrIpfP39XvSYgIseBWafPu50nhqfIPjWsqvqalQ6sqj1O3+XsW6a/Au/PM+6SNDo6ym233eZ2GOY6dXZ28vd///dA9hyzH9epLQV+/fytdGG4lpdvDzXGXEUwGGTbtm2cOnWK7du32y2ixlNWKgIpVf3JhkVijEdlMpn5u1LGxsY4f/68FYIC+OIXv0gqlSrIscfGxpiamuI73/nOuh87Eolw8ODBdT/uelmpCGwVkQ9drXHRxV5jfKurq2v+NkxVtWcFPOjy5cu+nTZipSJQDlRx9fP6Zp1t3brV7RDMKix3d5AVgfVXyL+mH3zwQX7+85/ziU98omDfo1itVATG8n0gzKyPaDTqdghmFTo6OnKeE7C7g7zppptucjsEV6x0i6iNADZYIpFwOwSzCp2dnZSVZT9KZWVldneQR/385z93OwRXrFQEltzGaQqrqanp2p1M0QkGg+zbtw8RYd++fXZR2KOqqqrcDsEVVy0CqprZyEAMHDlyxO0QzCp1dnZSW1trowAPu3DhgtshuCKfJ4bNBrnWPE6meAWDQd72trfZKMB4jhUBY4zxMSsCxhjjY1YEjDHGx6wIFJHW1la3QzBrYPnztpqaGrdDcIUVgSKSTqfdDsGsgeXP2xavBOcXVgSKSCgUunYnU7Qsf952ww03uB2CK6wIFJFMxh7N8DLLn7f5dQI5KwJFZPGC38ZbLH/eduXKFbdDcMVKE8iZDZTJZOjq6qKpqckeODKeVsh5/wtldHSU6elpHnzwQbdDydt6rVNgRaBIdHV1cfr0aZuL3nheKpXimWeeobKy0u1Q8vbSSy8B3hnNXb58ed2OZUWgCGQyGQ4fPgzA4cOHOXDggI0GjKdVVlbS0NDgdhgl68SJE+t2LLsmUAS6urqYmZkBYHZ2luW6lksAAA9ySURBVEOHDrkckVmNbdu2uR2CMdfNikAR6O7uni8CcytTGe+JRCJuh2DMdbPTQUXgzjvv5Mknn5zfbmtrczGa0laoi5ZjY2O89NJL3Hbbbet+7GJfqNx4mxUBY9bBel6oM2YjWREoAr29vTnb3//+9/ngBz/oUjSlrVB/UT/44INcuHDBlwuVG28r2DUBEfmyiJwVkeML9gVF5AkRGXH+3ezsFxH5nIg8KyJPi0i8UHEVo1e+8pU521u3bnUpEmOM3xTywvBfAPcu2vdR4LCq1gOHnW2AXwfqna/3Ag8VMK6ic/bs2Zzt8fFxlyIxxvhNwYqAqh4FFk+mch/wsPP6YeAtC/Z/VbOeAm4Rke2Fiq3YLP7L3yYiM8ZslI2+RTSkqmPO6zPA3G+7WuDUgn5pZ58v2EjAGOMW1y4Mq6qKyHWvrD42NpbzJOL+/fs5ePAgkUiEZDJJLBbj6NGjS97X1tZGKpUiHA4zPj7OqVOnctpra2sJh8OkUimi0Sg9PT1LjtHe3k4ymSQSiZBOpzl9+nRO+44dOwiFQqTTaSKRyJILvgB79uwhkUgQjUZJpVKcOXOGV7ziFTlzmd96662MjIwQDofp6+vLeb+IsHfvXoaGhojFYiSTySVFZOfOnVRXV5PJZAiFQvT39+e0V1RU0N7ezuDgIM3NzSQSCc6dO5fTp76+nkAgwOTkJMFgkMHBwZz2QCBAW1sbAwMD7N69m6GhIc6fP5/Tp6GhgfLycq5cuUJ1dTVDQ0M57ZWVlbS2ts4fY3BwkIsXL+b02bVrFzMzM8zOzhIIBDh+/HhOe1VVFS0tLfPH6O/vZ3JyMqdPY2MjU1NTlJWVUV5ezvDwcE57TU0N8Xh8/hh9fX1L7vZpampiYmKCTZs2MTMzs+SJzcnJSWpqauaP0dvbu2R++ng8TiaToaqqiqmpKUZGRnLat2zZQiwW49ixY8TjcXp6epbMbNnS0sL4+DjBYJCJiQlGR0dz2rdu3Uo0GiWRSNDU1MSRI0dQzf2Ytba2kk6nCYVCZDKZJVMlbNu2bU2fpwsXLizpb9bfhQsXcp4pyufztBxZ/D/IehKROuAxVW10tk8AHao65pzu6VbVBhH5gvP6kcX9Fh+zpaVFF/9S87q3vvWtOb8wAoEAX/va11yMyFyvBx98kEuXLvGZz3zG7VBc9+53v5vz589z0003uR1Kybp06RKbN2/mK1/5Sl79RWRAVVuWa9vo00GPAvc7r+8HvrFg/zudu4TuBF5crgCUKrsmUBoCgYDbIRhz3Qp2OkhEHgE6gFtFJA38HvBJ4C9F5D3AT4C3Od2/CbwZeBa4BLy7UHEVoxdeeCFne/HpHb/x6lTEs7OznpqKGArzNPL27duZmpqyCeQK6MSJE2zfvj73zhSsCKjq26/StG+Zvgq8v1CxFLu2tracaSN+9Vd/1cVo3GdTEW8Me8rZgD0xbIqUTUVceOs5HbHxLptFtAgsN22EMcZsBCsCRcCmjTDGuMWKQBGwh8WMMW6xIlAE7BZRY4xbrAgUAbtF1BjjFrs7qAjE4/Gci8G7d+92MRpj1u7y5cueuvto7ol9rzzwt56391oRKALPPffcitvGeIkX11oeHR1lenqauro6t0PJ23r9d7YiUAQWXwg+c+aMS5EYs3ZeXA/ZzyvDWRG4Ths1pcF6Tz9gi5UbY5ZjRaAIVFdXMzExkbPtZ2NjY1y6dMlT55S96NKlS4yN+WaeRnMVVgSuUyH+ms5kMrzrXe+a3/785z/P5s2b1/37GGPMYlYEikAwGJwfDdx1112+LwA2C+XGWM+ZKEvBzTff7HYIrrDnBIrEq171KgKBAO9973vdDsUYX7p06ZLbIbjCikCRuOGGG7jjjjt8Pwowxi1emrp8PdnpoCKyeE1aY8zLCnlnXiEXBSr2O/NsJFBErAgY447KykoqKvz5N7E/f2pT9GzagcLz2spihf5ruru7m46OjoJ+j2JUskXAa+vUzj22bmvU2rQDG8mL/63N+irZIuC1dWptjdqXFfP506vx87QDxttKtgiArVNbaF46XbMRvHQqyCy1Y8cOt0NwhV0YNmad3HjjjW6HYNbAr4s5WREwZp3Y3V3elk6n3Q7BFSV7OsgmISs8L05AVqgbBkZHR4H1n/0Viv8+81Lh14vkNhIwZh1UVlZSVmYfJy/r7e11OwRXFNVIQETuBT4LlAN/rqqfXO2xtm/fzoULF9YttkLz4n3mIuK5CcgK+Re1X+8zN95WNEVARMqB/wbcA6SBfxSRR1V1eDXHK9TQbmxsrCC3Rs7MzKCq3HDDDet+bMj+pVqIX9h+HUIbUyqKpggArwOeVdVRABE5BNwHrKoIFOovvkKdUx4bG2NqaqpgDxvZeWVjzHKKqQjUAqcWbKeB1sWdxsbGcu79379/PwcPHiQSiZBMJonFYhw9enTJwdva2kilUoTDYcbHxzl16lROe21tLeFwmFQqRTQapaenZ8kx2tvbueuuu3jHO95BOp3m9OnTOe07duwgFAqRTqeJRCLLnmPcs2cPiUSCaDRKKpXKWU94cnKSxsZGgsEg4+PjhMNh+vr6ct4vIuzdu5ehoSFisRjJZJKzZ8/m9Nm5cyfV1dVkMhlCoRD9/f1A9nQFQEVFBe3t7QwODtLc3EwikeDcuXM5x6ivrycQCDA5OUkwGGRwcDCnPRAI0NbWxsDAALt372ZoaIjz58/n9GloaKC8vJwrV65QXV3N0NBQTntlZSWtra3zxxgcHOTixYs5fXbt2sXMzAyzs7MEAgGOHz+e015VVUVLS8v8Mfr7+5mcnMzp09jYyNTUFGVlZZSXlzM8nPt3RU1NDfF4fP4YfX19S0Z7TU1NTExMsGnTJmZmZpbccDA3++vcMXp7e5fcLRSPx8lkMlRVVTE1NcXIyEhO+5YtW4jFYhw7dox4PE5PTw/T09M5fVpaWhgfHycYDDIxMTF/QXrO1q1biUajJBIJmpqaOHLkCKqa06e1tZV0Ok0oFCKTySx5QHHbtm0b9nlKJpNEIpGCfJ4A6urq8v48qSrDw8N5f57meOnztBxZ/D+IW0Tkt4B7VfVfO9u/DbSq6r9d2K+lpUUXJ6FUzM7O2sVFD7P8eVsp509EBlS1Zbm2YvqJTwMLH9kLO/t8I5FIuB2CWQPLn7f5NX/FVAT+EagXkYiI3AgcAB51OaYNFY1G3Q7BrIHlz9v8mr+iKQKqOg38W+DbwDPAX6qqr0qzl2Y9NUtZ/rzNr/krmiIAoKrfVNWoqt6hqv/F7Xg22uKLWsZbLH/e5tf8FVUR8Lu//du/dTsEswaWP2/za/6sCBSRxx57zO0QzBpY/rzNr/mzImCMMT5WNM8J5EtEXgB+4nYcBXIr8DO3gzCrZvnztlLO3+2q+srlGjxXBIwxxqwfOx1kjDE+ZkXAGGN8zIrABhCRyUXb7xKRzzuv/42IvPMa75/vb9aXiKiI/I8F2xUi8oKIXNetIiLSLSItzutvisgt6x2rWb3Fn0HzsmKaRdSXVPXP3I7B534ONIpIpapeJruexZrmrFLVN69LZMZsABsJuExEfl9EPuy8/hUReVpEjonIH4nIwnmTXyUij4vIiIj8V5fCLVXfBH7Def124JG5BhF5hYh8WUR+ICI/FJH7nP2VInJIRJ4Rkb8GKhe856SI3CoidQtzKCIfFpHfd153i8inRaTfOcaviMhfOfn9zxvwM/ueiDSLyFPOZ+6vRWSziGwVkQGnvckZKd7mbD8nIje5G/X6syKwMSqdX+zHROQY8PGr9PsK8H+oajMws6itGegEfhnoFJEdi99sVu0QcEBENgGvARZOOv8x4Luq+jrg9cAficgrgAeAS6r6T4DfA3av4vv+wpne98+AbwDvBxqBd4nIllX/NCZfXwU+oqqvAX4E/J6qngU2iUgNcDfQD9wtIrcDZ1X1knvhFoadDtoYl51f7ED2HD+QM7e3cw65WlXnVs74X8D+BV0Oq+qLTt9h4HZyF+Exq6SqT4tIHdlRwDcXNb8J+M250RqwCbgN2AN8bsH7n17Ft56bJfdHQEJVxwBEZJTstOrnrvZGszYicjNwi6oecXY9DHzNef194C6yOf4EcC8gwD9sdJwbwYqAdyxcpmoGy916exT4f4AOYOFf4QL8c1XNWUpMRPI55jS5o+1Ni9rncjpLbn5nsfy66SjZUcDtZEdoHwEU+Ds3gyoUOx1UJFT1AjAhInNLah5wMx4f+jLwB6r6o0X7vw18QJzf+iLyWmf/UeBfOPsayZ5GWmwc2CoiW0QkQO7IzrjIGVWfF5G7nV2/DcyNCv4BeAcwoqqzQAZ4M7B0jcwSYH9tFJf3AF8UkVmy/0O+6HI8vqGqaZzTO4v8IfAZ4GkRKQNSZH+ZPwR8RUSeIbv+xcAyx3xJRD4O/IDsHUc/LlD45tpuEpH0gu0/Ae4H/sy52DsKvBtAVU86RX9uceUeIKyquYv+lgibNqKIiEiVqk46rz8KbFfV33E5LGNMCbORQHH5DRH5XbJ5+QnwLnfDMcaUOhsJGGOMj9mFYWOM8TErAsYY42NWBIwxxsesCBhfymdWSRH54HrPFSMirxKRrzuvm0XEJpszrrIiYMzVfRBY1yKgqj9V1d9yNpvJPoRkjGusCBhfE5EOZ0bPr4vIj0Xkf0rWvwNeBTwpIk86fd8kIr0iMigiXxORKmf/SRH5A2f/j0Tkl5z9exdMHPhDEamem1lURG4kO5Fgp9Pe6cwg+krnvWUi8uzctjGFYkXAGHgt2b/6dwE7gbtU9XPAT4HXq+rrReRW4P8C3qiqcbKzS35owTF+5ux/CJibbO7DwPudyQPvBi7PdVbVXwD/CehS1WZV7QL+B/AvnS5vBIZU9YWC/MTGOKwIGAM/UNW0M0/MMaBumT53ki0S33OmA7+f7ARjc/7K+Xdgwfu/B/yJM6q4RVWnrxHHl4G5Veb+FdmpxY0pKHti2Jj8ZmgV4AlVffs1jjH/flX9pIj8Hdnz/t8TkV8DrlwtCFU9JSLjIvIG4HW8PCowpmBsJGDM1U0A1c7rp4C7ROTVML/iWHSlN4vIHar6I1X9FPCPwC+tcPw5f072tNDXVHXxwkLGrDsrAsZc3f8HPC4iTzrn5t8FPOIsINPL0l/qi33QuQj8NPAS8K1F7U8Cu+YuDDv7HgWqsFNBZoPY3EHGFBERaQE+rap3X7OzMevArgkYUySc6cMfwK4FmA1kIwFjjPExuyZgjDE+ZkXAGGN8zIqAMcb4mBUBY4zxMSsCxhjjY1YEjDHGx/43bGvaibjQ1iEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax=sns.boxplot(x=\"Intensity\", y=\"box_output\", data=df, color='grey')\n",
        "ax.grid('both', linestyle='-.')\n",
        "ax.set_ylabel('Throughput (TPS)')\n",
        "ax.set_axisbelow(True)\n",
        "ax.tick_params(axis='both', direction='in')\n",
        "#plt.savefig('Throughput.eps', format='eps', dpi=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UHEpBCU-pouD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "37ffabb6-6163-4cb4-df0b-ebeffa841340"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax1=sns.boxplot(x=\"Intensity\", y=\"Latency\", data=df, color='grey')\n",
        "ax1.grid('both', linestyle='-.')\n",
        "ax1.set_ylabel('Latency (seconds)')\n",
        "ax1.set_axisbelow(True)\n",
        "ax1.tick_params(axis='both', direction='in')\n",
        "#plt.savefig('Latency.eps', format='eps', dpi=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ntDBSGoemyq2"
      },
      "outputs": [],
      "source": [
        "# Make dummies for our catagorial variables to make it able to insert to machine learning models\n",
        "df_all = df.copy()\n",
        "df_all_dum = pd.get_dummies(df_all, prefix=['Intensity'], columns=['Intensity'])\n",
        "#uncomment next line to show all values\n",
        "# df_all_dum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P9dZn52kqQxj"
      },
      "outputs": [],
      "source": [
        "# We will try to convert the intenisty to ordinal numbers and see the difference in accurcy using pycaret \n",
        "df_all_ordinal = df.copy()\n",
        "df_all_ordinal = df_all_ordinal.replace({\"Intensity\":{\"Low\": 23600, \"Medium\": 35788, \"High\":143362 }})\n",
        "#uncomment next line to show all values\n",
        "# df_all_ordinal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoSSXm7bPja0"
      },
      "source": [
        "### Comparison between different Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305qRGc4aKuZ",
        "outputId": "6bedff2c-1e12-4139-91ee-22c29b5be774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.7/dist-packages (2.3.5)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.post1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.22.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.5)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.19.0)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.5)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.9.7)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.3.2)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.1.0)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.1.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (3.0.6)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.9.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (4.10.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.9.0)\n",
            "Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.6)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.7.4)\n",
            "Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.12.0)\n",
            "Requirement already satisfied: PyYAML>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (6.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (4.2.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.9.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.12.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (5.0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.16.2)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.18.7)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.1.26)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.29)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (20.1.0)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.1.6)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow->pycaret) (1.2.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (5.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.12.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (1.17)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn->pycaret) (0.5.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4756-TDtmw_P"
      },
      "outputs": [],
      "source": [
        "from pycaret.regression import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFNR3iRz_Zh"
      },
      "source": [
        "### Predict box_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-cZM0QEI05Bb"
      },
      "outputs": [],
      "source": [
        "#for dummy variable approche\n",
        "df_ouput_dum = df_all_dum.copy()\n",
        "df_ouput_dum.drop('Latency', axis=1, inplace=True)\n",
        "\n",
        "#for numerical ordinal variable approche\n",
        "df_ouput_ord = df_all_ordinal.copy()\n",
        "df_ouput_ord.drop('Latency', axis=1, inplace=True)\n",
        "\n",
        "#uncomment one of next line to show it's values\n",
        "# df_ouput_dum\n",
        "# df_ouput_ord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36a278388d9b49f9b5de9743a0d0fcac",
            "2592615ad6af4bdb97df3e28eb017ecf",
            "757f3a6850864f9b87049a1b335c1597",
            "485d10ef5b3749aaab80585ddc9d3a1b",
            "d371e6093af74c05b0dd43f501355e6c",
            "a91a445d620c4de4b4c60d11f767df46"
          ]
        },
        "id": "WdBVzOiSmxCz",
        "outputId": "20a23f08-d226-40d7-9330-aa5b9b09389e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0af2b008-5386-4027-8e84-433f7b67fa5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>box_output</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(190, 4)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(132, 3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(58, 3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>KFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>reg-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>USI</td>\n",
              "      <td>d615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Transform Target</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Transform Target Method</td>\n",
              "      <td>box-cox</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0af2b008-5386-4027-8e84-433f7b67fa5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0af2b008-5386-4027-8e84-433f7b67fa5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0af2b008-5386-4027-8e84-433f7b67fa5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               123\n",
              "1                                   Target        box_output\n",
              "2                            Original Data          (190, 4)\n",
              "3                           Missing Values             False\n",
              "4                         Numeric Features                 3\n",
              "5                     Categorical Features                 0\n",
              "6                         Ordinal Features             False\n",
              "7                High Cardinality Features             False\n",
              "8                  High Cardinality Method              None\n",
              "9                    Transformed Train Set          (132, 3)\n",
              "10                    Transformed Test Set           (58, 3)\n",
              "11                      Shuffle Train-Test              True\n",
              "12                     Stratify Train-Test             False\n",
              "13                          Fold Generator             KFold\n",
              "14                             Fold Number                10\n",
              "15                                CPU Jobs                -1\n",
              "16                                 Use GPU             False\n",
              "17                          Log Experiment             False\n",
              "18                         Experiment Name  reg-default-name\n",
              "19                                     USI              d615\n",
              "20                         Imputation Type            simple\n",
              "21          Iterative Imputation Iteration              None\n",
              "22                         Numeric Imputer              mean\n",
              "23      Iterative Imputation Numeric Model              None\n",
              "24                     Categorical Imputer          constant\n",
              "25  Iterative Imputation Categorical Model              None\n",
              "26           Unknown Categoricals Handling    least_frequent\n",
              "27                               Normalize             False\n",
              "28                        Normalize Method              None\n",
              "29                          Transformation             False\n",
              "30                   Transformation Method              None\n",
              "31                                     PCA             False\n",
              "32                              PCA Method              None\n",
              "33                          PCA Components              None\n",
              "34                     Ignore Low Variance             False\n",
              "35                     Combine Rare Levels             False\n",
              "36                    Rare Level Threshold              None\n",
              "37                         Numeric Binning             False\n",
              "38                         Remove Outliers             False\n",
              "39                      Outliers Threshold              None\n",
              "40                Remove Multicollinearity             False\n",
              "41             Multicollinearity Threshold              None\n",
              "42             Remove Perfect Collinearity              True\n",
              "43                              Clustering             False\n",
              "44                    Clustering Iteration              None\n",
              "45                     Polynomial Features             False\n",
              "46                       Polynomial Degree              None\n",
              "47                    Trignometry Features             False\n",
              "48                    Polynomial Threshold              None\n",
              "49                          Group Features             False\n",
              "50                       Feature Selection             False\n",
              "51                Feature Selection Method           classic\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                        Transform Target             False\n",
              "57                 Transform Target Method           box-cox"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "exp_reg101 = setup(data = df_ouput_ord, target = 'box_output', numeric_features = ['Block_period','Block_size','Intensity'], session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735,
          "referenced_widgets": [
            "25c5d9d9d3964495be264e0ff8d500cb",
            "fec14db65329472f9bbeee1995be08ef",
            "4b7d927da08c405496facf56cdae8572"
          ]
        },
        "id": "jTM74Tb5aAlu",
        "outputId": "ecebf964-aa68-4bc4-f976-44a86417438f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5463037f-ea73-4397-91ef-cb3afd200143\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "      <td>6.6435</td>\n",
              "      <td>1091.4478</td>\n",
              "      <td>15.8759</td>\n",
              "      <td>0.9408</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>0.0777</td>\n",
              "      <td>0.360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbr</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>7.4212</td>\n",
              "      <td>1035.6056</td>\n",
              "      <td>15.4335</td>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.1331</td>\n",
              "      <td>0.1084</td>\n",
              "      <td>0.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>8.6183</td>\n",
              "      <td>1315.5203</td>\n",
              "      <td>18.7493</td>\n",
              "      <td>0.9153</td>\n",
              "      <td>0.1486</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Regressor</td>\n",
              "      <td>11.1159</td>\n",
              "      <td>1369.2500</td>\n",
              "      <td>23.7514</td>\n",
              "      <td>0.8443</td>\n",
              "      <td>0.2016</td>\n",
              "      <td>0.1531</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Regressor</td>\n",
              "      <td>15.0304</td>\n",
              "      <td>2354.4702</td>\n",
              "      <td>29.8594</td>\n",
              "      <td>0.7688</td>\n",
              "      <td>0.2682</td>\n",
              "      <td>0.1859</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>AdaBoost Regressor</td>\n",
              "      <td>21.0480</td>\n",
              "      <td>1770.2670</td>\n",
              "      <td>31.9032</td>\n",
              "      <td>0.6751</td>\n",
              "      <td>0.6505</td>\n",
              "      <td>0.9295</td>\n",
              "      <td>0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>19.0264</td>\n",
              "      <td>2245.2876</td>\n",
              "      <td>32.4069</td>\n",
              "      <td>0.6616</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.4558</td>\n",
              "      <td>0.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llar</th>\n",
              "      <td>Lasso Least Angle Regression</td>\n",
              "      <td>27.2688</td>\n",
              "      <td>3245.0144</td>\n",
              "      <td>41.1229</td>\n",
              "      <td>0.4665</td>\n",
              "      <td>0.6910</td>\n",
              "      <td>1.0097</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>br</th>\n",
              "      <td>Bayesian Ridge</td>\n",
              "      <td>28.3402</td>\n",
              "      <td>2885.7628</td>\n",
              "      <td>40.2005</td>\n",
              "      <td>0.4179</td>\n",
              "      <td>0.7734</td>\n",
              "      <td>1.4871</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>28.5719</td>\n",
              "      <td>2897.3036</td>\n",
              "      <td>40.3545</td>\n",
              "      <td>0.4093</td>\n",
              "      <td>0.7838</td>\n",
              "      <td>1.5357</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lasso</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>28.7809</td>\n",
              "      <td>2897.8530</td>\n",
              "      <td>40.4761</td>\n",
              "      <td>0.4013</td>\n",
              "      <td>0.8018</td>\n",
              "      <td>1.5803</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>28.8415</td>\n",
              "      <td>2897.1509</td>\n",
              "      <td>40.5109</td>\n",
              "      <td>0.3988</td>\n",
              "      <td>0.8023</td>\n",
              "      <td>1.5948</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>28.8453</td>\n",
              "      <td>2897.0189</td>\n",
              "      <td>40.5125</td>\n",
              "      <td>0.3986</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>1.5957</td>\n",
              "      <td>0.279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lar</th>\n",
              "      <td>Least Angle Regression</td>\n",
              "      <td>28.8458</td>\n",
              "      <td>2897.1771</td>\n",
              "      <td>40.5137</td>\n",
              "      <td>0.3986</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>1.5957</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huber</th>\n",
              "      <td>Huber Regressor</td>\n",
              "      <td>32.1434</td>\n",
              "      <td>5127.1389</td>\n",
              "      <td>51.1921</td>\n",
              "      <td>0.2601</td>\n",
              "      <td>1.0815</td>\n",
              "      <td>0.9496</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omp</th>\n",
              "      <td>Orthogonal Matching Pursuit</td>\n",
              "      <td>32.6134</td>\n",
              "      <td>3918.3942</td>\n",
              "      <td>50.6036</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>0.9187</td>\n",
              "      <td>1.3668</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Regressor</td>\n",
              "      <td>44.5952</td>\n",
              "      <td>5233.1223</td>\n",
              "      <td>60.2192</td>\n",
              "      <td>-0.2737</td>\n",
              "      <td>1.2653</td>\n",
              "      <td>2.7355</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>par</th>\n",
              "      <td>Passive Aggressive Regressor</td>\n",
              "      <td>245.8966</td>\n",
              "      <td>151473.4188</td>\n",
              "      <td>293.6684</td>\n",
              "      <td>-164.9846</td>\n",
              "      <td>2.6131</td>\n",
              "      <td>19.8490</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5463037f-ea73-4397-91ef-cb3afd200143')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5463037f-ea73-4397-91ef-cb3afd200143 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5463037f-ea73-4397-91ef-cb3afd200143');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model       MAE          MSE      RMSE  \\\n",
              "et                  Extra Trees Regressor    6.6435    1091.4478   15.8759   \n",
              "gbr           Gradient Boosting Regressor    7.4212    1035.6056   15.4335   \n",
              "rf                Random Forest Regressor    8.6183    1315.5203   18.7493   \n",
              "dt                Decision Tree Regressor   11.1159    1369.2500   23.7514   \n",
              "knn                 K Neighbors Regressor   15.0304    2354.4702   29.8594   \n",
              "ada                    AdaBoost Regressor   21.0480    1770.2670   31.9032   \n",
              "lightgbm  Light Gradient Boosting Machine   19.0264    2245.2876   32.4069   \n",
              "llar         Lasso Least Angle Regression   27.2688    3245.0144   41.1229   \n",
              "br                         Bayesian Ridge   28.3402    2885.7628   40.2005   \n",
              "en                            Elastic Net   28.5719    2897.3036   40.3545   \n",
              "lasso                    Lasso Regression   28.7809    2897.8530   40.4761   \n",
              "ridge                    Ridge Regression   28.8415    2897.1509   40.5109   \n",
              "lr                      Linear Regression   28.8453    2897.0189   40.5125   \n",
              "lar                Least Angle Regression   28.8458    2897.1771   40.5137   \n",
              "huber                     Huber Regressor   32.1434    5127.1389   51.1921   \n",
              "omp           Orthogonal Matching Pursuit   32.6134    3918.3942   50.6036   \n",
              "dummy                     Dummy Regressor   44.5952    5233.1223   60.2192   \n",
              "par          Passive Aggressive Regressor  245.8966  151473.4188  293.6684   \n",
              "\n",
              "                R2   RMSLE     MAPE  TT (Sec)  \n",
              "et          0.9408  0.1055   0.0777     0.360  \n",
              "gbr         0.9367  0.1331   0.1084     0.038  \n",
              "rf          0.9153  0.1486   0.1099     0.408  \n",
              "dt          0.8443  0.2016   0.1531     0.013  \n",
              "knn         0.7688  0.2682   0.1859     0.060  \n",
              "ada         0.6751  0.6505   0.9295     0.048  \n",
              "lightgbm    0.6616  0.6280   0.4558     0.052  \n",
              "llar        0.4665  0.6910   1.0097     0.013  \n",
              "br          0.4179  0.7734   1.4871     0.012  \n",
              "en          0.4093  0.7838   1.5357     0.012  \n",
              "lasso       0.4013  0.8018   1.5803     0.013  \n",
              "ridge       0.3988  0.8023   1.5948     0.012  \n",
              "lr          0.3986  0.8024   1.5957     0.279  \n",
              "lar         0.3986  0.8024   1.5957     0.011  \n",
              "huber       0.2601  1.0815   0.9496     0.019  \n",
              "omp         0.0484  0.9187   1.3668     0.012  \n",
              "dummy      -0.2737  1.2653   2.7355     0.011  \n",
              "par      -164.9846  2.6131  19.8490     0.013  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
              "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                    max_samples=None, min_impurity_decrease=0.0,\n",
              "                    min_impurity_split=None, min_samples_leaf=1,\n",
              "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
              "                    random_state=123, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umHIw6RPQFdz"
      },
      "source": [
        "***After we apply pycaret regression with intensity numeric ordinal and dummies variables, we note that max accurcy for dummies approch with is with gradiant boast regressor with R2 = .93 and for numeric ordinal. the best model is extra tree regressor with R2 = .94 so numeric approch is slightly better than dummies variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GmOLfbpLg4Rh",
        "outputId": "473d84e8-6e3c-44ee-cc86-502761c88c98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1f2081f0-4b65-4697-834b-617edd51e429\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f2081f0-4b65-4697-834b-617edd51e429')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f2081f0-4b65-4697-834b-617edd51e429 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f2081f0-4b65-4697-834b-617edd51e429');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  Intensity\n",
              "0             1          13     143362\n",
              "1             2          13     143362\n",
              "2             3          13     143362\n",
              "3             4          13     143362\n",
              "4             5          13     143362"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#split our data to y that contain our output \"box_output\" and to x that conatin the featuers inputs for our model\n",
        "y_output=df_ouput_ord[\"box_output\"]\n",
        "x_output=df_ouput_ord.copy()\n",
        "x_output.drop(columns = ['box_output'],inplace = True)\n",
        "x_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xd5-bduDhY5A"
      },
      "outputs": [],
      "source": [
        "#split x,y to train and test to measure the accurcy of the model\n",
        "X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.2, random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TsKho5Cv-l58"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "def reg_out(rand):\n",
        "  for i in range(rand):\n",
        "    print('random state is',i)\n",
        "    X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.1, random_state = i)\n",
        "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0,bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                        max_samples=None, min_impurity_decrease=0.0,\n",
        "                        min_impurity_split=None, min_samples_leaf=1,\n",
        "                        min_samples_split=2, min_weight_fraction_leaf=0.0,n_jobs=-1, oob_score=False,\n",
        "                        verbose=0, warm_start=False).fit(X_train_output, y_train_output)\n",
        "\n",
        "    R2_score = reg.score(X_test_output, y_test_output)\n",
        "    print(\"R2 score for this model is\", R2_score)\n",
        "    y_pred_output = reg.predict(X_test_output)\n",
        "    MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "    RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "    print(\"RMSE score for this model is\", RMSE)\n",
        "\n",
        "# reg_out(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgyWKILeLeLm",
        "outputId": "507b0219-6655-4c65-d25c-100b053a7255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for this model is 0.9968461133890045\n",
            "RMSE score for this model is 1.562639467459835\n"
          ]
        }
      ],
      "source": [
        "#from above equation we can note that the best random state is 1 to make model learning well and generlize for validation data\n",
        "X_train_output, X_test_output, y_train_output, y_test_output = train_test_split(x_output, y_output, test_size = 0.1, random_state = 1)\n",
        "reg = ExtraTreesRegressor(n_estimators=100, random_state=0,bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_output, y_train_output)\n",
        "\n",
        "R2_score = reg.score(X_test_output, y_test_output)\n",
        "print(\"R2 score for this model is\", R2_score)\n",
        "\n",
        "y_pred_output = reg.predict(X_test_output)\n",
        "MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "print(\"RMSE score for this model is\", RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfKR52myGGLE",
        "outputId": "0967092e-0d69-4666-8b46-41bcd203a7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 1.5626394674598347\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse_out = mean_squared_error(y_test_output, y_pred_output)\n",
        "sk_rmse_out = sk_mse_out**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NilPkG6CGPeJ",
        "outputId": "d7d22d02-cc79-412b-bb57-f832540d058d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -19.935052 using {'criterion': 'mse', 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#define your own mse and set greater_is_better=False\n",
        "# mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
        "\n",
        "etr = ExtraTreesRegressor(n_estimators=100).fit(X_train_output, y_train_output)\n",
        "                            \n",
        "param_grid = {\n",
        "    'n_estimators': [100,120,130,150],\n",
        "    'criterion': ['mse', 'mae'],\n",
        "    'max_depth': [80,100,110],\n",
        "    #'oob_score': [True, False],\n",
        "    'max_features': ['auto','sqrt','log2'],  \n",
        "    #'bootstrap': [True, False],\n",
        "    #'warm_start': [True, False],\n",
        "    'min_samples_split': [1,2]\n",
        "}\n",
        "\n",
        "gcv = GridSearchCV(etr,param_grid,scoring='neg_root_mean_squared_error',cv=5,n_jobs=-1).fit(x_output,y_output)\n",
        "\n",
        "# grid_result = gsc.fit(x_output, y_output)\n",
        "\n",
        "print(\"Best: %f using %s\" % (gcv.best_score_, gcv.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySmK3crQIPhu"
      },
      "source": [
        "## Visualizations\n",
        "### actual and predicted box_output vs Model featuers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "myyAI0ERL8qJ",
        "outputId": "83947e06-0b6d-4f6b-dd8d-2e067bba1b7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a25aa55-9dfb-4969-b478-da4ed4e26ec1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity</th>\n",
              "      <th>actual_output</th>\n",
              "      <th>pred_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>89</td>\n",
              "      <td>89.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>43</td>\n",
              "      <td>43.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>28</td>\n",
              "      <td>28.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>20</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>143362</td>\n",
              "      <td>17</td>\n",
              "      <td>17.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a25aa55-9dfb-4969-b478-da4ed4e26ec1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a25aa55-9dfb-4969-b478-da4ed4e26ec1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a25aa55-9dfb-4969-b478-da4ed4e26ec1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  Intensity  actual_output  pred_output\n",
              "0             1          13     143362             89        89.00\n",
              "1             2          13     143362             43        43.00\n",
              "2             3          13     143362             28        28.00\n",
              "3             4          13     143362             20        20.00\n",
              "4             5          13     143362             17        17.41"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#combine x_output,y_output and y_pred_all on one table to be able to visiualize it\n",
        "y_pred_alloutput = reg.predict(x_output)\n",
        "\n",
        "df_vis_output = x_output.copy()\n",
        "df_vis_output['actual_output'] = y_output\n",
        "df_vis_output['pred_output'] = y_pred_alloutput\n",
        "df_vis_output.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance of ExtraTreeRegressor for Throughput"
      ],
      "metadata": {
        "id": "RtVAvarsbjHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "iu0M4r1lILCS",
        "outputId": "e1e1fcc1-e77d-424f-faa9-a67e8e4f5aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Error: -5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa3e539cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = [20, 10])\n",
        "base_color = sns.color_palette()[0]\n",
        " \n",
        "# plt.subplot(1, 2, 1)\n",
        "# # plot Block_period VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_period', y='actual_output', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_period', y='pred_output', color='red')\n",
        "# plt.title('Block_period vs actual and prdicted output')\n",
        "# plt.ylabel('Output')\n",
        "# plt.xlabel('Block_period')\n",
        "# plt.legend(['actual_output', 'pred_output'], loc='upper right')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plot Block_size VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_size', y='actual_output', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_output, x='Block_size', y='pred_output', color='red')\n",
        "# plt.title('Block_size vs actual and predicted output')\n",
        "# plt.ylabel('Output')\n",
        "# plt.xlabel('Block_size')\n",
        "# plt.legend(['actual_output', 'pred_output'], loc='upper right')\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "#to see the relationship between the predicted values using scattered graph\n",
        "## test\n",
        "\n",
        "## residuals\n",
        "residuals = y_test_output - y_pred_output\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true  = y_test_output.get(max_idx)\n",
        "max_pred = y_pred_output[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))\n",
        "\n",
        "from statsmodels.graphics.api import abline_plot\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "ax.scatter(y_pred_output, y_test_output, color=\"black\")\n",
        "abline_plot(intercept=0, slope=1, color=\"red\", ax=ax)\n",
        "#ax[0].vlines(x=max_pred, ymin=max_true, ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "ax.grid(True)\n",
        "ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs Actual Throughput\")\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "## Plot predicted vs residuals\n",
        "# ax[1].scatter(y_pred_output, residuals, color=\"red\")\n",
        "# ax[1].vlines(x=max_pred, ymin=0, ymax=max_error, color='black', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "# ax[1].grid(True)\n",
        "# ax[1].set(xlabel=\"Predicted\", ylabel=\"Residuals\", title=\"Predicted vs Residuals\")\n",
        "# ax[1].hlines(y=0, xmin=np.min(y_pred_output), xmax=np.max(y_pred_output))\n",
        "# ax[1].legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R9U-GzuQY1c"
      },
      "source": [
        "##Implement Gaussian Process Regression model for predicting Throughput and Latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa1M_3B1iYeT",
        "outputId": "a54363a0-54da-478f-e199-473d8da26554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianProcessRegressor(alpha=0.1, copy_X_train=True,\n",
              "                         kernel=1**2 * RBF(length_scale=10),\n",
              "                         n_restarts_optimizer=10, normalize_y=True,\n",
              "                         optimizer='fmin_l_bfgs_b', random_state=None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Import gussian prosess from sklearn library and handle it's parameter then start to train our data using it\n",
        "import sklearn.gaussian_process as gp\n",
        "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
        "gp_model_output = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
        "gp_model_output.fit(X_train_output, y_train_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx_PdxAVUlYc",
        "outputId": "c763b782-43d4-4f6c-80b4-35d213f1cf53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30.71535485, 30.71535485, 30.71535485])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#example of how to predict value using gaussian_process model\n",
        "gp_model_output.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iizbavFwiwER"
      },
      "outputs": [],
      "source": [
        "#Get y_pred to measure the accurcy using it and y_test\n",
        "y_pred_output = gp_model_output.predict(X_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-d4gDHsizGy",
        "outputId": "ce360a8e-722a-406c-9abe-986c48dc739a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5380304856525395"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#here we are measure the mean squre error and root mean squre error\n",
        "MSE = ((y_pred_output-y_test_output)**2).mean()\n",
        "RMSE = (((y_pred_output-y_test_output)**2).mean())**.5\n",
        "#show the value of root mean squre error\n",
        "RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKq_6RihjEnW",
        "outputId": "ff91778d-42f0-4747-e83c-daec47ceed97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9838321735469169"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#Getting the R2 score (accurcy of regression model) from model\n",
        "gp_model_output.score(X_test_output, y_test_output )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ajsop0jkrB6",
        "outputId": "054f0e9b-5a38-451f-872b-dd94b194879e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98383217, 0.9759058 , 0.69685348, 0.93174674, 0.76728646,\n",
              "       0.98917274, 0.91729934, 0.97032897, 0.924163  , 0.89926481])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#Implement the cross validation to get accurcy using different sets and get mean of all scores that will express the accurcy solving overfitting problem\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "# evaluate model\n",
        "scores = cross_val_score(gp_model_output, x_output, y_output, cv=cv, n_jobs=-1)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOBkEHAwyEOv",
        "outputId": "b390e124-9c38-4dc3-de10-d52c64e50628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9055853524777833"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXL4m2xtRDfd"
      },
      "source": [
        "##Implement Regression Neural Network Model to predict Throughput\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zy5tR2JxB9vu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zmeMf7alCCEK"
      },
      "outputs": [],
      "source": [
        "nu_model = Sequential()\n",
        "nu_model.add(Dense(units=32, activation='relu', input_shape=[X_train_output.shape[1]]))\n",
        "nu_model.add(Dropout(0.1))\n",
        "nu_model.add(Dense(units=64, activation='relu'))\n",
        "nu_model.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "jvaRyNUzCFRT"
      },
      "outputs": [],
      "source": [
        "nu_model.compile(loss='mean_squared_error', optimizer=Adam())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WGMkgU0jCIxz"
      },
      "outputs": [],
      "source": [
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                         patience = 200,\n",
        "                         verbose = 1,\n",
        "                         factor = 0.75,\n",
        "                         min_lr = 1e-4)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsdUKIsXCPl0",
        "outputId": "76b53624-9a3c-4595-f7c5-5c5cf4515d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                128       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,305\n",
            "Trainable params: 2,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nu_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvqlD9KDCSgU",
        "outputId": "5779995f-007a-4411-e65a-f6b3f94e89ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 49ms/step - loss: 9419625.0000 - val_loss: 118814.5078 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6195337.0000 - val_loss: 758443.0625 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3718576.2500 - val_loss: 32538.9922 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4440325.0000 - val_loss: 1174619.5000 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2038668.2500 - val_loss: 15808.6680 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1902865.1250 - val_loss: 126958.4297 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1302629.7500 - val_loss: 6989.2480 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1512342.8750 - val_loss: 241565.9375 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1135751.5000 - val_loss: 51224.0234 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1204385.0000 - val_loss: 171158.4062 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 796367.1250 - val_loss: 236069.8906 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 994138.5625 - val_loss: 2428.9175 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 362343.2500 - val_loss: 54393.9492 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 856327.8125 - val_loss: 398186.4062 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 759900.7500 - val_loss: 6125.5234 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 725884.0625 - val_loss: 193580.9375 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 570601.8750 - val_loss: 53211.0156 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 411114.0625 - val_loss: 166981.0781 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 540939.3125 - val_loss: 20067.8438 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 286779.5000 - val_loss: 72607.4141 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 369801.0625 - val_loss: 19975.2148 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 329084.8125 - val_loss: 63279.1719 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 332038.4062 - val_loss: 12007.8994 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 256237.1250 - val_loss: 16919.0801 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 438394.6875 - val_loss: 82241.8984 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 206667.1250 - val_loss: 4519.6855 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 353608.2188 - val_loss: 133218.7500 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 252481.6250 - val_loss: 41330.5195 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 223343.2344 - val_loss: 247848.5781 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 354676.2188 - val_loss: 44371.0859 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 170457.9062 - val_loss: 113154.9844 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 216758.1406 - val_loss: 15714.6553 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 204351.0938 - val_loss: 34446.8555 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 349907.8750 - val_loss: 8120.6377 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 219855.1094 - val_loss: 9465.4766 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 157483.9531 - val_loss: 2444.1829 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 110373.4219 - val_loss: 3013.5742 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 174888.9375 - val_loss: 4544.5273 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 161350.4688 - val_loss: 3374.8433 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 167253.4844 - val_loss: 9290.1094 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 216720.9688 - val_loss: 23223.3496 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 327577.7500 - val_loss: 6852.0293 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 294476.5625 - val_loss: 73058.1016 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 246948.3750 - val_loss: 13501.9355 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 207902.3906 - val_loss: 7235.1279 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 123971.4297 - val_loss: 14935.4531 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 128433.2188 - val_loss: 62171.8203 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 114177.4688 - val_loss: 70457.7109 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269673.8750 - val_loss: 12154.8281 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 239562.9375 - val_loss: 8299.2910 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 459051.8438 - val_loss: 47641.8672 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 131077.2969 - val_loss: 84362.7109 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 172660.6406 - val_loss: 24937.0527 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 304004.7812 - val_loss: 4739.8970 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 269386.2188 - val_loss: 137252.1094 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 317329.3438 - val_loss: 69135.8672 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 208237.7344 - val_loss: 43466.2031 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 136680.9844 - val_loss: 12411.6309 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 186658.0000 - val_loss: 40778.9297 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 355889.9375 - val_loss: 129335.5000 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 235286.2031 - val_loss: 159127.9062 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 189904.7344 - val_loss: 135370.6719 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291667.0000 - val_loss: 71485.7734 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 122602.6875 - val_loss: 37762.1367 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 129853.0000 - val_loss: 2628.2310 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 176615.8438 - val_loss: 30238.3828 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 158765.6719 - val_loss: 3406.6794 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 90587.4844 - val_loss: 2277.0640 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 108181.0156 - val_loss: 12318.6826 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 134453.0625 - val_loss: 7776.1035 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 121674.4297 - val_loss: 2203.2312 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 134264.3594 - val_loss: 34467.8477 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 189319.6094 - val_loss: 19924.9785 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 114657.2734 - val_loss: 18205.1250 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 95647.4141 - val_loss: 7277.5864 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 85023.5703 - val_loss: 25625.3125 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 232707.8750 - val_loss: 69436.8203 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 279045.0312 - val_loss: 2523.4587 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 102835.2500 - val_loss: 3653.0857 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 139943.1875 - val_loss: 11423.3037 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 139215.5781 - val_loss: 2347.1885 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57605.2109 - val_loss: 4157.7930 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 109911.7578 - val_loss: 48690.5625 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 192222.9844 - val_loss: 18672.7637 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 78867.5000 - val_loss: 2364.1382 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 73949.4844 - val_loss: 3861.9941 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 132427.6094 - val_loss: 5265.2681 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 61993.8672 - val_loss: 2455.2017 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 78949.8125 - val_loss: 4061.4919 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53627.8672 - val_loss: 7806.9731 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 83438.4062 - val_loss: 7192.8809 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 65865.9453 - val_loss: 11666.8105 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 51627.5430 - val_loss: 2684.3667 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 170861.5156 - val_loss: 6648.4819 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 68122.9375 - val_loss: 4857.9976 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 114268.7969 - val_loss: 14332.7939 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 127393.4375 - val_loss: 18391.3086 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 38478.9258 - val_loss: 2619.7112 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 73615.0625 - val_loss: 10645.6436 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 123685.2812 - val_loss: 21603.9199 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 60933.2656 - val_loss: 3055.1497 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 148535.3594 - val_loss: 2821.4141 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 95700.7422 - val_loss: 2796.0181 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39909.9258 - val_loss: 4045.9785 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 88233.2578 - val_loss: 3057.8691 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 55302.6953 - val_loss: 6746.7646 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59824.7031 - val_loss: 15862.2236 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 85128.3984 - val_loss: 21287.3887 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 82451.7891 - val_loss: 9010.0781 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 95272.3906 - val_loss: 2348.5515 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43018.0430 - val_loss: 4722.5469 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 111021.9375 - val_loss: 6936.0264 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 68812.7109 - val_loss: 8358.1182 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 72345.1328 - val_loss: 15861.7158 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 60844.4492 - val_loss: 9164.0635 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 92046.9609 - val_loss: 24181.4844 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 73412.5938 - val_loss: 25124.6426 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 178209.0625 - val_loss: 26597.4570 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 76126.2344 - val_loss: 3930.8245 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 80219.8438 - val_loss: 2420.9075 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57278.2734 - val_loss: 19778.2012 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 88400.6484 - val_loss: 3090.1536 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 44219.6484 - val_loss: 2214.7908 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 100543.5625 - val_loss: 5396.8374 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 102128.5469 - val_loss: 3312.7412 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 112691.2812 - val_loss: 2540.4021 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 122459.9453 - val_loss: 2233.6785 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 77410.8672 - val_loss: 11221.9932 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 51255.3789 - val_loss: 7894.7114 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73011.6484 - val_loss: 14428.9766 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 43192.4062 - val_loss: 3281.5264 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 42057.8359 - val_loss: 13135.5781 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 83233.4453 - val_loss: 3743.6353 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 56105.5898 - val_loss: 3726.4807 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 91485.5156 - val_loss: 6682.4829 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32076.1992 - val_loss: 2273.0742 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 96067.2344 - val_loss: 7502.3257 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 59657.9219 - val_loss: 2296.4656 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73500.5938 - val_loss: 8369.3252 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 43896.9492 - val_loss: 6984.5581 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43920.7812 - val_loss: 2239.5283 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 55335.3008 - val_loss: 12017.7021 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 144559.3906 - val_loss: 4888.5146 - lr: 0.0010\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 71375.7734 - val_loss: 2268.8682 - lr: 0.0010\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 46620.0859 - val_loss: 3718.5115 - lr: 0.0010\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 46016.2461 - val_loss: 7620.6895 - lr: 0.0010\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 59325.6094 - val_loss: 3247.0823 - lr: 0.0010\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 54980.8086 - val_loss: 10977.4893 - lr: 0.0010\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32561.9590 - val_loss: 14820.5283 - lr: 0.0010\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 65051.7266 - val_loss: 7544.5054 - lr: 0.0010\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 145021.5625 - val_loss: 23839.4648 - lr: 0.0010\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 88095.8750 - val_loss: 2681.3782 - lr: 0.0010\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 56534.2500 - val_loss: 63012.0938 - lr: 0.0010\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 105616.7734 - val_loss: 21836.1191 - lr: 0.0010\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 66377.8516 - val_loss: 42771.1289 - lr: 0.0010\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 138444.1094 - val_loss: 28322.1992 - lr: 0.0010\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 73217.4062 - val_loss: 27260.8184 - lr: 0.0010\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 133396.2812 - val_loss: 20444.9785 - lr: 0.0010\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 88809.8906 - val_loss: 60613.7656 - lr: 0.0010\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 99528.9062 - val_loss: 5339.0845 - lr: 0.0010\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 56978.5781 - val_loss: 12535.1924 - lr: 0.0010\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 128897.9844 - val_loss: 2939.8643 - lr: 0.0010\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 78869.8828 - val_loss: 13811.7891 - lr: 0.0010\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 66779.1406 - val_loss: 16580.8672 - lr: 0.0010\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42126.8438 - val_loss: 10896.1963 - lr: 0.0010\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42341.7188 - val_loss: 3862.8674 - lr: 0.0010\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 66723.8750 - val_loss: 2950.9121 - lr: 0.0010\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 173943.2344 - val_loss: 5367.7026 - lr: 0.0010\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31911.3086 - val_loss: 3397.9343 - lr: 0.0010\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 55091.2461 - val_loss: 3948.7214 - lr: 0.0010\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48640.8008 - val_loss: 2521.8789 - lr: 0.0010\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 44947.2461 - val_loss: 28571.8574 - lr: 0.0010\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 76760.5312 - val_loss: 3361.2273 - lr: 0.0010\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 87387.9062 - val_loss: 9544.2656 - lr: 0.0010\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40379.1562 - val_loss: 2641.5076 - lr: 0.0010\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41302.3398 - val_loss: 11648.4219 - lr: 0.0010\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43718.4258 - val_loss: 9934.4658 - lr: 0.0010\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 65469.9492 - val_loss: 10909.4648 - lr: 0.0010\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 135275.9062 - val_loss: 56858.1602 - lr: 0.0010\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 119393.5625 - val_loss: 6772.1284 - lr: 0.0010\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53820.4570 - val_loss: 2428.5054 - lr: 0.0010\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40853.8828 - val_loss: 76147.9844 - lr: 0.0010\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 121515.4453 - val_loss: 7888.9922 - lr: 0.0010\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 66523.6172 - val_loss: 37731.6016 - lr: 0.0010\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57228.1289 - val_loss: 2262.8630 - lr: 0.0010\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 57052.1016 - val_loss: 2742.3174 - lr: 0.0010\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 43262.7500 - val_loss: 4129.1338 - lr: 0.0010\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 25302.5469 - val_loss: 2357.3435 - lr: 0.0010\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 41565.3125 - val_loss: 8128.1206 - lr: 0.0010\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38009.4609 - val_loss: 2541.8479 - lr: 0.0010\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 54214.8750 - val_loss: 5587.2651 - lr: 0.0010\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32657.3086 - val_loss: 44177.8984 - lr: 0.0010\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 93865.8047 - val_loss: 4800.0479 - lr: 0.0010\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 58839.8633 - val_loss: 25757.6328 - lr: 0.0010\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59853.6289 - val_loss: 3631.0813 - lr: 0.0010\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59862.1602 - val_loss: 11785.3340 - lr: 0.0010\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 68311.8125 - val_loss: 2936.2432 - lr: 0.0010\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52773.3711 - val_loss: 18586.0215 - lr: 0.0010\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 43321.2188 - val_loss: 2217.0032 - lr: 0.0010\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 54700.2578 - val_loss: 2179.6646 - lr: 0.0010\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 106217.8281 - val_loss: 13394.2949 - lr: 0.0010\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 44746.6289 - val_loss: 2887.0920 - lr: 0.0010\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24359.7930 - val_loss: 4741.3125 - lr: 0.0010\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 48549.8398 - val_loss: 4479.8496 - lr: 0.0010\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41401.0781 - val_loss: 7670.5806 - lr: 0.0010\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39693.4844 - val_loss: 2334.9082 - lr: 0.0010\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 19865.5156 - val_loss: 4560.5103 - lr: 0.0010\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42906.8555 - val_loss: 8365.3818 - lr: 0.0010\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 50384.9531 - val_loss: 5226.0938 - lr: 0.0010\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 39322.6836 - val_loss: 11985.1846 - lr: 0.0010\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27518.3379 - val_loss: 2843.3982 - lr: 0.0010\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28933.3984 - val_loss: 2201.6431 - lr: 0.0010\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 69569.7656 - val_loss: 2410.9402 - lr: 0.0010\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 79850.4141 - val_loss: 2184.0869 - lr: 0.0010\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 82458.5078 - val_loss: 3345.5581 - lr: 0.0010\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25545.5859 - val_loss: 9832.4170 - lr: 0.0010\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42757.0938 - val_loss: 11931.0430 - lr: 0.0010\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 43053.5352 - val_loss: 13481.2861 - lr: 0.0010\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39722.5820 - val_loss: 2469.2620 - lr: 0.0010\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 47407.2383 - val_loss: 6216.2446 - lr: 0.0010\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19856.2422 - val_loss: 8540.1338 - lr: 0.0010\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31110.6074 - val_loss: 3058.9473 - lr: 0.0010\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 29870.7402 - val_loss: 7173.0063 - lr: 0.0010\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49360.1719 - val_loss: 4243.6768 - lr: 0.0010\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 163228.5781 - val_loss: 2680.9497 - lr: 0.0010\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31896.0586 - val_loss: 16849.3535 - lr: 0.0010\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 85115.6250 - val_loss: 5118.4565 - lr: 0.0010\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36064.4297 - val_loss: 3935.3999 - lr: 0.0010\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 39912.2695 - val_loss: 17872.1875 - lr: 0.0010\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26087.4102 - val_loss: 2565.4192 - lr: 0.0010\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40635.5273 - val_loss: 4580.6978 - lr: 0.0010\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57839.6289 - val_loss: 2378.5535 - lr: 0.0010\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27554.5254 - val_loss: 5127.9585 - lr: 0.0010\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31908.3418 - val_loss: 12194.7627 - lr: 0.0010\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 62161.8438 - val_loss: 8671.6396 - lr: 0.0010\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73332.2188 - val_loss: 64974.2305 - lr: 0.0010\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 64412.9648 - val_loss: 18318.2188 - lr: 0.0010\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 53094.2070 - val_loss: 33265.9492 - lr: 0.0010\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 58879.1914 - val_loss: 5199.8374 - lr: 0.0010\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 23448.7344 - val_loss: 2638.3149 - lr: 0.0010\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 108468.8984 - val_loss: 9339.4570 - lr: 0.0010\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 46757.8594 - val_loss: 11707.9014 - lr: 0.0010\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32252.7422 - val_loss: 7339.0698 - lr: 0.0010\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 38473.9375 - val_loss: 4088.0281 - lr: 0.0010\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35384.5156 - val_loss: 21043.9180 - lr: 0.0010\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 28997.8789 - val_loss: 2416.8015 - lr: 0.0010\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32290.9258 - val_loss: 2919.0300 - lr: 0.0010\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49021.0117 - val_loss: 7639.2739 - lr: 0.0010\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22654.5059 - val_loss: 2668.5952 - lr: 0.0010\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29969.4746 - val_loss: 6443.9248 - lr: 0.0010\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59416.7109 - val_loss: 4682.7212 - lr: 0.0010\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 28760.0117 - val_loss: 2481.7061 - lr: 0.0010\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32165.8457 - val_loss: 2166.6611 - lr: 0.0010\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14518.1543 - val_loss: 4701.7109 - lr: 0.0010\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27830.7383 - val_loss: 3156.6575 - lr: 0.0010\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27676.8418 - val_loss: 2197.2661 - lr: 0.0010\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43146.1016 - val_loss: 13127.6553 - lr: 0.0010\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26854.7285 - val_loss: 2350.2612 - lr: 0.0010\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 21918.1777 - val_loss: 3249.3789 - lr: 0.0010\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25749.1562 - val_loss: 4336.3896 - lr: 0.0010\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36066.6289 - val_loss: 3301.0544 - lr: 0.0010\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40868.4688 - val_loss: 2753.7097 - lr: 0.0010\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 50155.4883 - val_loss: 5371.7163 - lr: 0.0010\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 20403.5547 - val_loss: 2816.2490 - lr: 0.0010\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27546.7070 - val_loss: 23537.0586 - lr: 0.0010\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28311.3223 - val_loss: 27043.4902 - lr: 0.0010\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26506.0078 - val_loss: 2850.1570 - lr: 0.0010\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 16576.3555 - val_loss: 14489.8691 - lr: 0.0010\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 65116.7578 - val_loss: 3701.7300 - lr: 0.0010\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 28121.6738 - val_loss: 2317.0649 - lr: 0.0010\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 26653.8730 - val_loss: 7883.9976 - lr: 0.0010\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 31523.8828 - val_loss: 2307.4805 - lr: 0.0010\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 28000.2676 - val_loss: 2496.4673 - lr: 0.0010\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40821.9023 - val_loss: 2313.2314 - lr: 0.0010\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 25299.0430 - val_loss: 3755.5933 - lr: 0.0010\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38911.8008 - val_loss: 38579.5469 - lr: 0.0010\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 104041.6719 - val_loss: 23677.7012 - lr: 0.0010\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41979.3516 - val_loss: 2892.1821 - lr: 0.0010\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30286.9941 - val_loss: 16132.9336 - lr: 0.0010\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 68087.3828 - val_loss: 17654.0977 - lr: 0.0010\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53143.6875 - val_loss: 8677.9971 - lr: 0.0010\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 109364.2422 - val_loss: 2692.5554 - lr: 0.0010\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 42282.7188 - val_loss: 49107.8398 - lr: 0.0010\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 71604.6875 - val_loss: 9182.9521 - lr: 0.0010\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32870.2891 - val_loss: 2313.2534 - lr: 0.0010\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 37672.1914 - val_loss: 3322.3579 - lr: 0.0010\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32593.5039 - val_loss: 30593.7246 - lr: 0.0010\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33364.5703 - val_loss: 4175.9111 - lr: 0.0010\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41199.7852 - val_loss: 2216.4709 - lr: 0.0010\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35024.6836 - val_loss: 12915.2012 - lr: 0.0010\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 44407.0352 - val_loss: 5628.1699 - lr: 0.0010\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29887.4004 - val_loss: 2160.8240 - lr: 0.0010\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24359.9531 - val_loss: 6812.7847 - lr: 0.0010\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 30273.7188 - val_loss: 7876.5239 - lr: 0.0010\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 30732.0352 - val_loss: 2261.4363 - lr: 0.0010\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 26541.0527 - val_loss: 2155.8242 - lr: 0.0010\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 26865.0586 - val_loss: 6067.2759 - lr: 0.0010\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32426.8594 - val_loss: 25439.4512 - lr: 0.0010\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 46784.7734 - val_loss: 2602.6445 - lr: 0.0010\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 19111.5195 - val_loss: 6762.6104 - lr: 0.0010\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 17265.0371 - val_loss: 3989.4316 - lr: 0.0010\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19953.5352 - val_loss: 2287.4834 - lr: 0.0010\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38639.8281 - val_loss: 2154.5076 - lr: 0.0010\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 22712.6484 - val_loss: 2698.7544 - lr: 0.0010\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 27223.9980 - val_loss: 3796.9241 - lr: 0.0010\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 30779.4414 - val_loss: 8928.8604 - lr: 0.0010\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29415.8379 - val_loss: 9367.2881 - lr: 0.0010\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 40202.7539 - val_loss: 3841.1375 - lr: 0.0010\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28415.1113 - val_loss: 2190.5591 - lr: 0.0010\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39533.5117 - val_loss: 3251.4265 - lr: 0.0010\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29511.0371 - val_loss: 9984.7383 - lr: 0.0010\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 40357.9453 - val_loss: 2470.8806 - lr: 0.0010\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38742.8086 - val_loss: 11722.5889 - lr: 0.0010\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28053.1133 - val_loss: 15849.8379 - lr: 0.0010\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 46779.5117 - val_loss: 4423.6323 - lr: 0.0010\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 29878.7910 - val_loss: 5788.7568 - lr: 0.0010\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20287.0469 - val_loss: 6582.1157 - lr: 0.0010\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32989.6211 - val_loss: 3158.4680 - lr: 0.0010\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33896.1523 - val_loss: 12122.4180 - lr: 0.0010\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26880.0156 - val_loss: 4143.8706 - lr: 0.0010\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19090.8574 - val_loss: 2658.9097 - lr: 0.0010\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36638.8867 - val_loss: 9887.7168 - lr: 0.0010\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 45809.2148 - val_loss: 28246.5391 - lr: 0.0010\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49079.7344 - val_loss: 17975.5020 - lr: 0.0010\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 49741.7773 - val_loss: 2474.7542 - lr: 0.0010\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 47397.8164 - val_loss: 39285.9102 - lr: 0.0010\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53086.7773 - val_loss: 45221.8672 - lr: 0.0010\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 71506.2969 - val_loss: 4691.4302 - lr: 0.0010\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 51257.0820 - val_loss: 10236.2344 - lr: 0.0010\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 58809.2227 - val_loss: 89619.6562 - lr: 0.0010\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 79694.7422 - val_loss: 25957.9922 - lr: 0.0010\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43966.3047 - val_loss: 4442.4399 - lr: 0.0010\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22651.4043 - val_loss: 18442.0664 - lr: 0.0010\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25193.9043 - val_loss: 5109.6646 - lr: 0.0010\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24236.8984 - val_loss: 2409.0452 - lr: 0.0010\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22344.3359 - val_loss: 4313.3364 - lr: 0.0010\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23418.4902 - val_loss: 14188.6611 - lr: 0.0010\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22746.6660 - val_loss: 9366.0176 - lr: 0.0010\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27757.8047 - val_loss: 2819.4839 - lr: 0.0010\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 37333.6836 - val_loss: 4756.0654 - lr: 0.0010\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 52481.0898 - val_loss: 4242.4741 - lr: 0.0010\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 21430.2227 - val_loss: 15114.0801 - lr: 0.0010\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39874.2383 - val_loss: 4181.5034 - lr: 0.0010\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 23761.0605 - val_loss: 6445.9180 - lr: 0.0010\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 22088.7715 - val_loss: 2197.0352 - lr: 0.0010\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24868.6367 - val_loss: 13036.7783 - lr: 0.0010\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 17664.4883 - val_loss: 2214.1340 - lr: 0.0010\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 18654.2246 - val_loss: 23916.5352 - lr: 0.0010\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 66606.8594 - val_loss: 36454.9375 - lr: 0.0010\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38574.8008 - val_loss: 13936.6875 - lr: 0.0010\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 68847.0859 - val_loss: 9270.7822 - lr: 0.0010\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39470.7852 - val_loss: 2900.6277 - lr: 0.0010\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24543.7656 - val_loss: 2713.8586 - lr: 0.0010\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31607.8574 - val_loss: 2143.1021 - lr: 0.0010\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35629.1836 - val_loss: 31120.0508 - lr: 0.0010\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 62449.2188 - val_loss: 10705.0254 - lr: 0.0010\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 51805.2266 - val_loss: 2143.5779 - lr: 0.0010\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28849.8398 - val_loss: 2822.2515 - lr: 0.0010\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35684.8789 - val_loss: 11035.7764 - lr: 0.0010\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23698.2812 - val_loss: 4410.6562 - lr: 0.0010\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 25568.9902 - val_loss: 9884.5049 - lr: 0.0010\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25730.3594 - val_loss: 4182.6929 - lr: 0.0010\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42311.6719 - val_loss: 2630.5925 - lr: 0.0010\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15922.0830 - val_loss: 2146.1709 - lr: 0.0010\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18161.4316 - val_loss: 3044.0251 - lr: 0.0010\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 49374.7422 - val_loss: 2971.0979 - lr: 0.0010\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16238.6377 - val_loss: 2237.1016 - lr: 0.0010\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14360.1221 - val_loss: 2337.7493 - lr: 0.0010\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15776.4414 - val_loss: 12195.4316 - lr: 0.0010\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20522.3320 - val_loss: 3933.1777 - lr: 0.0010\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14213.2812 - val_loss: 2786.4111 - lr: 0.0010\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23035.3574 - val_loss: 2680.9812 - lr: 0.0010\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16023.9600 - val_loss: 2594.4541 - lr: 0.0010\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 13483.9502 - val_loss: 6968.2661 - lr: 0.0010\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17668.8926 - val_loss: 2303.0649 - lr: 0.0010\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38517.1094 - val_loss: 6861.5269 - lr: 0.0010\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12927.2607 - val_loss: 4202.5605 - lr: 0.0010\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23053.9746 - val_loss: 4595.0669 - lr: 0.0010\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22670.0508 - val_loss: 2181.5562 - lr: 0.0010\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16636.6133 - val_loss: 4570.8511 - lr: 0.0010\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14605.3633 - val_loss: 4221.0757 - lr: 0.0010\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 20856.0918 - val_loss: 2136.3711 - lr: 0.0010\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 24749.1465 - val_loss: 2620.0134 - lr: 0.0010\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23219.2168 - val_loss: 2833.7324 - lr: 0.0010\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30841.6582 - val_loss: 3059.8677 - lr: 0.0010\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22380.3066 - val_loss: 4474.4526 - lr: 0.0010\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14061.3125 - val_loss: 2298.2393 - lr: 0.0010\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20355.6992 - val_loss: 5418.6553 - lr: 0.0010\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 45168.8203 - val_loss: 2633.6938 - lr: 0.0010\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 29853.4082 - val_loss: 6308.2075 - lr: 0.0010\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24942.0234 - val_loss: 6676.0137 - lr: 0.0010\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 62025.6914 - val_loss: 44097.6562 - lr: 0.0010\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 32921.4062 - val_loss: 4337.8467 - lr: 0.0010\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 45826.1914 - val_loss: 51320.1797 - lr: 0.0010\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 60753.4531 - val_loss: 8722.9150 - lr: 0.0010\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24942.2598 - val_loss: 6993.0918 - lr: 0.0010\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33620.8711 - val_loss: 8157.7998 - lr: 0.0010\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 64032.4102 - val_loss: 11586.9092 - lr: 0.0010\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 23963.9648 - val_loss: 3829.1687 - lr: 0.0010\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33735.8320 - val_loss: 2132.7024 - lr: 0.0010\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 27245.7344 - val_loss: 26909.0645 - lr: 0.0010\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 46866.7500 - val_loss: 40747.7930 - lr: 0.0010\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 79310.2656 - val_loss: 49243.5469 - lr: 0.0010\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 94354.7031 - val_loss: 82054.9688 - lr: 0.0010\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 122246.9141 - val_loss: 2367.2493 - lr: 0.0010\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 122259.0000 - val_loss: 72598.6172 - lr: 0.0010\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 71193.9688 - val_loss: 49952.3594 - lr: 0.0010\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 45909.9531 - val_loss: 32802.4609 - lr: 0.0010\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 56614.3906 - val_loss: 6226.2065 - lr: 0.0010\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33290.3281 - val_loss: 14262.1436 - lr: 0.0010\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37380.6680 - val_loss: 3141.3364 - lr: 0.0010\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 54290.7500 - val_loss: 25023.7598 - lr: 0.0010\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42129.5820 - val_loss: 55175.8789 - lr: 0.0010\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41934.9727 - val_loss: 29709.1992 - lr: 0.0010\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41793.0625 - val_loss: 20470.5117 - lr: 0.0010\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34012.9258 - val_loss: 2128.6648 - lr: 0.0010\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35535.9102 - val_loss: 7398.5288 - lr: 0.0010\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16097.0078 - val_loss: 6279.3208 - lr: 0.0010\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23554.8613 - val_loss: 8849.4766 - lr: 0.0010\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17770.0879 - val_loss: 7493.6011 - lr: 0.0010\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30838.2090 - val_loss: 17441.5098 - lr: 0.0010\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29470.1465 - val_loss: 4250.8647 - lr: 0.0010\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 44892.5156 - val_loss: 2790.6135 - lr: 0.0010\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17340.6113 - val_loss: 5626.7061 - lr: 0.0010\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 51911.8516 - val_loss: 52387.5508 - lr: 0.0010\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53312.7734 - val_loss: 8154.6143 - lr: 0.0010\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34484.4062 - val_loss: 9462.0791 - lr: 0.0010\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43008.5195 - val_loss: 4868.5913 - lr: 0.0010\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29143.1738 - val_loss: 97774.4844 - lr: 0.0010\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 77784.1484 - val_loss: 140120.7344 - lr: 0.0010\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 94949.2109 - val_loss: 90459.2031 - lr: 0.0010\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 89390.3750 - val_loss: 31285.0996 - lr: 0.0010\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 100622.4297 - val_loss: 4687.5386 - lr: 0.0010\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 71820.2578 - val_loss: 42643.3789 - lr: 0.0010\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 65967.2422 - val_loss: 23799.4316 - lr: 0.0010\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32644.1992 - val_loss: 6616.9863 - lr: 0.0010\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28764.3906 - val_loss: 2607.4929 - lr: 0.0010\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14980.4297 - val_loss: 3185.5068 - lr: 0.0010\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36957.2461 - val_loss: 2304.7273 - lr: 0.0010\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 17014.8750 - val_loss: 2381.4609 - lr: 0.0010\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18619.2500 - val_loss: 2236.1812 - lr: 0.0010\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13100.6494 - val_loss: 3873.6509 - lr: 0.0010\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24483.6719 - val_loss: 2286.1133 - lr: 0.0010\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11106.4336 - val_loss: 2185.4309 - lr: 0.0010\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32779.1719 - val_loss: 2458.3081 - lr: 0.0010\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15009.1592 - val_loss: 2484.5366 - lr: 0.0010\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13502.4590 - val_loss: 2119.3723 - lr: 0.0010\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19902.7227 - val_loss: 3263.4272 - lr: 0.0010\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30214.3145 - val_loss: 8649.1162 - lr: 0.0010\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27835.1406 - val_loss: 3980.9072 - lr: 0.0010\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14932.9512 - val_loss: 11662.6377 - lr: 0.0010\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 21789.0078 - val_loss: 9035.4033 - lr: 0.0010\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 58443.7930 - val_loss: 2469.5786 - lr: 0.0010\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17860.5059 - val_loss: 6489.0537 - lr: 0.0010\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 21580.3262 - val_loss: 6637.2178 - lr: 0.0010\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15780.1641 - val_loss: 2584.7917 - lr: 0.0010\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10767.5850 - val_loss: 2449.1438 - lr: 0.0010\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13619.3770 - val_loss: 2310.3586 - lr: 0.0010\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12584.3672 - val_loss: 3269.9558 - lr: 0.0010\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13262.1797 - val_loss: 2923.8237 - lr: 0.0010\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29999.5430 - val_loss: 2748.4316 - lr: 0.0010\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 26487.7715 - val_loss: 2477.9185 - lr: 0.0010\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14228.0791 - val_loss: 11751.9609 - lr: 0.0010\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 20680.5352 - val_loss: 6526.6460 - lr: 0.0010\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14840.6758 - val_loss: 5962.9688 - lr: 0.0010\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15378.5908 - val_loss: 9084.6045 - lr: 0.0010\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23253.4434 - val_loss: 12654.8594 - lr: 0.0010\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18011.4043 - val_loss: 3065.9224 - lr: 0.0010\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16018.9941 - val_loss: 2160.5437 - lr: 0.0010\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17837.2969 - val_loss: 2662.4050 - lr: 0.0010\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15484.8105 - val_loss: 2240.3967 - lr: 0.0010\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13612.8896 - val_loss: 2562.1870 - lr: 0.0010\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14269.4795 - val_loss: 3105.4309 - lr: 0.0010\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26004.7656 - val_loss: 5766.0972 - lr: 0.0010\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17642.4434 - val_loss: 7702.4204 - lr: 0.0010\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16352.5518 - val_loss: 4013.5420 - lr: 0.0010\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12436.6699 - val_loss: 2202.2771 - lr: 0.0010\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12383.9521 - val_loss: 2347.9070 - lr: 0.0010\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25662.0215 - val_loss: 2236.3494 - lr: 0.0010\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22857.2598 - val_loss: 4118.8164 - lr: 0.0010\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23469.5312 - val_loss: 2874.3892 - lr: 0.0010\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36258.9180 - val_loss: 2118.6128 - lr: 0.0010\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33657.3281 - val_loss: 24814.1973 - lr: 0.0010\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29475.0840 - val_loss: 11532.8936 - lr: 0.0010\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20786.5527 - val_loss: 11565.8076 - lr: 0.0010\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28806.4355 - val_loss: 30271.9004 - lr: 0.0010\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 45443.1836 - val_loss: 21636.0430 - lr: 0.0010\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 69651.0469 - val_loss: 4310.0400 - lr: 0.0010\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26273.9219 - val_loss: 2207.9878 - lr: 0.0010\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20156.0840 - val_loss: 5111.9126 - lr: 0.0010\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15330.0439 - val_loss: 10662.2578 - lr: 0.0010\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13039.1201 - val_loss: 2759.6406 - lr: 0.0010\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11656.9375 - val_loss: 2138.4143 - lr: 0.0010\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16438.6680 - val_loss: 3856.8308 - lr: 0.0010\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26759.5176 - val_loss: 3302.6389 - lr: 0.0010\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13728.2480 - val_loss: 2429.3232 - lr: 0.0010\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 17771.8965 - val_loss: 2163.1582 - lr: 0.0010\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28510.5586 - val_loss: 3800.9209 - lr: 0.0010\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15045.1797 - val_loss: 2779.6445 - lr: 0.0010\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22804.8555 - val_loss: 2548.2383 - lr: 0.0010\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13314.7754 - val_loss: 2126.0381 - lr: 0.0010\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19989.8906 - val_loss: 2155.6570 - lr: 0.0010\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18557.8340 - val_loss: 2102.5664 - lr: 0.0010\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18682.8301 - val_loss: 9492.9736 - lr: 0.0010\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23955.7578 - val_loss: 4831.8921 - lr: 0.0010\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22591.6094 - val_loss: 7673.3633 - lr: 0.0010\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16958.2910 - val_loss: 2099.3459 - lr: 0.0010\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10675.4502 - val_loss: 3391.5220 - lr: 0.0010\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12816.3613 - val_loss: 3041.7744 - lr: 0.0010\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11460.2891 - val_loss: 5666.2959 - lr: 0.0010\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27603.4980 - val_loss: 13128.8389 - lr: 0.0010\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16829.2656 - val_loss: 19680.5469 - lr: 0.0010\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37684.0195 - val_loss: 28396.6270 - lr: 0.0010\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 42853.8086 - val_loss: 6754.1323 - lr: 0.0010\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19271.7871 - val_loss: 2213.7842 - lr: 0.0010\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41127.2031 - val_loss: 3539.6682 - lr: 0.0010\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18333.1992 - val_loss: 2495.1560 - lr: 0.0010\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15635.3750 - val_loss: 3329.7773 - lr: 0.0010\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28081.9336 - val_loss: 14655.9932 - lr: 0.0010\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21253.8848 - val_loss: 2856.5608 - lr: 0.0010\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24479.5098 - val_loss: 3772.2590 - lr: 0.0010\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33967.7656 - val_loss: 18354.0820 - lr: 0.0010\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 20288.9590 - val_loss: 2968.5212 - lr: 0.0010\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26270.3906 - val_loss: 2352.3481 - lr: 0.0010\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17219.8633 - val_loss: 3584.6240 - lr: 0.0010\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20036.9316 - val_loss: 3504.4656 - lr: 0.0010\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17231.1367 - val_loss: 3776.9504 - lr: 0.0010\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14195.2002 - val_loss: 2453.2251 - lr: 0.0010\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 21955.1797 - val_loss: 2100.6646 - lr: 0.0010\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11802.0654 - val_loss: 5336.6157 - lr: 0.0010\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11879.1104 - val_loss: 4198.8936 - lr: 0.0010\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12264.0928 - val_loss: 2226.5203 - lr: 0.0010\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13438.6729 - val_loss: 2899.5139 - lr: 0.0010\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15259.9658 - val_loss: 3219.4585 - lr: 0.0010\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21483.8027 - val_loss: 3223.4697 - lr: 0.0010\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 15327.5244 - val_loss: 5581.6714 - lr: 0.0010\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32333.0840 - val_loss: 5322.8071 - lr: 0.0010\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12849.3193 - val_loss: 3866.6504 - lr: 0.0010\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14373.7793 - val_loss: 6794.7188 - lr: 0.0010\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24453.5957 - val_loss: 2305.1160 - lr: 0.0010\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 13999.6416 - val_loss: 2146.7874 - lr: 0.0010\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19075.8691 - val_loss: 13570.8008 - lr: 0.0010\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 19699.1582 - val_loss: 12346.1582 - lr: 0.0010\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35102.1836 - val_loss: 6223.6685 - lr: 0.0010\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15160.3887 - val_loss: 2177.9468 - lr: 0.0010\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22434.6680 - val_loss: 4968.8657 - lr: 0.0010\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16717.5723 - val_loss: 2761.3303 - lr: 0.0010\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9916.7734 - val_loss: 3013.2085 - lr: 0.0010\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16303.1328 - val_loss: 2089.6926 - lr: 0.0010\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17404.6191 - val_loss: 5086.2715 - lr: 0.0010\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9114.3525 - val_loss: 2612.4165 - lr: 0.0010\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21062.1270 - val_loss: 7756.9409 - lr: 0.0010\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24678.7422 - val_loss: 2265.5552 - lr: 0.0010\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14610.4150 - val_loss: 2654.7539 - lr: 0.0010\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11216.2119 - val_loss: 2684.7788 - lr: 0.0010\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13548.1621 - val_loss: 4350.2798 - lr: 0.0010\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10413.0010 - val_loss: 2741.7048 - lr: 0.0010\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9996.8750 - val_loss: 2097.3315 - lr: 0.0010\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10123.1523 - val_loss: 2511.6577 - lr: 0.0010\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12457.1934 - val_loss: 2543.1252 - lr: 0.0010\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28027.8945 - val_loss: 3641.1235 - lr: 0.0010\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12276.3037 - val_loss: 2710.9531 - lr: 0.0010\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19606.3691 - val_loss: 19414.0312 - lr: 0.0010\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23978.5449 - val_loss: 35891.6875 - lr: 0.0010\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35955.3672 - val_loss: 34500.8789 - lr: 0.0010\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 43440.2188 - val_loss: 37781.9883 - lr: 0.0010\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 35443.9258 - val_loss: 9269.2549 - lr: 0.0010\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12474.8672 - val_loss: 4198.7451 - lr: 0.0010\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 14782.0625 - val_loss: 5638.3560 - lr: 0.0010\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16383.4922 - val_loss: 3809.2332 - lr: 0.0010\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11980.9287 - val_loss: 2080.6826 - lr: 0.0010\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9521.7373 - val_loss: 4537.3193 - lr: 0.0010\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44441.4023 - val_loss: 2598.6597 - lr: 0.0010\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17088.2129 - val_loss: 3241.2195 - lr: 0.0010\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16615.8496 - val_loss: 3261.1599 - lr: 0.0010\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18197.6836 - val_loss: 2083.3481 - lr: 0.0010\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26427.2949 - val_loss: 3622.8958 - lr: 0.0010\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18828.8242 - val_loss: 2160.3140 - lr: 0.0010\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28358.9609 - val_loss: 6399.1323 - lr: 0.0010\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25686.8125 - val_loss: 4580.3525 - lr: 0.0010\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19773.2402 - val_loss: 8472.1924 - lr: 0.0010\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26633.3125 - val_loss: 8156.7954 - lr: 0.0010\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28238.0664 - val_loss: 2925.8186 - lr: 0.0010\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22783.5586 - val_loss: 2908.2288 - lr: 0.0010\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18160.8613 - val_loss: 6661.8071 - lr: 0.0010\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17923.4395 - val_loss: 8516.3389 - lr: 0.0010\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23168.6543 - val_loss: 17031.5527 - lr: 0.0010\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 19476.3359 - val_loss: 9852.0488 - lr: 0.0010\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17164.5215 - val_loss: 12531.8857 - lr: 0.0010\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 11300.5703 - val_loss: 2821.8845 - lr: 0.0010\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11808.2832 - val_loss: 2206.8269 - lr: 0.0010\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9730.6455 - val_loss: 8637.2549 - lr: 0.0010\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11680.8799 - val_loss: 4798.0625 - lr: 0.0010\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14151.1309 - val_loss: 2093.1936 - lr: 0.0010\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 14359.3359 - val_loss: 2106.3088 - lr: 0.0010\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10933.6699 - val_loss: 3295.4182 - lr: 0.0010\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10864.5488 - val_loss: 5740.1650 - lr: 0.0010\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17107.4824 - val_loss: 5403.8813 - lr: 0.0010\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 40215.9531 - val_loss: 2123.1287 - lr: 0.0010\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18384.5156 - val_loss: 5219.8726 - lr: 0.0010\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28564.1426 - val_loss: 3820.4358 - lr: 0.0010\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 24561.5723 - val_loss: 6864.2485 - lr: 0.0010\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28684.2715 - val_loss: 7703.5239 - lr: 0.0010\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32279.3633 - val_loss: 4087.0496 - lr: 0.0010\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26533.9141 - val_loss: 3688.4111 - lr: 0.0010\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18733.3281 - val_loss: 2072.2241 - lr: 0.0010\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12656.3779 - val_loss: 2824.1902 - lr: 0.0010\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11967.0918 - val_loss: 2249.7849 - lr: 0.0010\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10617.2012 - val_loss: 2195.5378 - lr: 0.0010\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 21268.8496 - val_loss: 11245.3486 - lr: 0.0010\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15317.8008 - val_loss: 11072.4785 - lr: 0.0010\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26408.7676 - val_loss: 3486.1514 - lr: 0.0010\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17429.4453 - val_loss: 3732.6836 - lr: 0.0010\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23065.2344 - val_loss: 8561.9736 - lr: 0.0010\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17698.5195 - val_loss: 19522.2715 - lr: 0.0010\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 24675.0879 - val_loss: 7973.1304 - lr: 0.0010\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21273.8008 - val_loss: 20226.0820 - lr: 0.0010\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20920.1660 - val_loss: 10300.4395 - lr: 0.0010\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13432.3984 - val_loss: 9907.0176 - lr: 0.0010\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18923.7773 - val_loss: 4407.3594 - lr: 0.0010\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23005.7227 - val_loss: 21513.3242 - lr: 0.0010\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 35229.3203 - val_loss: 8817.1113 - lr: 0.0010\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24466.8516 - val_loss: 2060.8481 - lr: 0.0010\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20304.8594 - val_loss: 15875.7031 - lr: 0.0010\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26973.9883 - val_loss: 4759.7725 - lr: 0.0010\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15010.8311 - val_loss: 6341.5962 - lr: 0.0010\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 16186.8232 - val_loss: 9254.8965 - lr: 0.0010\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23566.0566 - val_loss: 17923.8965 - lr: 0.0010\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 22467.1250 - val_loss: 16803.8398 - lr: 0.0010\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27825.9668 - val_loss: 7097.9648 - lr: 0.0010\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12847.7861 - val_loss: 4895.9951 - lr: 0.0010\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 26216.3848 - val_loss: 2806.4753 - lr: 0.0010\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10923.7695 - val_loss: 3686.5518 - lr: 0.0010\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10333.5693 - val_loss: 2108.7034 - lr: 0.0010\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14025.8672 - val_loss: 5946.8091 - lr: 0.0010\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17326.4551 - val_loss: 9220.6328 - lr: 0.0010\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 18417.1387 - val_loss: 7080.5024 - lr: 0.0010\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14533.4912 - val_loss: 6508.1660 - lr: 0.0010\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22060.4434 - val_loss: 4553.7686 - lr: 0.0010\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14255.5850 - val_loss: 2254.5894 - lr: 0.0010\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10444.0547 - val_loss: 2726.3191 - lr: 0.0010\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 8460.3818 - val_loss: 2191.9678 - lr: 0.0010\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8685.0869 - val_loss: 3648.5188 - lr: 0.0010\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14542.9023 - val_loss: 3535.3416 - lr: 0.0010\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16294.5645 - val_loss: 3645.8691 - lr: 0.0010\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16225.1709 - val_loss: 3390.4983 - lr: 0.0010\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13997.6641 - val_loss: 4605.1226 - lr: 0.0010\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18677.8652 - val_loss: 3823.4402 - lr: 0.0010\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12310.3457 - val_loss: 3799.8303 - lr: 0.0010\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11205.5352 - val_loss: 3688.0825 - lr: 0.0010\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15832.0918 - val_loss: 2514.4180 - lr: 0.0010\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15839.6104 - val_loss: 3106.3198 - lr: 0.0010\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12145.9258 - val_loss: 3168.8022 - lr: 0.0010\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16190.0898 - val_loss: 4308.1675 - lr: 0.0010\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13736.5850 - val_loss: 2052.8530 - lr: 0.0010\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11294.7891 - val_loss: 3085.3020 - lr: 0.0010\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12379.7080 - val_loss: 2061.3711 - lr: 0.0010\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9846.0420 - val_loss: 3989.8821 - lr: 0.0010\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14444.2334 - val_loss: 6215.8423 - lr: 0.0010\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21293.5801 - val_loss: 4809.2290 - lr: 0.0010\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10422.1494 - val_loss: 6450.6455 - lr: 0.0010\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13232.2002 - val_loss: 5744.8174 - lr: 0.0010\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30222.5898 - val_loss: 5393.8301 - lr: 0.0010\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30012.9824 - val_loss: 5933.1304 - lr: 0.0010\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18485.6367 - val_loss: 5264.5303 - lr: 0.0010\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18668.6484 - val_loss: 5419.1523 - lr: 0.0010\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 20426.7207 - val_loss: 2078.6890 - lr: 0.0010\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11480.5176 - val_loss: 2258.1270 - lr: 0.0010\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25053.1523 - val_loss: 2088.3062 - lr: 0.0010\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 29040.4395 - val_loss: 10231.3496 - lr: 0.0010\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27092.6094 - val_loss: 18541.1934 - lr: 0.0010\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20611.3750 - val_loss: 9861.0879 - lr: 0.0010\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18740.8594 - val_loss: 2490.0728 - lr: 0.0010\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9258.4141 - val_loss: 3221.2908 - lr: 0.0010\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12146.7529 - val_loss: 4083.6558 - lr: 0.0010\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 10950.3848 - val_loss: 11958.4111 - lr: 0.0010\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14239.3770 - val_loss: 5442.9307 - lr: 0.0010\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10001.2920 - val_loss: 2866.6648 - lr: 0.0010\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12613.6992 - val_loss: 2331.8525 - lr: 0.0010\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17371.8848 - val_loss: 6423.5972 - lr: 0.0010\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18347.0332 - val_loss: 2300.7778 - lr: 0.0010\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18755.9785 - val_loss: 2400.3035 - lr: 0.0010\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9049.8721 - val_loss: 7280.5845 - lr: 0.0010\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17507.3809 - val_loss: 4440.1763 - lr: 0.0010\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 21312.8945 - val_loss: 13475.3164 - lr: 0.0010\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24705.4492 - val_loss: 5605.9043 - lr: 0.0010\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10858.3105 - val_loss: 5730.9438 - lr: 0.0010\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 18580.8906 - val_loss: 4892.2466 - lr: 0.0010\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19154.6660 - val_loss: 2494.8279 - lr: 0.0010\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14342.3828 - val_loss: 2149.5732 - lr: 0.0010\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11141.5947 - val_loss: 9978.3906 - lr: 0.0010\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20556.0840 - val_loss: 22020.6602 - lr: 0.0010\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 21204.5605 - val_loss: 6074.5669 - lr: 0.0010\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12534.2119 - val_loss: 2691.3909 - lr: 0.0010\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13195.0400 - val_loss: 2386.3848 - lr: 0.0010\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22304.0723 - val_loss: 2428.7012 - lr: 0.0010\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14709.1973 - val_loss: 4889.9243 - lr: 0.0010\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13379.6172 - val_loss: 9955.6016 - lr: 0.0010\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11756.8330 - val_loss: 4414.6680 - lr: 0.0010\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9474.2139 - val_loss: 2908.0686 - lr: 0.0010\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8614.2568 - val_loss: 2392.9187 - lr: 0.0010\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7991.7085 - val_loss: 5661.1226 - lr: 0.0010\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 12344.6182 - val_loss: 11562.4502 - lr: 0.0010\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19316.9238 - val_loss: 4029.4326 - lr: 0.0010\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14390.0996 - val_loss: 5115.7563 - lr: 0.0010\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27928.2285 - val_loss: 6526.9199 - lr: 0.0010\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19764.5293 - val_loss: 5341.8354 - lr: 0.0010\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 39907.3984 - val_loss: 31355.8672 - lr: 0.0010\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32195.3594 - val_loss: 4736.6748 - lr: 0.0010\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26262.7930 - val_loss: 6803.7847 - lr: 0.0010\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 19676.0176 - val_loss: 9542.4736 - lr: 0.0010\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26350.6680 - val_loss: 17075.9277 - lr: 0.0010\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22894.9902 - val_loss: 9347.3242 - lr: 0.0010\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36910.7852 - val_loss: 12446.1787 - lr: 0.0010\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14680.1602 - val_loss: 2452.5747 - lr: 0.0010\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14356.0068 - val_loss: 5377.7466 - lr: 0.0010\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16873.5449 - val_loss: 13459.6309 - lr: 0.0010\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15196.4766 - val_loss: 3948.5710 - lr: 0.0010\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13603.7705 - val_loss: 2857.7915 - lr: 0.0010\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13178.0645 - val_loss: 2184.5903 - lr: 0.0010\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11379.9521 - val_loss: 3345.0298 - lr: 0.0010\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12284.6973 - val_loss: 2420.3433 - lr: 0.0010\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11481.5459 - val_loss: 3225.5981 - lr: 0.0010\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11668.2314 - val_loss: 4518.3027 - lr: 0.0010\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13475.0967 - val_loss: 5005.0220 - lr: 0.0010\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13004.3320 - val_loss: 5748.6484 - lr: 0.0010\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14862.9307 - val_loss: 9599.8486 - lr: 0.0010\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31223.6758 - val_loss: 6878.4004 - lr: 0.0010\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18248.0371 - val_loss: 3714.9702 - lr: 0.0010\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14267.1895 - val_loss: 2070.2944 - lr: 0.0010\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17212.1875 - val_loss: 2059.0847 - lr: 0.0010\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18240.6191 - val_loss: 4760.7534 - lr: 0.0010\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22659.6406 - val_loss: 13941.0225 - lr: 0.0010\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22960.6113 - val_loss: 2019.7004 - lr: 0.0010\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23474.7832 - val_loss: 2495.6003 - lr: 0.0010\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 22331.4199 - val_loss: 4165.6792 - lr: 0.0010\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23212.1211 - val_loss: 5058.3525 - lr: 0.0010\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20980.6016 - val_loss: 8695.7549 - lr: 0.0010\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17711.9941 - val_loss: 30085.2969 - lr: 0.0010\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 32939.1641 - val_loss: 3754.0017 - lr: 0.0010\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23931.6992 - val_loss: 3204.9683 - lr: 0.0010\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14056.0146 - val_loss: 7096.7412 - lr: 0.0010\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16592.9199 - val_loss: 2034.4181 - lr: 0.0010\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9972.3379 - val_loss: 7124.5283 - lr: 0.0010\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12082.2422 - val_loss: 7890.1025 - lr: 0.0010\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16169.3809 - val_loss: 13935.1523 - lr: 0.0010\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 17447.8867 - val_loss: 2088.5793 - lr: 0.0010\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18960.7988 - val_loss: 2149.1843 - lr: 0.0010\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10966.9609 - val_loss: 2331.5964 - lr: 0.0010\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20951.4961 - val_loss: 3421.6145 - lr: 0.0010\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11751.0977 - val_loss: 3389.5039 - lr: 0.0010\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15532.3955 - val_loss: 4038.3916 - lr: 0.0010\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12335.0371 - val_loss: 17980.2676 - lr: 0.0010\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18175.5801 - val_loss: 21513.8379 - lr: 0.0010\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17711.1758 - val_loss: 9257.4268 - lr: 0.0010\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10788.2607 - val_loss: 8805.9951 - lr: 0.0010\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12335.8926 - val_loss: 3875.2629 - lr: 0.0010\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8408.8613 - val_loss: 2171.4070 - lr: 0.0010\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7256.4961 - val_loss: 2531.4517 - lr: 0.0010\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 12207.1064 - val_loss: 4018.7834 - lr: 0.0010\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8263.4160 - val_loss: 2023.0623 - lr: 0.0010\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8872.3467 - val_loss: 3791.9080 - lr: 0.0010\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9378.8311 - val_loss: 4897.4697 - lr: 0.0010\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11919.1641 - val_loss: 3602.1072 - lr: 0.0010\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12696.5166 - val_loss: 3193.3171 - lr: 0.0010\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9652.3242 - val_loss: 3813.8665 - lr: 0.0010\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11458.2061 - val_loss: 2028.2656 - lr: 0.0010\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9917.8887 - val_loss: 2575.6108 - lr: 0.0010\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 10806.2637 - val_loss: 2740.8989 - lr: 0.0010\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11548.7754 - val_loss: 12578.0635 - lr: 0.0010\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14195.8789 - val_loss: 13267.1719 - lr: 0.0010\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15635.9980 - val_loss: 2175.5715 - lr: 0.0010\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20183.1094 - val_loss: 10969.5488 - lr: 0.0010\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 22834.6328 - val_loss: 3899.9817 - lr: 0.0010\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16128.7207 - val_loss: 27605.4844 - lr: 0.0010\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36566.1758 - val_loss: 51222.6055 - lr: 0.0010\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 48216.6484 - val_loss: 38174.0703 - lr: 0.0010\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 51690.3711 - val_loss: 17136.2500 - lr: 0.0010\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27253.7656 - val_loss: 4893.9097 - lr: 0.0010\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25448.2793 - val_loss: 2329.8118 - lr: 0.0010\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20031.2051 - val_loss: 2229.3406 - lr: 0.0010\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 17282.7695 - val_loss: 2065.8164 - lr: 0.0010\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 20565.2930 - val_loss: 2093.9695 - lr: 0.0010\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14314.0527 - val_loss: 2022.5192 - lr: 0.0010\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11232.2354 - val_loss: 2846.1487 - lr: 0.0010\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14007.4521 - val_loss: 2299.2170 - lr: 0.0010\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9783.9150 - val_loss: 2813.3972 - lr: 0.0010\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18954.2461 - val_loss: 2007.7201 - lr: 0.0010\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10284.9619 - val_loss: 5345.8364 - lr: 0.0010\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14213.1045 - val_loss: 5566.5400 - lr: 0.0010\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 18480.2930 - val_loss: 2443.0610 - lr: 0.0010\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11690.6650 - val_loss: 11571.3369 - lr: 0.0010\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13789.1348 - val_loss: 8116.4141 - lr: 0.0010\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12841.4453 - val_loss: 7072.4692 - lr: 0.0010\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 17321.6699 - val_loss: 3513.3806 - lr: 0.0010\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 19680.4707 - val_loss: 5814.2803 - lr: 0.0010\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13175.8330 - val_loss: 7883.6152 - lr: 0.0010\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12130.5654 - val_loss: 4515.0454 - lr: 0.0010\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 13531.0732 - val_loss: 4617.6050 - lr: 0.0010\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 15972.2354 - val_loss: 5541.3931 - lr: 0.0010\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14430.8770 - val_loss: 3553.8774 - lr: 0.0010\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16314.4297 - val_loss: 2000.0565 - lr: 0.0010\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9853.9062 - val_loss: 4788.3511 - lr: 0.0010\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11021.8105 - val_loss: 7502.6216 - lr: 0.0010\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13477.0938 - val_loss: 4030.3616 - lr: 0.0010\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9281.3271 - val_loss: 4148.5791 - lr: 0.0010\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9549.8066 - val_loss: 3409.5806 - lr: 0.0010\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 18931.5410 - val_loss: 4843.6860 - lr: 0.0010\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12620.5537 - val_loss: 2123.5352 - lr: 0.0010\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11192.5293 - val_loss: 2049.1694 - lr: 0.0010\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9529.6074 - val_loss: 3601.3037 - lr: 0.0010\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12537.0215 - val_loss: 2235.7175 - lr: 0.0010\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9360.8359 - val_loss: 3972.7812 - lr: 0.0010\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10990.2070 - val_loss: 5804.0742 - lr: 0.0010\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11035.7393 - val_loss: 6943.1187 - lr: 0.0010\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10493.4395 - val_loss: 2311.3364 - lr: 0.0010\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11028.3799 - val_loss: 2668.2332 - lr: 0.0010\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 16098.9688 - val_loss: 2065.8813 - lr: 0.0010\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10061.5928 - val_loss: 2506.7405 - lr: 0.0010\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9658.4189 - val_loss: 2000.5359 - lr: 0.0010\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9640.7441 - val_loss: 2350.7109 - lr: 0.0010\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16655.2773 - val_loss: 3072.1199 - lr: 0.0010\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12335.9482 - val_loss: 2093.6025 - lr: 0.0010\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14385.8516 - val_loss: 4431.7002 - lr: 0.0010\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10387.1797 - val_loss: 6153.6836 - lr: 0.0010\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15392.1641 - val_loss: 6215.4946 - lr: 0.0010\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11774.3457 - val_loss: 7255.7417 - lr: 0.0010\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 14651.3213 - val_loss: 2807.8225 - lr: 0.0010\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 21934.9395 - val_loss: 4208.1377 - lr: 0.0010\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9445.4189 - val_loss: 8982.7852 - lr: 0.0010\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19900.1113 - val_loss: 5244.4297 - lr: 0.0010\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 10948.5947 - val_loss: 1983.5223 - lr: 0.0010\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14644.3428 - val_loss: 3803.3367 - lr: 0.0010\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11069.7637 - val_loss: 2552.4536 - lr: 0.0010\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9017.4043 - val_loss: 3204.8347 - lr: 0.0010\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11964.1055 - val_loss: 2078.1631 - lr: 0.0010\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11317.1230 - val_loss: 4504.0010 - lr: 0.0010\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 9423.7109 - val_loss: 2200.0732 - lr: 0.0010\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12347.8613 - val_loss: 2038.1099 - lr: 0.0010\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11236.3955 - val_loss: 5312.6074 - lr: 0.0010\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14329.1230 - val_loss: 2969.1963 - lr: 0.0010\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11695.4209 - val_loss: 2587.7722 - lr: 0.0010\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12908.4092 - val_loss: 11891.3408 - lr: 0.0010\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15711.1025 - val_loss: 16670.8672 - lr: 0.0010\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 16404.8047 - val_loss: 5301.3179 - lr: 0.0010\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 18053.5977 - val_loss: 13304.6768 - lr: 0.0010\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23827.4434 - val_loss: 4671.9399 - lr: 0.0010\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12389.8828 - val_loss: 4037.4358 - lr: 0.0010\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16647.6445 - val_loss: 2020.4437 - lr: 0.0010\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10455.6377 - val_loss: 2800.1335 - lr: 0.0010\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 12147.9980 - val_loss: 3313.1648 - lr: 0.0010\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12556.0449 - val_loss: 1986.7543 - lr: 0.0010\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8885.8936 - val_loss: 5567.6050 - lr: 0.0010\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12223.1660 - val_loss: 5041.5073 - lr: 0.0010\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11671.0039 - val_loss: 1984.2837 - lr: 0.0010\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 22012.7578 - val_loss: 9596.5527 - lr: 0.0010\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14081.0322 - val_loss: 2226.6238 - lr: 0.0010\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11503.6523 - val_loss: 6129.3101 - lr: 0.0010\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8461.4326 - val_loss: 9021.6895 - lr: 0.0010\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11282.4248 - val_loss: 8169.7124 - lr: 0.0010\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14056.6943 - val_loss: 3436.1943 - lr: 0.0010\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 10774.5811 - val_loss: 2042.4849 - lr: 0.0010\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10403.2920 - val_loss: 2414.5664 - lr: 0.0010\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8312.5850 - val_loss: 2012.7672 - lr: 0.0010\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 7331.9541 - val_loss: 6044.2075 - lr: 0.0010\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 12786.4463 - val_loss: 13134.6406 - lr: 0.0010\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 16222.1650 - val_loss: 8191.3159 - lr: 0.0010\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11881.7578 - val_loss: 4220.4062 - lr: 0.0010\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10607.0117 - val_loss: 3843.4924 - lr: 0.0010\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11863.9600 - val_loss: 2089.5896 - lr: 0.0010\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8825.1182 - val_loss: 1983.9232 - lr: 0.0010\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8922.5498 - val_loss: 4118.4219 - lr: 0.0010\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 13394.0039 - val_loss: 8455.8965 - lr: 0.0010\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13604.5850 - val_loss: 3304.2351 - lr: 0.0010\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10341.7715 - val_loss: 2200.8696 - lr: 0.0010\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9938.3252 - val_loss: 4015.0000 - lr: 0.0010\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9700.7803 - val_loss: 3236.7261 - lr: 0.0010\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9896.2324 - val_loss: 2257.6294 - lr: 0.0010\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11998.9492 - val_loss: 3133.3689 - lr: 0.0010\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 9985.3320 - val_loss: 1988.3766 - lr: 0.0010\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8723.3516 - val_loss: 1977.0792 - lr: 0.0010\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8459.9941 - val_loss: 2407.7437 - lr: 0.0010\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10492.7178 - val_loss: 2589.9727 - lr: 0.0010\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10857.2861 - val_loss: 2398.6169 - lr: 0.0010\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8088.7446 - val_loss: 4686.8999 - lr: 0.0010\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9094.2754 - val_loss: 4697.1899 - lr: 0.0010\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 22515.3652 - val_loss: 5283.9600 - lr: 0.0010\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14164.6260 - val_loss: 2440.1797 - lr: 0.0010\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15501.7900 - val_loss: 12777.1406 - lr: 0.0010\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19363.9531 - val_loss: 5211.5693 - lr: 0.0010\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13370.3066 - val_loss: 6486.2261 - lr: 0.0010\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15296.9961 - val_loss: 2321.8135 - lr: 0.0010\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12251.3125 - val_loss: 3531.4146 - lr: 0.0010\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12610.4150 - val_loss: 2235.8093 - lr: 0.0010\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13709.6172 - val_loss: 2375.9861 - lr: 0.0010\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14433.0352 - val_loss: 13717.4443 - lr: 0.0010\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18554.6250 - val_loss: 1999.6056 - lr: 0.0010\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9869.2842 - val_loss: 2832.5703 - lr: 0.0010\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13466.4033 - val_loss: 4701.3643 - lr: 0.0010\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11389.8984 - val_loss: 6252.4087 - lr: 0.0010\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 16404.3125 - val_loss: 17774.3789 - lr: 0.0010\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15087.4189 - val_loss: 7777.6865 - lr: 0.0010\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20811.2695 - val_loss: 10285.1660 - lr: 0.0010\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 52757.9688 - val_loss: 24552.5352 - lr: 0.0010\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43575.2656 - val_loss: 13144.7344 - lr: 0.0010\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33796.9375 - val_loss: 3945.6367 - lr: 0.0010\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 21861.2031 - val_loss: 6030.8667 - lr: 0.0010\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28217.6855 - val_loss: 2879.0481 - lr: 0.0010\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 20490.8926 - val_loss: 12135.6689 - lr: 0.0010\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20026.7793 - val_loss: 34534.3750 - lr: 0.0010\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30936.9531 - val_loss: 21074.3438 - lr: 0.0010\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28135.2422 - val_loss: 21368.4277 - lr: 0.0010\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29877.1094 - val_loss: 8013.3599 - lr: 0.0010\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 18653.5312 - val_loss: 2667.8433 - lr: 0.0010\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 21069.3691 - val_loss: 6312.8950 - lr: 0.0010\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 17353.0078 - val_loss: 3536.0017 - lr: 0.0010\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11300.0928 - val_loss: 2353.8853 - lr: 0.0010\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14417.7002 - val_loss: 2752.8833 - lr: 0.0010\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13452.4854 - val_loss: 6056.3569 - lr: 0.0010\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12481.7715 - val_loss: 12001.2344 - lr: 0.0010\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 15442.3711 - val_loss: 2328.2134 - lr: 0.0010\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11055.1094 - val_loss: 2224.9602 - lr: 0.0010\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12780.4062 - val_loss: 5965.0054 - lr: 0.0010\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13888.0137 - val_loss: 1965.0348 - lr: 0.0010\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8581.7891 - val_loss: 2501.8228 - lr: 0.0010\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8726.8594 - val_loss: 3011.0864 - lr: 0.0010\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12030.1992 - val_loss: 2167.3740 - lr: 0.0010\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6969.9053 - val_loss: 2845.3381 - lr: 0.0010\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10425.2842 - val_loss: 2179.8662 - lr: 0.0010\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9083.4414 - val_loss: 5810.2363 - lr: 0.0010\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12371.4629 - val_loss: 4379.8760 - lr: 0.0010\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9861.7480 - val_loss: 2528.3701 - lr: 0.0010\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 13274.4033 - val_loss: 2224.4690 - lr: 0.0010\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11686.3691 - val_loss: 3044.8096 - lr: 0.0010\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 13229.0889 - val_loss: 8411.9219 - lr: 0.0010\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 20319.0820 - val_loss: 3656.0676 - lr: 0.0010\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10502.3975 - val_loss: 4162.4443 - lr: 0.0010\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 12029.6045 - val_loss: 2238.4348 - lr: 0.0010\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12155.8057 - val_loss: 2355.9856 - lr: 0.0010\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 7432.5679 - val_loss: 2020.6547 - lr: 0.0010\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14179.9824 - val_loss: 2380.3486 - lr: 0.0010\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14206.6377 - val_loss: 2038.3799 - lr: 0.0010\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 10220.0830 - val_loss: 6671.5444 - lr: 0.0010\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10905.3828 - val_loss: 4351.1685 - lr: 0.0010\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8033.2832 - val_loss: 2165.0730 - lr: 0.0010\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9961.5908 - val_loss: 2859.8474 - lr: 0.0010\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 14302.2568 - val_loss: 4099.4307 - lr: 0.0010\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 19345.1270 - val_loss: 3094.2610 - lr: 0.0010\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10734.2227 - val_loss: 2039.4989 - lr: 0.0010\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 7278.0640 - val_loss: 1962.7775 - lr: 0.0010\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14279.2705 - val_loss: 2333.1072 - lr: 0.0010\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12250.0293 - val_loss: 3499.6643 - lr: 0.0010\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11266.1523 - val_loss: 2472.2734 - lr: 0.0010\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 13014.5762 - val_loss: 5406.4761 - lr: 0.0010\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10934.5518 - val_loss: 2719.9004 - lr: 0.0010\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 10123.8984 - val_loss: 2069.3474 - lr: 0.0010\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12241.0352 - val_loss: 2649.3252 - lr: 0.0010\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8212.5703 - val_loss: 1931.3745 - lr: 0.0010\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12674.6523 - val_loss: 2829.6812 - lr: 0.0010\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14484.6885 - val_loss: 13817.5254 - lr: 0.0010\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14758.0811 - val_loss: 2278.3916 - lr: 0.0010\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12765.8896 - val_loss: 6095.8062 - lr: 0.0010\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14261.2451 - val_loss: 8944.6885 - lr: 0.0010\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17444.1387 - val_loss: 7126.7671 - lr: 0.0010\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 33578.9102 - val_loss: 2327.6194 - lr: 0.0010\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 13088.0195 - val_loss: 8232.3154 - lr: 0.0010\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 15684.7246 - val_loss: 6201.2188 - lr: 0.0010\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 17065.3945 - val_loss: 1944.4512 - lr: 0.0010\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 10956.6016 - val_loss: 3276.1082 - lr: 0.0010\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 14022.8467 - val_loss: 2667.9858 - lr: 0.0010\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 15267.1992 - val_loss: 5854.2983 - lr: 0.0010\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11409.1084 - val_loss: 4024.1160 - lr: 0.0010\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 14235.1846 - val_loss: 13137.1338 - lr: 0.0010\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 18314.2227 - val_loss: 9641.8906 - lr: 0.0010\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 15688.1543 - val_loss: 6146.3726 - lr: 0.0010\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 13506.3203 - val_loss: 1939.2761 - lr: 0.0010\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17744.9746 - val_loss: 11511.7402 - lr: 0.0010\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 19950.3105 - val_loss: 3744.4832 - lr: 0.0010\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9638.9355 - val_loss: 3573.9451 - lr: 0.0010\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8702.6230 - val_loss: 2511.5662 - lr: 0.0010\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 10536.1182 - val_loss: 9584.2998 - lr: 0.0010\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11812.7471 - val_loss: 2099.7837 - lr: 0.0010\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 11214.2891 - val_loss: 6983.9316 - lr: 0.0010\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 13356.7031 - val_loss: 3789.8325 - lr: 0.0010\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10451.8438 - val_loss: 2511.7542 - lr: 0.0010\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8007.7471 - val_loss: 1963.6375 - lr: 0.0010\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9638.3877 - val_loss: 4096.2939 - lr: 0.0010\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9121.2646 - val_loss: 1919.0918 - lr: 0.0010\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23331.7520 - val_loss: 1922.9763 - lr: 0.0010\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12541.7158 - val_loss: 5238.1343 - lr: 0.0010\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11487.3291 - val_loss: 3824.2974 - lr: 0.0010\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 10383.5508 - val_loss: 2432.1919 - lr: 0.0010\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8691.8271 - val_loss: 2208.8945 - lr: 0.0010\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8738.7529 - val_loss: 1927.6191 - lr: 0.0010\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 7629.8643 - val_loss: 3103.9985 - lr: 0.0010\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11658.9922 - val_loss: 1916.6520 - lr: 0.0010\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 8922.5684 - val_loss: 2082.0630 - lr: 0.0010\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8469.5654 - val_loss: 2881.0916 - lr: 0.0010\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 8938.5420 - val_loss: 2503.8450 - lr: 0.0010\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11774.4785 - val_loss: 1929.0714 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "history = nu_model.fit(X_train_output, y_train_output, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[lrd, mcp, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V88vdGiCghm",
        "outputId": "cc92953f-70f0-4d2d-d99b-9e24a2622188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 1002.4031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1002.403076171875"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "nu_model.evaluate(X_test_output, y_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2tPnc2xCkbU",
        "outputId": "bc847377-c8b7-4f75-83c9-9699ae5f210e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.578747],\n",
              "       [29.848156],\n",
              "       [30.156017],\n",
              "       [30.435558],\n",
              "       [29.79774 ],\n",
              "       [13.128063],\n",
              "       [29.654186],\n",
              "       [30.01588 ],\n",
              "       [29.960705],\n",
              "       [29.942028],\n",
              "       [12.759014],\n",
              "       [29.487194],\n",
              "       [29.646618],\n",
              "       [13.547558],\n",
              "       [12.910168],\n",
              "       [29.867931],\n",
              "       [30.366955],\n",
              "       [29.747692],\n",
              "       [29.87611 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y_pred_output = nu_model.predict(X_test_output)\n",
        "y_pred_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBx-E25FlMS9",
        "outputId": "b0d3966d-25fe-4a7e-b357-33f3eae98b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.839123],\n",
              "       [29.839123],\n",
              "       [29.839123]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#showing the prdiction of some random points\n",
        "nu_model.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sBcVCr6Cm6C",
        "outputId": "1e37d5c8-8276-4f3e-b88c-0a044218f689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.29470157774733496"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#geeting the r2 score for y_test and y_pred\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test_output, y_pred_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGYwUtc7F0s-",
        "outputId": "7d9e7022-618d-4cd9-8849-884fd5fe1458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.660705636124938"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#calculate the root mean square error for neural network model\n",
        "RMSE = (((y_pred_output[:,0]-y_test_output)**2).mean())**.5\n",
        "RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "-7qNaCgaFA3Y",
        "outputId": "f6bc02ea-fdff-413d-a048-be73ff3e3f6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH5MMErINHf0"
      },
      "source": [
        "**As we see from R2 and RMSE the neural network is very bad for these data and can not be able to detect the patterens from our small dataset so we will use best model we discoverd in pycaret Extra tree regroessor with numirc ordinal tenisty values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNummzcUNGob",
        "outputId": "d3830d1a-4e49-477e-9f76-e3a77c1568b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9968461133890045"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(X_train_output, y_train_output)\n",
        "reg.score(X_test_output, y_test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw3zrbEBO3eo",
        "outputId": "1931ebfd-53cc-4a29-b7c5-a2e4cf6b35d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28., 28., 28.])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#showing the prdiction of some random points\n",
        "reg.predict([[3,13,143362],[3,13,143362],[3,13,143362]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDhyCOKXPkBy"
      },
      "source": [
        "## Predict Latency thru Neural networks regression \n",
        "### Comparison between different models in pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "tqQSM6oxPjiU"
      },
      "outputs": [],
      "source": [
        "#for dummy variable approach\n",
        "df_laten_dum = df_all_dum.copy()\n",
        "df_laten_dum.drop('box_output', axis=1, inplace=True)\n",
        "\n",
        "#for numerical ordinal variable approach\n",
        "df_laten_ord = df_all_ordinal.copy()\n",
        "df_laten_ord.drop('box_output', axis=1, inplace=True)\n",
        "\n",
        "#uncomment one of next line to show it's values\n",
        "# df_laten_dum.head()\n",
        "# df_laten_ord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a35561fa17c84143924f9f276a71823c",
            "f8525441dcdd425ca63d1a76ae180a54",
            "389ab271ead44b498ae498e6f2c64855",
            "fd88e71a946d4e55ae413ef64bf1a6dd",
            "758fdaa572e143ffbbd5a04c524da5b7",
            "d27b8af787cd4fef839abb967b46da8d"
          ]
        },
        "id": "DfVUUKQHPPkb",
        "outputId": "4cbb4926-0d5a-42bd-a064-122fb5806b79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e14eb4db-ef2b-4ec4-a26d-8d9045788be4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Latency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(190, 6)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(132, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(58, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>KFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>reg-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>USI</td>\n",
              "      <td>71f6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Transform Target</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Transform Target Method</td>\n",
              "      <td>box-cox</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e14eb4db-ef2b-4ec4-a26d-8d9045788be4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e14eb4db-ef2b-4ec4-a26d-8d9045788be4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e14eb4db-ef2b-4ec4-a26d-8d9045788be4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               123\n",
              "1                                   Target           Latency\n",
              "2                            Original Data          (190, 6)\n",
              "3                           Missing Values             False\n",
              "4                         Numeric Features                 5\n",
              "5                     Categorical Features                 0\n",
              "6                         Ordinal Features             False\n",
              "7                High Cardinality Features             False\n",
              "8                  High Cardinality Method              None\n",
              "9                    Transformed Train Set          (132, 5)\n",
              "10                    Transformed Test Set           (58, 5)\n",
              "11                      Shuffle Train-Test              True\n",
              "12                     Stratify Train-Test             False\n",
              "13                          Fold Generator             KFold\n",
              "14                             Fold Number                10\n",
              "15                                CPU Jobs                -1\n",
              "16                                 Use GPU             False\n",
              "17                          Log Experiment             False\n",
              "18                         Experiment Name  reg-default-name\n",
              "19                                     USI              71f6\n",
              "20                         Imputation Type            simple\n",
              "21          Iterative Imputation Iteration              None\n",
              "22                         Numeric Imputer              mean\n",
              "23      Iterative Imputation Numeric Model              None\n",
              "24                     Categorical Imputer          constant\n",
              "25  Iterative Imputation Categorical Model              None\n",
              "26           Unknown Categoricals Handling    least_frequent\n",
              "27                               Normalize             False\n",
              "28                        Normalize Method              None\n",
              "29                          Transformation             False\n",
              "30                   Transformation Method              None\n",
              "31                                     PCA             False\n",
              "32                              PCA Method              None\n",
              "33                          PCA Components              None\n",
              "34                     Ignore Low Variance             False\n",
              "35                     Combine Rare Levels             False\n",
              "36                    Rare Level Threshold              None\n",
              "37                         Numeric Binning             False\n",
              "38                         Remove Outliers             False\n",
              "39                      Outliers Threshold              None\n",
              "40                Remove Multicollinearity             False\n",
              "41             Multicollinearity Threshold              None\n",
              "42             Remove Perfect Collinearity              True\n",
              "43                              Clustering             False\n",
              "44                    Clustering Iteration              None\n",
              "45                     Polynomial Features             False\n",
              "46                       Polynomial Degree              None\n",
              "47                    Trignometry Features             False\n",
              "48                    Polynomial Threshold              None\n",
              "49                          Group Features             False\n",
              "50                       Feature Selection             False\n",
              "51                Feature Selection Method           classic\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                        Transform Target             False\n",
              "57                 Transform Target Method           box-cox"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "exp_reg101 = setup(data = df_laten_dum, target = 'Latency', numeric_features = ['Block_period','Block_size'], session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735,
          "referenced_widgets": [
            "caffd9a3e2654a64b5aecf41013a4e2f",
            "353d3d4b4ec146779e5f3c9363941972",
            "6a72095a475b4b80bf55fbf989096b93"
          ]
        },
        "id": "gpqCV7CFQzA0",
        "outputId": "6a487193-2228-4ae7-9997-6a976ec5c25e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4319f63f-1440-4701-b390-95a151ec82b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "      <td>17.5122</td>\n",
              "      <td>1088.5077</td>\n",
              "      <td>28.5000</td>\n",
              "      <td>0.9933</td>\n",
              "      <td>0.1080</td>\n",
              "      <td>0.0752</td>\n",
              "      <td>0.364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbr</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>27.4762</td>\n",
              "      <td>1623.9351</td>\n",
              "      <td>38.3856</td>\n",
              "      <td>0.9888</td>\n",
              "      <td>0.1891</td>\n",
              "      <td>0.1420</td>\n",
              "      <td>0.041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>28.5001</td>\n",
              "      <td>1953.8883</td>\n",
              "      <td>39.7239</td>\n",
              "      <td>0.9871</td>\n",
              "      <td>0.1693</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Regressor</td>\n",
              "      <td>45.4888</td>\n",
              "      <td>4102.1749</td>\n",
              "      <td>61.7987</td>\n",
              "      <td>0.9714</td>\n",
              "      <td>0.1764</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>60.3390</td>\n",
              "      <td>8173.9975</td>\n",
              "      <td>85.8819</td>\n",
              "      <td>0.9402</td>\n",
              "      <td>0.3806</td>\n",
              "      <td>0.3034</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>AdaBoost Regressor</td>\n",
              "      <td>79.3329</td>\n",
              "      <td>9884.5993</td>\n",
              "      <td>97.3343</td>\n",
              "      <td>0.9278</td>\n",
              "      <td>0.5127</td>\n",
              "      <td>0.6022</td>\n",
              "      <td>0.071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llar</th>\n",
              "      <td>Lasso Least Angle Regression</td>\n",
              "      <td>101.7077</td>\n",
              "      <td>19933.8098</td>\n",
              "      <td>137.5799</td>\n",
              "      <td>0.8497</td>\n",
              "      <td>0.6915</td>\n",
              "      <td>0.8799</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lasso</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>102.3703</td>\n",
              "      <td>19846.1875</td>\n",
              "      <td>137.0728</td>\n",
              "      <td>0.8494</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.9719</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lar</th>\n",
              "      <td>Least Angle Regression</td>\n",
              "      <td>103.1232</td>\n",
              "      <td>19934.0796</td>\n",
              "      <td>137.3521</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>0.6155</td>\n",
              "      <td>0.9884</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>103.1232</td>\n",
              "      <td>19934.0809</td>\n",
              "      <td>137.3521</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>0.6155</td>\n",
              "      <td>0.9884</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>101.7961</td>\n",
              "      <td>19916.1281</td>\n",
              "      <td>137.2169</td>\n",
              "      <td>0.8488</td>\n",
              "      <td>0.6221</td>\n",
              "      <td>0.9582</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>br</th>\n",
              "      <td>Bayesian Ridge</td>\n",
              "      <td>102.1630</td>\n",
              "      <td>19922.9986</td>\n",
              "      <td>137.2594</td>\n",
              "      <td>0.8488</td>\n",
              "      <td>0.6327</td>\n",
              "      <td>0.9669</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huber</th>\n",
              "      <td>Huber Regressor</td>\n",
              "      <td>93.9216</td>\n",
              "      <td>21027.8562</td>\n",
              "      <td>139.9129</td>\n",
              "      <td>0.8367</td>\n",
              "      <td>0.6918</td>\n",
              "      <td>0.7991</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>par</th>\n",
              "      <td>Passive Aggressive Regressor</td>\n",
              "      <td>99.0486</td>\n",
              "      <td>23116.0783</td>\n",
              "      <td>147.9253</td>\n",
              "      <td>0.8205</td>\n",
              "      <td>0.7179</td>\n",
              "      <td>0.9357</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Regressor</td>\n",
              "      <td>110.9859</td>\n",
              "      <td>28487.8929</td>\n",
              "      <td>161.9928</td>\n",
              "      <td>0.7823</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7546</td>\n",
              "      <td>0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>113.8900</td>\n",
              "      <td>31986.6044</td>\n",
              "      <td>174.0746</td>\n",
              "      <td>0.7536</td>\n",
              "      <td>0.5970</td>\n",
              "      <td>0.6488</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omp</th>\n",
              "      <td>Orthogonal Matching Pursuit</td>\n",
              "      <td>176.6694</td>\n",
              "      <td>57129.3705</td>\n",
              "      <td>232.7619</td>\n",
              "      <td>0.5620</td>\n",
              "      <td>1.0175</td>\n",
              "      <td>1.1021</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Regressor</td>\n",
              "      <td>310.9017</td>\n",
              "      <td>143944.2133</td>\n",
              "      <td>375.3520</td>\n",
              "      <td>-0.0348</td>\n",
              "      <td>1.1869</td>\n",
              "      <td>2.4696</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4319f63f-1440-4701-b390-95a151ec82b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4319f63f-1440-4701-b390-95a151ec82b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4319f63f-1440-4701-b390-95a151ec82b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model       MAE          MSE      RMSE  \\\n",
              "et                  Extra Trees Regressor   17.5122    1088.5077   28.5000   \n",
              "gbr           Gradient Boosting Regressor   27.4762    1623.9351   38.3856   \n",
              "rf                Random Forest Regressor   28.5001    1953.8883   39.7239   \n",
              "dt                Decision Tree Regressor   45.4888    4102.1749   61.7987   \n",
              "lightgbm  Light Gradient Boosting Machine   60.3390    8173.9975   85.8819   \n",
              "ada                    AdaBoost Regressor   79.3329    9884.5993   97.3343   \n",
              "llar         Lasso Least Angle Regression  101.7077   19933.8098  137.5799   \n",
              "lasso                    Lasso Regression  102.3703   19846.1875  137.0728   \n",
              "lar                Least Angle Regression  103.1232   19934.0796  137.3521   \n",
              "lr                      Linear Regression  103.1232   19934.0809  137.3521   \n",
              "ridge                    Ridge Regression  101.7961   19916.1281  137.2169   \n",
              "br                         Bayesian Ridge  102.1630   19922.9986  137.2594   \n",
              "huber                     Huber Regressor   93.9216   21027.8562  139.9129   \n",
              "par          Passive Aggressive Regressor   99.0486   23116.0783  147.9253   \n",
              "knn                 K Neighbors Regressor  110.9859   28487.8929  161.9928   \n",
              "en                            Elastic Net  113.8900   31986.6044  174.0746   \n",
              "omp           Orthogonal Matching Pursuit  176.6694   57129.3705  232.7619   \n",
              "dummy                     Dummy Regressor  310.9017  143944.2133  375.3520   \n",
              "\n",
              "              R2   RMSLE    MAPE  TT (Sec)  \n",
              "et        0.9933  0.1080  0.0752     0.364  \n",
              "gbr       0.9888  0.1891  0.1420     0.041  \n",
              "rf        0.9871  0.1693  0.1349     0.409  \n",
              "dt        0.9714  0.1764  0.1525     0.014  \n",
              "lightgbm  0.9402  0.3806  0.3034     0.022  \n",
              "ada       0.9278  0.5127  0.6022     0.071  \n",
              "llar      0.8497  0.6915  0.8799     0.014  \n",
              "lasso     0.8494  0.6389  0.9719     0.016  \n",
              "lar       0.8489  0.6155  0.9884     0.016  \n",
              "lr        0.8489  0.6155  0.9884     0.014  \n",
              "ridge     0.8488  0.6221  0.9582     0.014  \n",
              "br        0.8488  0.6327  0.9669     0.014  \n",
              "huber     0.8367  0.6918  0.7991     0.024  \n",
              "par       0.8205  0.7179  0.9357     0.018  \n",
              "knn       0.7823  0.6260  0.7546     0.061  \n",
              "en        0.7536  0.5970  0.6488     0.016  \n",
              "omp       0.5620  1.0175  1.1021     0.014  \n",
              "dummy    -0.0348  1.1869  2.4696     0.011  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
              "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                    max_samples=None, min_impurity_decrease=0.0,\n",
              "                    min_impurity_split=None, min_samples_leaf=1,\n",
              "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                    n_estimators=100, n_jobs=-1, oob_score=False,\n",
              "                    random_state=123, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIPsOPERslt"
      },
      "source": [
        "***Dummy approach here is better than numeric ordinal for intensity feature but with very little difference..R2 for Dummy = .9933 and also we get better RMSE and for ordinal = .9925 so we can use dummy here and the extra tree regressor is the best that get these accuracies in the two cases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "glqZhXxzU_qU"
      },
      "outputs": [],
      "source": [
        "#split our data to y that contain our output \"Latency\" and to x that contain the features inputs for our model\n",
        "y_lat=df_laten_dum[\"Latency\"]\n",
        "x_lat=df_laten_dum.copy()\n",
        "x_lat.drop(columns = ['Latency'],inplace = True)\n",
        "# x_lat.head()\n",
        "\n",
        "#split x,y to train and test to measure the accurcy of the model\n",
        "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(x_lat, y_lat, test_size = .1, random_state = 43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99DdjFoSf_O"
      },
      "source": [
        "## Try neural network for Latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Q5IH5-ZJV5RV"
      },
      "outputs": [],
      "source": [
        "# data normalization with sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "norm = MinMaxScaler().fit(X_train_lat)\n",
        "\n",
        "# transform training data\n",
        "X_train_norm = norm.transform(X_train_lat)\n",
        "\n",
        "# transform testing dataabs\n",
        "X_test_norm = norm.transform(X_test_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Wfky7NGxWu0e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "n2aQPSetRDL9"
      },
      "outputs": [],
      "source": [
        "nu_model_lat = Sequential()\n",
        "nu_model_lat.add(Dense(units=100, activation='relu', input_shape=[X_train_norm.shape[1]]))\n",
        "nu_model_lat.add(Dense(units=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtKpIr9S8-q",
        "outputId": "061df7b7-1321-4cb0-f576-bd72d65ab64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               600       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 701\n",
            "Trainable params: 701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nu_model_lat.compile(loss='mean_squared_error', optimizer=Adam())\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                         patience = 300,\n",
        "                         verbose = 1,\n",
        "                         factor = 0.75,\n",
        "                         min_lr = 1e-6)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=600)\n",
        "nu_model_lat.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhBwFxzJTWRF",
        "outputId": "d6a047f3-5c23-4f03-b076-07807ed32a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 359038.8750 - val_loss: 247146.2812 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 358940.1562 - val_loss: 247061.6250 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 358842.5938 - val_loss: 246975.6562 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 358745.4688 - val_loss: 246887.3750 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 358641.6562 - val_loss: 246795.3438 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 358533.1250 - val_loss: 246699.7500 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 358421.9375 - val_loss: 246598.7188 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 358301.2812 - val_loss: 246491.4844 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 358176.0938 - val_loss: 246374.7500 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 358037.5000 - val_loss: 246249.4062 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 357892.4375 - val_loss: 246109.8281 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 357717.3438 - val_loss: 245956.1094 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 357543.2500 - val_loss: 245785.5781 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 357338.7188 - val_loss: 245603.8906 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 357123.5938 - val_loss: 245410.2500 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 356898.4062 - val_loss: 245204.6250 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 356671.6250 - val_loss: 244982.4062 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 356398.3750 - val_loss: 244755.7500 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 356137.2500 - val_loss: 244504.5781 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 355843.8750 - val_loss: 244237.0781 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 355533.0938 - val_loss: 243958.9219 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 355225.1562 - val_loss: 243662.0625 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 354871.2188 - val_loss: 243358.7656 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 354521.3438 - val_loss: 243042.7969 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 354159.1250 - val_loss: 242703.4531 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 353758.8125 - val_loss: 242355.9375 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 353354.8750 - val_loss: 241987.4219 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 352927.1562 - val_loss: 241608.0781 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 352481.0938 - val_loss: 241213.7969 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 352034.8750 - val_loss: 240802.4531 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 351561.9062 - val_loss: 240379.2031 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 351078.3438 - val_loss: 239934.0781 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 350556.9062 - val_loss: 239478.2500 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 350038.9375 - val_loss: 239007.4531 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 349500.4062 - val_loss: 238530.2344 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 348920.8438 - val_loss: 238043.6562 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 348366.0312 - val_loss: 237516.8906 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 347745.5000 - val_loss: 236963.3125 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 347121.5625 - val_loss: 236384.9219 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 346435.9062 - val_loss: 235805.2344 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 345782.0312 - val_loss: 235209.3750 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 345084.8750 - val_loss: 234603.6406 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 344407.3750 - val_loss: 233976.1250 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 343681.0000 - val_loss: 233342.1719 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 342924.6562 - val_loss: 232709.0156 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 342222.9375 - val_loss: 232051.7500 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 341470.6875 - val_loss: 231396.7656 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 340730.2500 - val_loss: 230729.9375 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 339952.8438 - val_loss: 230069.9375 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 339218.9375 - val_loss: 229394.1406 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 338458.4375 - val_loss: 228701.8125 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 337652.7188 - val_loss: 228032.2969 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 336883.1562 - val_loss: 227355.4688 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 336120.2500 - val_loss: 226674.6094 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 335311.1562 - val_loss: 225977.7188 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 334490.9688 - val_loss: 225235.3125 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 333622.6875 - val_loss: 224472.6875 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 332778.5938 - val_loss: 223698.0938 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 331906.9688 - val_loss: 222912.6250 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 330977.6250 - val_loss: 222117.8906 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 330047.8750 - val_loss: 221311.5938 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 329141.7500 - val_loss: 220481.5781 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 328203.4688 - val_loss: 219689.2812 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 327268.3750 - val_loss: 218893.4062 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 326324.0625 - val_loss: 218072.4375 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 325379.5312 - val_loss: 217209.7656 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 324383.4062 - val_loss: 216353.9062 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 323406.2500 - val_loss: 215476.3125 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 322390.5625 - val_loss: 214555.7188 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 321337.5625 - val_loss: 213633.5469 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 320259.3125 - val_loss: 212738.8125 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 319262.2188 - val_loss: 211829.2188 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 318191.2812 - val_loss: 210924.7812 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 317180.0938 - val_loss: 210014.0000 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 316125.1875 - val_loss: 209088.2656 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 315025.4375 - val_loss: 208154.9219 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 313941.7812 - val_loss: 207208.6562 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 312834.7812 - val_loss: 206233.6719 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 311776.8438 - val_loss: 205251.6875 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 310643.5000 - val_loss: 204285.6250 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 309502.5938 - val_loss: 203307.5312 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 308345.1250 - val_loss: 202336.1719 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 307221.8750 - val_loss: 201331.2031 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 306056.3125 - val_loss: 200310.0000 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304937.3125 - val_loss: 199305.0625 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 303735.6562 - val_loss: 198314.4844 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 302567.4062 - val_loss: 197325.2500 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301416.7812 - val_loss: 196315.1406 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300259.4375 - val_loss: 195319.9062 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299142.8125 - val_loss: 194331.4219 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 297990.7188 - val_loss: 193355.3750 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 296875.5000 - val_loss: 192371.5469 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295714.5938 - val_loss: 191379.0938 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 294602.5000 - val_loss: 190377.4531 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293411.1250 - val_loss: 189379.2656 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292253.0938 - val_loss: 188389.4531 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291079.5625 - val_loss: 187392.6562 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289918.1562 - val_loss: 186373.2969 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288756.2812 - val_loss: 185317.8906 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287458.6562 - val_loss: 184263.4531 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286293.5625 - val_loss: 183195.3438 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 285060.5938 - val_loss: 182141.3594 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 283796.3438 - val_loss: 181116.6875 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282645.0312 - val_loss: 180081.9688 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281430.1875 - val_loss: 179027.9219 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280168.0938 - val_loss: 178001.9375 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278930.7500 - val_loss: 176970.2500 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277714.5938 - val_loss: 175906.1719 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 276483.5312 - val_loss: 174819.3438 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 275229.7188 - val_loss: 173753.7500 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273906.0312 - val_loss: 172699.7656 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272757.7500 - val_loss: 171622.4844 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 271500.9375 - val_loss: 170559.4219 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 270151.0000 - val_loss: 169495.1250 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 268944.7188 - val_loss: 168373.0156 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267605.3438 - val_loss: 167286.0781 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 266379.0000 - val_loss: 166202.5312 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265035.0625 - val_loss: 165153.4844 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 263851.1562 - val_loss: 164094.7969 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 262585.6250 - val_loss: 163054.5000 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 261345.4375 - val_loss: 162058.0938 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260160.0625 - val_loss: 161061.5781 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258934.3281 - val_loss: 160020.1094 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 257728.7031 - val_loss: 158963.1406 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 256460.0625 - val_loss: 157945.6719 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 255252.5938 - val_loss: 156935.8125 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254041.7031 - val_loss: 155907.8125 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 252750.5312 - val_loss: 154844.3125 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 251474.1250 - val_loss: 153734.5156 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 250128.8594 - val_loss: 152658.8750 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 248878.9688 - val_loss: 151605.0625 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 247599.8281 - val_loss: 150560.4219 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 246371.5781 - val_loss: 149531.9375 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 245152.0000 - val_loss: 148525.7188 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 243863.9062 - val_loss: 147517.8594 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 242648.7500 - val_loss: 146432.8125 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 241299.8281 - val_loss: 145360.9375 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 240118.9219 - val_loss: 144276.3594 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 238741.4844 - val_loss: 143272.1719 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 237475.9688 - val_loss: 142250.8906 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 236207.1406 - val_loss: 141219.1406 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 235012.5938 - val_loss: 140162.0625 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 233749.7188 - val_loss: 139154.4375 - lr: 0.0010\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 232514.2344 - val_loss: 138153.9062 - lr: 0.0010\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 231207.9062 - val_loss: 137158.7188 - lr: 0.0010\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 230005.3281 - val_loss: 136149.3281 - lr: 0.0010\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 228774.4531 - val_loss: 135108.0781 - lr: 0.0010\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 227512.8750 - val_loss: 134085.4219 - lr: 0.0010\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 226179.7188 - val_loss: 133086.2344 - lr: 0.0010\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 225028.7188 - val_loss: 132099.8281 - lr: 0.0010\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 223751.2500 - val_loss: 131138.4688 - lr: 0.0010\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 222560.5625 - val_loss: 130190.1562 - lr: 0.0010\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 221318.5625 - val_loss: 129258.4297 - lr: 0.0010\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 220265.9062 - val_loss: 128259.2578 - lr: 0.0010\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 218984.0625 - val_loss: 127351.6562 - lr: 0.0010\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 217819.6406 - val_loss: 126484.9609 - lr: 0.0010\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 216724.4062 - val_loss: 125587.5547 - lr: 0.0010\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 215565.0938 - val_loss: 124687.3750 - lr: 0.0010\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 214467.5938 - val_loss: 123800.6172 - lr: 0.0010\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 213327.0625 - val_loss: 122929.6406 - lr: 0.0010\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 212192.9688 - val_loss: 122082.7969 - lr: 0.0010\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 211140.0625 - val_loss: 121196.2266 - lr: 0.0010\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 209991.2812 - val_loss: 120305.5703 - lr: 0.0010\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 208874.2031 - val_loss: 119422.5391 - lr: 0.0010\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 207754.4375 - val_loss: 118589.6719 - lr: 0.0010\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 206659.9531 - val_loss: 117755.5156 - lr: 0.0010\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 205561.2500 - val_loss: 116891.5156 - lr: 0.0010\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 204477.3438 - val_loss: 116020.2031 - lr: 0.0010\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 203302.0938 - val_loss: 115179.0156 - lr: 0.0010\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 202242.1562 - val_loss: 114309.5078 - lr: 0.0010\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 201108.2500 - val_loss: 113452.6172 - lr: 0.0010\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 199993.6406 - val_loss: 112580.0391 - lr: 0.0010\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 198849.1719 - val_loss: 111764.2969 - lr: 0.0010\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 197803.7500 - val_loss: 110962.2188 - lr: 0.0010\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 196767.0625 - val_loss: 110145.9922 - lr: 0.0010\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 195623.7656 - val_loss: 109384.2188 - lr: 0.0010\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 194530.3750 - val_loss: 108600.2969 - lr: 0.0010\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 193564.7031 - val_loss: 107739.9766 - lr: 0.0010\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 192409.0312 - val_loss: 106939.4375 - lr: 0.0010\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 191386.8750 - val_loss: 106147.1094 - lr: 0.0010\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 190309.2969 - val_loss: 105383.6875 - lr: 0.0010\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 189331.3750 - val_loss: 104642.4844 - lr: 0.0010\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 188303.7031 - val_loss: 103905.4531 - lr: 0.0010\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 187297.9062 - val_loss: 103166.0234 - lr: 0.0010\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 186288.2656 - val_loss: 102420.5078 - lr: 0.0010\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 185254.8438 - val_loss: 101677.3828 - lr: 0.0010\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 184325.3438 - val_loss: 100917.1250 - lr: 0.0010\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 183247.8438 - val_loss: 100199.7734 - lr: 0.0010\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 182262.3750 - val_loss: 99490.1328 - lr: 0.0010\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 181337.2344 - val_loss: 98775.0391 - lr: 0.0010\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 180354.8750 - val_loss: 98036.2812 - lr: 0.0010\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 179326.2500 - val_loss: 97327.8750 - lr: 0.0010\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 178325.5312 - val_loss: 96649.8984 - lr: 0.0010\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 177362.3750 - val_loss: 95945.0703 - lr: 0.0010\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 176524.4375 - val_loss: 95205.0391 - lr: 0.0010\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 175440.5781 - val_loss: 94536.0391 - lr: 0.0010\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 174445.8750 - val_loss: 93888.8281 - lr: 0.0010\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 173577.4531 - val_loss: 93188.0234 - lr: 0.0010\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 172560.6719 - val_loss: 92504.9688 - lr: 0.0010\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 171584.9688 - val_loss: 91826.5156 - lr: 0.0010\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 170619.7969 - val_loss: 91178.4219 - lr: 0.0010\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 169688.4375 - val_loss: 90573.1406 - lr: 0.0010\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 168838.2812 - val_loss: 89983.2266 - lr: 0.0010\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 167996.5156 - val_loss: 89385.5391 - lr: 0.0010\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 167105.0625 - val_loss: 88800.3438 - lr: 0.0010\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 166291.2969 - val_loss: 88164.8438 - lr: 0.0010\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 165392.7969 - val_loss: 87548.5703 - lr: 0.0010\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 164478.3281 - val_loss: 86944.5391 - lr: 0.0010\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 163603.5000 - val_loss: 86354.1641 - lr: 0.0010\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 162747.0312 - val_loss: 85771.8359 - lr: 0.0010\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 161900.6250 - val_loss: 85181.5547 - lr: 0.0010\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 161015.1250 - val_loss: 84615.7188 - lr: 0.0010\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 160169.7969 - val_loss: 84045.5234 - lr: 0.0010\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 159305.7969 - val_loss: 83489.1875 - lr: 0.0010\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 158544.6094 - val_loss: 82922.9609 - lr: 0.0010\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 157670.2031 - val_loss: 82386.5312 - lr: 0.0010\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 156854.0469 - val_loss: 81846.9688 - lr: 0.0010\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 156049.6250 - val_loss: 81314.9609 - lr: 0.0010\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 155231.9219 - val_loss: 80782.7031 - lr: 0.0010\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 154361.8750 - val_loss: 80254.3125 - lr: 0.0010\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 153596.8438 - val_loss: 79688.4531 - lr: 0.0010\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 152751.8750 - val_loss: 79152.4141 - lr: 0.0010\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 151950.6719 - val_loss: 78617.9844 - lr: 0.0010\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 151069.3281 - val_loss: 78120.5156 - lr: 0.0010\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 150362.5938 - val_loss: 77626.1172 - lr: 0.0010\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 149593.6250 - val_loss: 77139.0625 - lr: 0.0010\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 148803.7656 - val_loss: 76635.3438 - lr: 0.0010\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 147974.5156 - val_loss: 76131.2422 - lr: 0.0010\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 147220.7969 - val_loss: 75606.9609 - lr: 0.0010\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 146325.0312 - val_loss: 75109.3828 - lr: 0.0010\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 145610.8750 - val_loss: 74604.2422 - lr: 0.0010\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 144882.2188 - val_loss: 74104.1797 - lr: 0.0010\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 144020.8750 - val_loss: 73641.5703 - lr: 0.0010\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 143279.0781 - val_loss: 73173.1406 - lr: 0.0010\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 142514.9062 - val_loss: 72726.5234 - lr: 0.0010\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 141804.2500 - val_loss: 72273.6641 - lr: 0.0010\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 141016.5156 - val_loss: 71827.7188 - lr: 0.0010\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 140274.4844 - val_loss: 71339.5703 - lr: 0.0010\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 139469.7344 - val_loss: 70858.1875 - lr: 0.0010\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 138672.8594 - val_loss: 70361.1250 - lr: 0.0010\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 137857.5156 - val_loss: 69892.9297 - lr: 0.0010\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 137133.7500 - val_loss: 69445.1484 - lr: 0.0010\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 136393.5469 - val_loss: 69015.5859 - lr: 0.0010\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 135632.5625 - val_loss: 68594.3984 - lr: 0.0010\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 134913.2344 - val_loss: 68152.7891 - lr: 0.0010\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 134169.2969 - val_loss: 67741.2109 - lr: 0.0010\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 133487.3750 - val_loss: 67347.1797 - lr: 0.0010\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 132802.7031 - val_loss: 66971.2656 - lr: 0.0010\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 132102.1094 - val_loss: 66562.7969 - lr: 0.0010\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 131426.3125 - val_loss: 66138.3750 - lr: 0.0010\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 130709.9688 - val_loss: 65735.7500 - lr: 0.0010\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 129947.5469 - val_loss: 65347.5273 - lr: 0.0010\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 129275.9688 - val_loss: 64946.9219 - lr: 0.0010\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 128599.3672 - val_loss: 64568.9297 - lr: 0.0010\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 127928.1328 - val_loss: 64207.6719 - lr: 0.0010\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 127274.7656 - val_loss: 63858.3945 - lr: 0.0010\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 126632.8125 - val_loss: 63491.1055 - lr: 0.0010\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 125968.7344 - val_loss: 63099.9805 - lr: 0.0010\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 125231.7812 - val_loss: 62730.5781 - lr: 0.0010\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 124585.7500 - val_loss: 62382.9141 - lr: 0.0010\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 123992.5000 - val_loss: 62024.5938 - lr: 0.0010\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 123297.8906 - val_loss: 61689.8125 - lr: 0.0010\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 122705.3984 - val_loss: 61356.8711 - lr: 0.0010\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 122094.4922 - val_loss: 61033.2578 - lr: 0.0010\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 121469.5312 - val_loss: 60723.6992 - lr: 0.0010\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 120888.5781 - val_loss: 60410.3125 - lr: 0.0010\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 120353.2891 - val_loss: 60087.1133 - lr: 0.0010\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 119715.8203 - val_loss: 59784.5781 - lr: 0.0010\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 119121.6797 - val_loss: 59483.7969 - lr: 0.0010\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 118543.4141 - val_loss: 59178.5508 - lr: 0.0010\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 117952.0234 - val_loss: 58864.6641 - lr: 0.0010\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 117393.4297 - val_loss: 58556.6875 - lr: 0.0010\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 116765.1250 - val_loss: 58256.2578 - lr: 0.0010\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 116164.3125 - val_loss: 57960.1367 - lr: 0.0010\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 115622.3672 - val_loss: 57664.7930 - lr: 0.0010\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 115013.9531 - val_loss: 57369.3398 - lr: 0.0010\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 114418.8281 - val_loss: 57071.0938 - lr: 0.0010\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 113852.1719 - val_loss: 56789.0312 - lr: 0.0010\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 113304.6250 - val_loss: 56519.3203 - lr: 0.0010\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 112770.7969 - val_loss: 56246.3477 - lr: 0.0010\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 112217.0547 - val_loss: 55968.7695 - lr: 0.0010\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 111661.6250 - val_loss: 55699.9688 - lr: 0.0010\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 111106.5156 - val_loss: 55438.8984 - lr: 0.0010\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 110588.8594 - val_loss: 55178.0352 - lr: 0.0010\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 110069.6328 - val_loss: 54921.4336 - lr: 0.0010\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 109540.8125 - val_loss: 54666.9297 - lr: 0.0010\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 109004.9375 - val_loss: 54412.1211 - lr: 0.0010\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 108465.6484 - val_loss: 54160.4922 - lr: 0.0010\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 107970.1016 - val_loss: 53904.0781 - lr: 0.0010\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 107425.3594 - val_loss: 53655.5938 - lr: 0.0010\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 106935.4453 - val_loss: 53405.3945 - lr: 0.0010\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 106429.1484 - val_loss: 53162.4570 - lr: 0.0010\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 105937.1328 - val_loss: 52927.1016 - lr: 0.0010\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 105454.3125 - val_loss: 52700.3281 - lr: 0.0010\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 104979.1094 - val_loss: 52469.5859 - lr: 0.0010\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 104511.0234 - val_loss: 52248.6016 - lr: 0.0010\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 104062.8828 - val_loss: 52023.5742 - lr: 0.0010\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 103571.0234 - val_loss: 51794.7617 - lr: 0.0010\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 103109.9766 - val_loss: 51567.4922 - lr: 0.0010\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 102597.8594 - val_loss: 51344.0156 - lr: 0.0010\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 102149.4922 - val_loss: 51116.2305 - lr: 0.0010\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 101638.8672 - val_loss: 50901.6016 - lr: 0.0010\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 101123.0156 - val_loss: 50692.7422 - lr: 0.0010\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 100637.5625 - val_loss: 50480.6406 - lr: 0.0010\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 100142.4062 - val_loss: 50269.0586 - lr: 0.0010\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 99622.5859 - val_loss: 50058.4883 - lr: 0.0010\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 99139.2656 - val_loss: 49861.0234 - lr: 0.0010\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 98698.6953 - val_loss: 49659.7539 - lr: 0.0010\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 98260.1250 - val_loss: 49457.6133 - lr: 0.0010\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 97835.8125 - val_loss: 49258.9141 - lr: 0.0010\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 97352.1484 - val_loss: 49068.9375 - lr: 0.0010\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 96904.3984 - val_loss: 48877.5039 - lr: 0.0010\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 96456.7656 - val_loss: 48681.7422 - lr: 0.0010\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 96017.4844 - val_loss: 48489.2852 - lr: 0.0010\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 95590.3828 - val_loss: 48305.3359 - lr: 0.0010\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 95193.7500 - val_loss: 48128.4141 - lr: 0.0010\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 94746.5703 - val_loss: 47950.7227 - lr: 0.0010\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 94349.8906 - val_loss: 47771.6914 - lr: 0.0010\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 93955.8125 - val_loss: 47595.9062 - lr: 0.0010\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 93561.1406 - val_loss: 47427.5703 - lr: 0.0010\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 93143.1719 - val_loss: 47254.7227 - lr: 0.0010\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 92738.8125 - val_loss: 47094.6406 - lr: 0.0010\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 92328.5234 - val_loss: 46931.2383 - lr: 0.0010\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 91913.1875 - val_loss: 46764.1250 - lr: 0.0010\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 91550.0938 - val_loss: 46606.0391 - lr: 0.0010\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 91149.5391 - val_loss: 46442.2695 - lr: 0.0010\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 90770.6406 - val_loss: 46281.9883 - lr: 0.0010\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 90370.1406 - val_loss: 46114.2383 - lr: 0.0010\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 89979.0078 - val_loss: 45954.5938 - lr: 0.0010\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 89638.0000 - val_loss: 45792.4219 - lr: 0.0010\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 89250.1406 - val_loss: 45632.6328 - lr: 0.0010\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 88870.1016 - val_loss: 45474.9492 - lr: 0.0010\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 88512.4375 - val_loss: 45314.2031 - lr: 0.0010\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 88144.6953 - val_loss: 45149.7500 - lr: 0.0010\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 87807.0781 - val_loss: 45003.9805 - lr: 0.0010\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 87416.6641 - val_loss: 44849.5664 - lr: 0.0010\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 87046.2891 - val_loss: 44701.2266 - lr: 0.0010\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 86700.7266 - val_loss: 44559.3789 - lr: 0.0010\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 86357.6875 - val_loss: 44425.1172 - lr: 0.0010\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 86011.0547 - val_loss: 44273.2422 - lr: 0.0010\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 85642.5781 - val_loss: 44129.6836 - lr: 0.0010\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 85305.5781 - val_loss: 43992.0117 - lr: 0.0010\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 84969.0938 - val_loss: 43855.0742 - lr: 0.0010\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 84599.5938 - val_loss: 43715.2070 - lr: 0.0010\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 84252.6797 - val_loss: 43573.8555 - lr: 0.0010\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 83918.8984 - val_loss: 43442.6875 - lr: 0.0010\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 83576.8672 - val_loss: 43307.9570 - lr: 0.0010\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 83246.7266 - val_loss: 43188.6211 - lr: 0.0010\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 82880.1641 - val_loss: 43050.0547 - lr: 0.0010\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 82511.7656 - val_loss: 42923.2695 - lr: 0.0010\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 82208.2031 - val_loss: 42805.1953 - lr: 0.0010\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 81841.5469 - val_loss: 42684.8516 - lr: 0.0010\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 81511.6016 - val_loss: 42551.2812 - lr: 0.0010\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 81220.2812 - val_loss: 42431.4375 - lr: 0.0010\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 80855.2031 - val_loss: 42306.0820 - lr: 0.0010\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 80582.4141 - val_loss: 42180.0273 - lr: 0.0010\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 80229.0625 - val_loss: 42045.6055 - lr: 0.0010\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 79985.4922 - val_loss: 41923.2070 - lr: 0.0010\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 79651.6484 - val_loss: 41816.2031 - lr: 0.0010\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 79353.1484 - val_loss: 41707.8633 - lr: 0.0010\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 79038.0938 - val_loss: 41626.5625 - lr: 0.0010\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 78684.5469 - val_loss: 41526.1602 - lr: 0.0010\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 78382.5547 - val_loss: 41447.9648 - lr: 0.0010\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 78059.6875 - val_loss: 41372.0117 - lr: 0.0010\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 77710.0625 - val_loss: 41240.7344 - lr: 0.0010\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 77418.5312 - val_loss: 41111.8555 - lr: 0.0010\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 77143.7422 - val_loss: 40995.1484 - lr: 0.0010\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 76823.8672 - val_loss: 40889.8477 - lr: 0.0010\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 76560.5312 - val_loss: 40762.3008 - lr: 0.0010\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 76268.9766 - val_loss: 40635.2812 - lr: 0.0010\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 75994.3203 - val_loss: 40530.2148 - lr: 0.0010\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 75672.5938 - val_loss: 40425.0703 - lr: 0.0010\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 75391.5234 - val_loss: 40330.4414 - lr: 0.0010\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 75109.2266 - val_loss: 40244.6914 - lr: 0.0010\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 74843.2578 - val_loss: 40161.2148 - lr: 0.0010\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 74554.6953 - val_loss: 40048.4492 - lr: 0.0010\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 74307.9141 - val_loss: 39933.3203 - lr: 0.0010\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 74037.0469 - val_loss: 39823.7695 - lr: 0.0010\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73780.2734 - val_loss: 39706.7344 - lr: 0.0010\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73503.7734 - val_loss: 39612.3555 - lr: 0.0010\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 73258.7266 - val_loss: 39526.1562 - lr: 0.0010\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 73008.9219 - val_loss: 39436.4219 - lr: 0.0010\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 72763.2188 - val_loss: 39304.6094 - lr: 0.0010\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 72513.6094 - val_loss: 39169.3203 - lr: 0.0010\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 72256.3125 - val_loss: 39050.0977 - lr: 0.0010\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 72003.9766 - val_loss: 38940.6445 - lr: 0.0010\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 71763.6016 - val_loss: 38838.4648 - lr: 0.0010\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 71520.6172 - val_loss: 38761.1602 - lr: 0.0010\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 71236.2656 - val_loss: 38648.3125 - lr: 0.0010\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 70985.4922 - val_loss: 38538.8281 - lr: 0.0010\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 70763.0781 - val_loss: 38431.2695 - lr: 0.0010\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 70497.5625 - val_loss: 38299.9023 - lr: 0.0010\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 70260.4844 - val_loss: 38158.4648 - lr: 0.0010\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 70027.2812 - val_loss: 38059.7188 - lr: 0.0010\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 69770.2891 - val_loss: 37981.1758 - lr: 0.0010\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 69548.0859 - val_loss: 37908.8086 - lr: 0.0010\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 69270.7500 - val_loss: 37824.0078 - lr: 0.0010\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 69043.6250 - val_loss: 37734.9570 - lr: 0.0010\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 68800.1484 - val_loss: 37630.5703 - lr: 0.0010\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 68574.2031 - val_loss: 37525.5977 - lr: 0.0010\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 68341.9375 - val_loss: 37424.1016 - lr: 0.0010\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 68110.1719 - val_loss: 37327.0781 - lr: 0.0010\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 67864.3438 - val_loss: 37240.7188 - lr: 0.0010\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 67636.3125 - val_loss: 37137.0703 - lr: 0.0010\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 67391.3906 - val_loss: 36987.8828 - lr: 0.0010\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 67153.7969 - val_loss: 36836.4141 - lr: 0.0010\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 66954.2188 - val_loss: 36692.7578 - lr: 0.0010\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 66727.6172 - val_loss: 36559.1953 - lr: 0.0010\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 66504.4922 - val_loss: 36473.5430 - lr: 0.0010\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 66286.0547 - val_loss: 36366.3867 - lr: 0.0010\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 66056.7500 - val_loss: 36266.8438 - lr: 0.0010\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 65847.9062 - val_loss: 36160.9180 - lr: 0.0010\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 65632.0938 - val_loss: 36092.5156 - lr: 0.0010\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 65401.7734 - val_loss: 36002.7344 - lr: 0.0010\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 65198.0938 - val_loss: 35947.8125 - lr: 0.0010\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 64967.9922 - val_loss: 35889.9609 - lr: 0.0010\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 64765.1602 - val_loss: 35836.4648 - lr: 0.0010\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 64534.8594 - val_loss: 35751.6016 - lr: 0.0010\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 64313.2812 - val_loss: 35657.1797 - lr: 0.0010\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 64104.4766 - val_loss: 35574.8438 - lr: 0.0010\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 63872.1836 - val_loss: 35501.2617 - lr: 0.0010\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 63658.9766 - val_loss: 35421.1914 - lr: 0.0010\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 63422.9102 - val_loss: 35333.7305 - lr: 0.0010\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 63217.7930 - val_loss: 35260.4062 - lr: 0.0010\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 62969.9414 - val_loss: 35207.0977 - lr: 0.0010\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 62765.4414 - val_loss: 35167.2734 - lr: 0.0010\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 62535.7148 - val_loss: 35075.2578 - lr: 0.0010\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 62295.7148 - val_loss: 34992.3516 - lr: 0.0010\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 62095.9180 - val_loss: 34878.9961 - lr: 0.0010\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 61879.5938 - val_loss: 34770.1484 - lr: 0.0010\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 61679.5977 - val_loss: 34708.7891 - lr: 0.0010\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 61452.5273 - val_loss: 34647.3633 - lr: 0.0010\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 61245.8516 - val_loss: 34584.1406 - lr: 0.0010\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 61076.9570 - val_loss: 34509.0039 - lr: 0.0010\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 60879.7305 - val_loss: 34404.9688 - lr: 0.0010\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 60679.4609 - val_loss: 34306.0625 - lr: 0.0010\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 60503.7578 - val_loss: 34226.6992 - lr: 0.0010\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 60305.1211 - val_loss: 34128.8672 - lr: 0.0010\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 60130.8359 - val_loss: 34018.9180 - lr: 0.0010\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59935.9688 - val_loss: 33917.7461 - lr: 0.0010\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59751.2695 - val_loss: 33812.7539 - lr: 0.0010\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 59574.8750 - val_loss: 33704.4180 - lr: 0.0010\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 59384.0781 - val_loss: 33610.4023 - lr: 0.0010\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59209.4375 - val_loss: 33512.3711 - lr: 0.0010\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 59023.8555 - val_loss: 33404.8867 - lr: 0.0010\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 58854.9805 - val_loss: 33299.3633 - lr: 0.0010\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 58673.5586 - val_loss: 33198.1445 - lr: 0.0010\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 58505.2344 - val_loss: 33089.3438 - lr: 0.0010\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 58324.1406 - val_loss: 33003.1875 - lr: 0.0010\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 58150.4023 - val_loss: 32895.1016 - lr: 0.0010\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57961.1797 - val_loss: 32773.5977 - lr: 0.0010\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 57775.4570 - val_loss: 32708.7598 - lr: 0.0010\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57583.4805 - val_loss: 32656.1562 - lr: 0.0010\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 57380.5234 - val_loss: 32567.9531 - lr: 0.0010\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 57204.8984 - val_loss: 32506.8652 - lr: 0.0010\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 57011.3789 - val_loss: 32442.1504 - lr: 0.0010\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 56824.9062 - val_loss: 32396.5215 - lr: 0.0010\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 56645.4102 - val_loss: 32343.3965 - lr: 0.0010\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 56484.3633 - val_loss: 32282.0566 - lr: 0.0010\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 56308.0430 - val_loss: 32187.7891 - lr: 0.0010\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 56140.9648 - val_loss: 32114.6777 - lr: 0.0010\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 55975.7109 - val_loss: 32062.2930 - lr: 0.0010\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 55801.0000 - val_loss: 31987.5430 - lr: 0.0010\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 55611.5312 - val_loss: 31905.8711 - lr: 0.0010\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 55444.7812 - val_loss: 31831.9688 - lr: 0.0010\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 55259.4883 - val_loss: 31768.2715 - lr: 0.0010\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 55083.9922 - val_loss: 31713.1211 - lr: 0.0010\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 54900.6406 - val_loss: 31654.0859 - lr: 0.0010\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 54713.2344 - val_loss: 31562.3496 - lr: 0.0010\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 54532.3906 - val_loss: 31494.2363 - lr: 0.0010\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 54368.3477 - val_loss: 31434.3359 - lr: 0.0010\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 54203.9766 - val_loss: 31365.2324 - lr: 0.0010\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 54019.6133 - val_loss: 31281.1035 - lr: 0.0010\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 53854.0859 - val_loss: 31174.5566 - lr: 0.0010\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 53703.9219 - val_loss: 31070.2500 - lr: 0.0010\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 53536.7031 - val_loss: 30978.2598 - lr: 0.0010\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 53364.6289 - val_loss: 30861.0352 - lr: 0.0010\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 53196.8438 - val_loss: 30781.8926 - lr: 0.0010\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 53033.0195 - val_loss: 30695.5078 - lr: 0.0010\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52864.0703 - val_loss: 30595.8438 - lr: 0.0010\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52702.9414 - val_loss: 30464.3711 - lr: 0.0010\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52549.4297 - val_loss: 30341.0391 - lr: 0.0010\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 52401.3281 - val_loss: 30226.1250 - lr: 0.0010\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52245.5820 - val_loss: 30150.1562 - lr: 0.0010\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 52093.4023 - val_loss: 30066.9707 - lr: 0.0010\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 51929.9219 - val_loss: 30014.3926 - lr: 0.0010\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 51782.2617 - val_loss: 29948.3340 - lr: 0.0010\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 51631.8750 - val_loss: 29835.4180 - lr: 0.0010\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 51468.8438 - val_loss: 29694.8008 - lr: 0.0010\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 51330.7969 - val_loss: 29542.2539 - lr: 0.0010\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 51172.6719 - val_loss: 29403.9258 - lr: 0.0010\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 51023.5039 - val_loss: 29291.9707 - lr: 0.0010\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 50866.0898 - val_loss: 29211.1016 - lr: 0.0010\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 50689.7422 - val_loss: 29151.5762 - lr: 0.0010\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 50527.2500 - val_loss: 29086.1953 - lr: 0.0010\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 50374.4297 - val_loss: 29046.9316 - lr: 0.0010\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 50199.3984 - val_loss: 28970.3457 - lr: 0.0010\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 50051.8281 - val_loss: 28935.4277 - lr: 0.0010\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49905.2344 - val_loss: 28912.3242 - lr: 0.0010\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 49752.2969 - val_loss: 28852.7852 - lr: 0.0010\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 49599.8672 - val_loss: 28737.9512 - lr: 0.0010\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 49461.1719 - val_loss: 28653.6094 - lr: 0.0010\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49323.4766 - val_loss: 28578.8691 - lr: 0.0010\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49180.2617 - val_loss: 28463.5527 - lr: 0.0010\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 49042.9648 - val_loss: 28344.7402 - lr: 0.0010\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 48901.0430 - val_loss: 28256.8438 - lr: 0.0010\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 48755.7109 - val_loss: 28135.6562 - lr: 0.0010\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 48611.9805 - val_loss: 28012.8477 - lr: 0.0010\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 48460.7500 - val_loss: 27896.1367 - lr: 0.0010\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 48319.0664 - val_loss: 27792.5000 - lr: 0.0010\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 48170.4688 - val_loss: 27776.9082 - lr: 0.0010\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 48001.8633 - val_loss: 27740.1016 - lr: 0.0010\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 47845.7070 - val_loss: 27674.6836 - lr: 0.0010\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 47693.5625 - val_loss: 27612.7793 - lr: 0.0010\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 47529.4766 - val_loss: 27565.9531 - lr: 0.0010\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 47360.0742 - val_loss: 27522.1152 - lr: 0.0010\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 47217.7070 - val_loss: 27481.0156 - lr: 0.0010\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 47061.0391 - val_loss: 27418.8125 - lr: 0.0010\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 46918.9844 - val_loss: 27328.8555 - lr: 0.0010\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 46775.9688 - val_loss: 27187.9141 - lr: 0.0010\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 46641.7578 - val_loss: 27047.0801 - lr: 0.0010\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 46494.3203 - val_loss: 26919.0527 - lr: 0.0010\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 46370.8164 - val_loss: 26777.0723 - lr: 0.0010\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 46219.3828 - val_loss: 26708.6152 - lr: 0.0010\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 46084.0391 - val_loss: 26638.2227 - lr: 0.0010\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 45925.0117 - val_loss: 26545.2402 - lr: 0.0010\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 45787.7422 - val_loss: 26454.9277 - lr: 0.0010\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 45651.2305 - val_loss: 26369.3652 - lr: 0.0010\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 45507.2500 - val_loss: 26284.5312 - lr: 0.0010\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 45384.8047 - val_loss: 26174.6211 - lr: 0.0010\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 45243.2539 - val_loss: 26123.0723 - lr: 0.0010\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 45088.1172 - val_loss: 26062.6543 - lr: 0.0010\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 44975.8281 - val_loss: 26050.1055 - lr: 0.0010\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 44828.5742 - val_loss: 25981.9180 - lr: 0.0010\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 44696.1836 - val_loss: 25886.8984 - lr: 0.0010\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44580.4688 - val_loss: 25807.6953 - lr: 0.0010\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 44452.4375 - val_loss: 25758.5059 - lr: 0.0010\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 44313.0898 - val_loss: 25701.6602 - lr: 0.0010\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 44189.8477 - val_loss: 25603.0430 - lr: 0.0010\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 44062.7852 - val_loss: 25493.4785 - lr: 0.0010\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43933.7969 - val_loss: 25395.4180 - lr: 0.0010\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 43793.0000 - val_loss: 25316.1504 - lr: 0.0010\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43676.9883 - val_loss: 25241.5645 - lr: 0.0010\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 43539.2969 - val_loss: 25183.6836 - lr: 0.0010\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43406.9180 - val_loss: 25124.9277 - lr: 0.0010\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43272.7773 - val_loss: 25075.9121 - lr: 0.0010\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43145.1641 - val_loss: 25009.3379 - lr: 0.0010\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 43012.2383 - val_loss: 24950.2246 - lr: 0.0010\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 42888.0742 - val_loss: 24886.6426 - lr: 0.0010\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 42747.2500 - val_loss: 24844.9805 - lr: 0.0010\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 42617.1055 - val_loss: 24790.5488 - lr: 0.0010\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 42491.1680 - val_loss: 24720.4062 - lr: 0.0010\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 42357.9297 - val_loss: 24636.2227 - lr: 0.0010\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 42237.4219 - val_loss: 24562.9043 - lr: 0.0010\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 42112.9219 - val_loss: 24508.7676 - lr: 0.0010\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41988.9766 - val_loss: 24442.6426 - lr: 0.0010\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41867.9141 - val_loss: 24361.9414 - lr: 0.0010\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41757.8906 - val_loss: 24280.2168 - lr: 0.0010\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 41660.7930 - val_loss: 24249.3984 - lr: 0.0010\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41529.9258 - val_loss: 24139.0840 - lr: 0.0010\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41416.9375 - val_loss: 24069.2871 - lr: 0.0010\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 41287.3945 - val_loss: 24008.6309 - lr: 0.0010\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 41179.2891 - val_loss: 23965.7246 - lr: 0.0010\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 41068.6875 - val_loss: 23888.5352 - lr: 0.0010\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40965.4961 - val_loss: 23828.9844 - lr: 0.0010\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 40849.7617 - val_loss: 23775.5352 - lr: 0.0010\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40719.1367 - val_loss: 23721.9844 - lr: 0.0010\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 40620.1094 - val_loss: 23647.7402 - lr: 0.0010\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 40504.8945 - val_loss: 23595.4609 - lr: 0.0010\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 40391.4062 - val_loss: 23530.7812 - lr: 0.0010\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40276.9102 - val_loss: 23418.2539 - lr: 0.0010\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 40161.1172 - val_loss: 23308.6523 - lr: 0.0010\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 40058.1016 - val_loss: 23172.6328 - lr: 0.0010\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 39957.9844 - val_loss: 23040.3848 - lr: 0.0010\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 39833.0430 - val_loss: 22968.6562 - lr: 0.0010\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39717.3164 - val_loss: 22908.8223 - lr: 0.0010\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 39599.4375 - val_loss: 22836.0820 - lr: 0.0010\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39496.3984 - val_loss: 22739.7207 - lr: 0.0010\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 39386.0352 - val_loss: 22672.6641 - lr: 0.0010\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 39284.5781 - val_loss: 22643.1152 - lr: 0.0010\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 39174.2656 - val_loss: 22630.3184 - lr: 0.0010\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 39076.6562 - val_loss: 22623.4395 - lr: 0.0010\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38967.9688 - val_loss: 22599.3574 - lr: 0.0010\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38873.4727 - val_loss: 22543.5176 - lr: 0.0010\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 38767.8945 - val_loss: 22515.7676 - lr: 0.0010\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38663.0586 - val_loss: 22468.7090 - lr: 0.0010\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 38553.2383 - val_loss: 22384.0664 - lr: 0.0010\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 38442.4922 - val_loss: 22355.1836 - lr: 0.0010\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38345.4805 - val_loss: 22322.0645 - lr: 0.0010\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 38244.7930 - val_loss: 22304.6211 - lr: 0.0010\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38133.5352 - val_loss: 22226.6816 - lr: 0.0010\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 38030.0547 - val_loss: 22183.6562 - lr: 0.0010\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37940.6055 - val_loss: 22131.8926 - lr: 0.0010\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37843.7891 - val_loss: 22069.4492 - lr: 0.0010\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37746.8086 - val_loss: 21997.4336 - lr: 0.0010\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 37661.1836 - val_loss: 21920.2441 - lr: 0.0010\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37565.5312 - val_loss: 21844.0723 - lr: 0.0010\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37476.3555 - val_loss: 21743.3262 - lr: 0.0010\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37376.6250 - val_loss: 21667.5508 - lr: 0.0010\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 37274.3281 - val_loss: 21576.9512 - lr: 0.0010\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37174.5664 - val_loss: 21483.5078 - lr: 0.0010\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 37080.3594 - val_loss: 21436.1172 - lr: 0.0010\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36983.9062 - val_loss: 21387.1895 - lr: 0.0010\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36890.5312 - val_loss: 21333.1543 - lr: 0.0010\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36788.1719 - val_loss: 21289.3008 - lr: 0.0010\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 36686.7148 - val_loss: 21243.1016 - lr: 0.0010\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36605.4258 - val_loss: 21185.1172 - lr: 0.0010\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 36511.5508 - val_loss: 21126.6758 - lr: 0.0010\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36417.9453 - val_loss: 21060.3281 - lr: 0.0010\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36331.9805 - val_loss: 20980.9688 - lr: 0.0010\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36239.8281 - val_loss: 20920.2422 - lr: 0.0010\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 36155.0312 - val_loss: 20879.4805 - lr: 0.0010\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 36076.7969 - val_loss: 20841.6758 - lr: 0.0010\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35976.4297 - val_loss: 20748.5293 - lr: 0.0010\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35886.3633 - val_loss: 20718.6309 - lr: 0.0010\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35779.8555 - val_loss: 20650.4160 - lr: 0.0010\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35696.1289 - val_loss: 20583.4062 - lr: 0.0010\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35594.8125 - val_loss: 20524.8320 - lr: 0.0010\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35506.3398 - val_loss: 20477.7637 - lr: 0.0010\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35422.1094 - val_loss: 20422.9883 - lr: 0.0010\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 35329.0742 - val_loss: 20366.1855 - lr: 0.0010\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35243.9766 - val_loss: 20298.0098 - lr: 0.0010\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 35167.3320 - val_loss: 20260.1777 - lr: 0.0010\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 35076.9805 - val_loss: 20202.1406 - lr: 0.0010\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34988.4062 - val_loss: 20155.2246 - lr: 0.0010\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34916.2031 - val_loss: 20105.7910 - lr: 0.0010\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34831.8672 - val_loss: 20068.2344 - lr: 0.0010\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34759.5898 - val_loss: 20035.4277 - lr: 0.0010\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 34668.7930 - val_loss: 19973.0547 - lr: 0.0010\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34597.1914 - val_loss: 19907.7461 - lr: 0.0010\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34506.0234 - val_loss: 19832.7754 - lr: 0.0010\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 34435.1133 - val_loss: 19779.7070 - lr: 0.0010\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34342.6250 - val_loss: 19760.4082 - lr: 0.0010\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 34270.6094 - val_loss: 19774.8047 - lr: 0.0010\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34171.4531 - val_loss: 19776.5059 - lr: 0.0010\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34085.2930 - val_loss: 19798.9277 - lr: 0.0010\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 34010.4961 - val_loss: 19810.4395 - lr: 0.0010\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33917.5000 - val_loss: 19752.7363 - lr: 0.0010\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33828.2812 - val_loss: 19690.2871 - lr: 0.0010\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33749.9883 - val_loss: 19618.0312 - lr: 0.0010\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33674.0234 - val_loss: 19572.1953 - lr: 0.0010\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33601.4062 - val_loss: 19537.3496 - lr: 0.0010\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 33515.7578 - val_loss: 19506.7012 - lr: 0.0010\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33435.3125 - val_loss: 19464.8984 - lr: 0.0010\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33358.6133 - val_loss: 19430.5820 - lr: 0.0010\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33278.4805 - val_loss: 19376.0293 - lr: 0.0010\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 33211.6719 - val_loss: 19349.0859 - lr: 0.0010\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 33126.1719 - val_loss: 19302.2578 - lr: 0.0010\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 33049.7773 - val_loss: 19243.3008 - lr: 0.0010\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32975.7969 - val_loss: 19185.0254 - lr: 0.0010\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32896.5547 - val_loss: 19141.5938 - lr: 0.0010\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32830.1523 - val_loss: 19105.0918 - lr: 0.0010\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32756.0449 - val_loss: 19019.9316 - lr: 0.0010\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32677.6504 - val_loss: 18926.7734 - lr: 0.0010\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32614.5293 - val_loss: 18832.8184 - lr: 0.0010\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 32538.6543 - val_loss: 18758.1016 - lr: 0.0010\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32486.4707 - val_loss: 18661.1484 - lr: 0.0010\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32422.2383 - val_loss: 18581.2539 - lr: 0.0010\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32347.5156 - val_loss: 18530.5234 - lr: 0.0010\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32283.8867 - val_loss: 18493.7129 - lr: 0.0010\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 32213.9668 - val_loss: 18467.0195 - lr: 0.0010\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32140.6465 - val_loss: 18443.7188 - lr: 0.0010\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 32063.2793 - val_loss: 18436.3965 - lr: 0.0010\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31996.1172 - val_loss: 18399.6445 - lr: 0.0010\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31926.5078 - val_loss: 18361.7930 - lr: 0.0010\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31861.6328 - val_loss: 18313.3691 - lr: 0.0010\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31802.0156 - val_loss: 18262.7246 - lr: 0.0010\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31736.9844 - val_loss: 18265.4492 - lr: 0.0010\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31672.5215 - val_loss: 18305.0762 - lr: 0.0010\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31591.1719 - val_loss: 18296.4062 - lr: 0.0010\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31522.3418 - val_loss: 18271.7422 - lr: 0.0010\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 31455.2500 - val_loss: 18227.7188 - lr: 0.0010\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 31385.4297 - val_loss: 18192.4453 - lr: 0.0010\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 31321.2324 - val_loss: 18152.4570 - lr: 0.0010\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31245.9297 - val_loss: 18073.3477 - lr: 0.0010\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31189.1504 - val_loss: 17990.8887 - lr: 0.0010\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 31124.1797 - val_loss: 17918.8965 - lr: 0.0010\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 31067.5371 - val_loss: 17846.3984 - lr: 0.0010\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 31008.5801 - val_loss: 17783.2324 - lr: 0.0010\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 30953.7578 - val_loss: 17726.4355 - lr: 0.0010\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 30893.0449 - val_loss: 17682.0664 - lr: 0.0010\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30824.7656 - val_loss: 17657.3066 - lr: 0.0010\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30751.8906 - val_loss: 17647.4961 - lr: 0.0010\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30682.1328 - val_loss: 17654.3867 - lr: 0.0010\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30625.3555 - val_loss: 17648.9688 - lr: 0.0010\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30542.0156 - val_loss: 17616.9453 - lr: 0.0010\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30480.1094 - val_loss: 17571.9844 - lr: 0.0010\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30416.7520 - val_loss: 17526.4961 - lr: 0.0010\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 30345.3359 - val_loss: 17538.7188 - lr: 0.0010\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 30284.4199 - val_loss: 17569.9453 - lr: 0.0010\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30206.2656 - val_loss: 17554.1777 - lr: 0.0010\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 30165.3457 - val_loss: 17564.8984 - lr: 0.0010\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30086.0117 - val_loss: 17567.6895 - lr: 0.0010\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 30022.1816 - val_loss: 17570.6406 - lr: 0.0010\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29962.2344 - val_loss: 17566.1777 - lr: 0.0010\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29906.0938 - val_loss: 17544.0430 - lr: 0.0010\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29840.9902 - val_loss: 17527.6836 - lr: 0.0010\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29773.1074 - val_loss: 17508.9102 - lr: 0.0010\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29722.0605 - val_loss: 17510.4570 - lr: 0.0010\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29657.2637 - val_loss: 17472.8770 - lr: 0.0010\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29600.5273 - val_loss: 17431.8926 - lr: 0.0010\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29542.7598 - val_loss: 17385.7148 - lr: 0.0010\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29482.3301 - val_loss: 17357.1562 - lr: 0.0010\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 29433.8281 - val_loss: 17289.9160 - lr: 0.0010\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29373.9375 - val_loss: 17213.9395 - lr: 0.0010\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29316.3574 - val_loss: 17143.3008 - lr: 0.0010\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 29269.7461 - val_loss: 17069.3691 - lr: 0.0010\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29207.0859 - val_loss: 17030.4785 - lr: 0.0010\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29155.9531 - val_loss: 16985.1016 - lr: 0.0010\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29093.5000 - val_loss: 16930.9668 - lr: 0.0010\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 29035.8105 - val_loss: 16912.9590 - lr: 0.0010\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28969.3906 - val_loss: 16897.2500 - lr: 0.0010\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28922.8867 - val_loss: 16914.3945 - lr: 0.0010\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 28855.4727 - val_loss: 16877.1016 - lr: 0.0010\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28808.1035 - val_loss: 16819.6328 - lr: 0.0010\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28755.5137 - val_loss: 16764.0742 - lr: 0.0010\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28708.8125 - val_loss: 16714.3789 - lr: 0.0010\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 28650.9316 - val_loss: 16690.5449 - lr: 0.0010\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28601.6309 - val_loss: 16652.5410 - lr: 0.0010\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28556.0234 - val_loss: 16618.9180 - lr: 0.0010\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28510.6953 - val_loss: 16594.9766 - lr: 0.0010\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28452.3340 - val_loss: 16605.0488 - lr: 0.0010\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28409.1270 - val_loss: 16629.2598 - lr: 0.0010\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28365.3867 - val_loss: 16616.3145 - lr: 0.0010\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 28320.0879 - val_loss: 16602.8672 - lr: 0.0010\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28265.0059 - val_loss: 16605.6152 - lr: 0.0010\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28231.5801 - val_loss: 16644.9590 - lr: 0.0010\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 28161.3594 - val_loss: 16668.0605 - lr: 0.0010\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28114.8262 - val_loss: 16685.6016 - lr: 0.0010\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 28072.1953 - val_loss: 16674.8613 - lr: 0.0010\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 28014.4434 - val_loss: 16696.6406 - lr: 0.0010\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27976.4883 - val_loss: 16726.0664 - lr: 0.0010\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27922.7617 - val_loss: 16714.7676 - lr: 0.0010\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27884.9746 - val_loss: 16703.4043 - lr: 0.0010\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27830.4707 - val_loss: 16658.5449 - lr: 0.0010\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27780.4219 - val_loss: 16586.9082 - lr: 0.0010\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27734.3477 - val_loss: 16556.8828 - lr: 0.0010\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27678.0312 - val_loss: 16530.6855 - lr: 0.0010\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27639.6230 - val_loss: 16512.0410 - lr: 0.0010\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27584.1406 - val_loss: 16476.4609 - lr: 0.0010\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27539.2812 - val_loss: 16431.7734 - lr: 0.0010\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27502.4199 - val_loss: 16368.1699 - lr: 0.0010\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27457.3086 - val_loss: 16307.2354 - lr: 0.0010\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27421.9453 - val_loss: 16257.7344 - lr: 0.0010\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27380.0996 - val_loss: 16243.9141 - lr: 0.0010\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27334.5840 - val_loss: 16227.6943 - lr: 0.0010\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 27293.1680 - val_loss: 16227.8057 - lr: 0.0010\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27257.7910 - val_loss: 16210.7715 - lr: 0.0010\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 27207.3145 - val_loss: 16201.2461 - lr: 0.0010\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27175.7383 - val_loss: 16185.1504 - lr: 0.0010\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27130.9180 - val_loss: 16168.6719 - lr: 0.0010\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 27099.1973 - val_loss: 16184.8164 - lr: 0.0010\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 27051.4590 - val_loss: 16168.9287 - lr: 0.0010\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 27014.6660 - val_loss: 16140.3232 - lr: 0.0010\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26978.1562 - val_loss: 16130.7861 - lr: 0.0010\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26936.1133 - val_loss: 16150.1963 - lr: 0.0010\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26888.6719 - val_loss: 16139.2627 - lr: 0.0010\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26846.9219 - val_loss: 16099.5840 - lr: 0.0010\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26808.8418 - val_loss: 16071.0537 - lr: 0.0010\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26769.9492 - val_loss: 16059.2549 - lr: 0.0010\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26736.6855 - val_loss: 16059.8574 - lr: 0.0010\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26705.6582 - val_loss: 16033.1123 - lr: 0.0010\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26672.8320 - val_loss: 16029.2461 - lr: 0.0010\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26635.4219 - val_loss: 16011.3164 - lr: 0.0010\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 26605.7012 - val_loss: 15971.8320 - lr: 0.0010\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26562.5469 - val_loss: 15942.1211 - lr: 0.0010\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26539.4668 - val_loss: 15903.3516 - lr: 0.0010\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26512.9707 - val_loss: 15869.8818 - lr: 0.0010\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26487.3945 - val_loss: 15836.2734 - lr: 0.0010\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26463.3633 - val_loss: 15800.3086 - lr: 0.0010\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26436.7832 - val_loss: 15799.2002 - lr: 0.0010\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26399.4570 - val_loss: 15782.4746 - lr: 0.0010\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26379.2539 - val_loss: 15755.8037 - lr: 0.0010\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26356.4238 - val_loss: 15739.5479 - lr: 0.0010\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26322.5762 - val_loss: 15730.1807 - lr: 0.0010\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26297.2656 - val_loss: 15710.4805 - lr: 0.0010\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26268.0156 - val_loss: 15684.7266 - lr: 0.0010\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26244.0371 - val_loss: 15660.7354 - lr: 0.0010\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26219.4492 - val_loss: 15647.8682 - lr: 0.0010\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26196.2969 - val_loss: 15635.4326 - lr: 0.0010\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26174.5039 - val_loss: 15587.8281 - lr: 0.0010\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 26142.0723 - val_loss: 15559.6104 - lr: 0.0010\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26116.3594 - val_loss: 15534.4844 - lr: 0.0010\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26097.5254 - val_loss: 15524.5889 - lr: 0.0010\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26081.7754 - val_loss: 15543.5264 - lr: 0.0010\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 26040.2012 - val_loss: 15547.6768 - lr: 0.0010\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 26011.6895 - val_loss: 15560.2754 - lr: 0.0010\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25989.1875 - val_loss: 15575.6289 - lr: 0.0010\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25961.7148 - val_loss: 15587.0605 - lr: 0.0010\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25944.3262 - val_loss: 15596.7236 - lr: 0.0010\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25916.0840 - val_loss: 15577.5469 - lr: 0.0010\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25889.3379 - val_loss: 15587.5732 - lr: 0.0010\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25858.3652 - val_loss: 15588.9121 - lr: 0.0010\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25832.7266 - val_loss: 15585.1230 - lr: 0.0010\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25805.3027 - val_loss: 15605.4326 - lr: 0.0010\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25772.2363 - val_loss: 15607.6035 - lr: 0.0010\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25741.8164 - val_loss: 15596.1250 - lr: 0.0010\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25715.2832 - val_loss: 15607.0020 - lr: 0.0010\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25684.8535 - val_loss: 15610.8535 - lr: 0.0010\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 25658.4980 - val_loss: 15615.4736 - lr: 0.0010\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25635.8145 - val_loss: 15607.5498 - lr: 0.0010\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25609.9785 - val_loss: 15598.2305 - lr: 0.0010\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25585.9551 - val_loss: 15560.6270 - lr: 0.0010\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25556.4180 - val_loss: 15536.1104 - lr: 0.0010\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25533.9141 - val_loss: 15522.4414 - lr: 0.0010\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25517.1309 - val_loss: 15507.8271 - lr: 0.0010\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25493.4434 - val_loss: 15481.8271 - lr: 0.0010\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25475.2324 - val_loss: 15461.6895 - lr: 0.0010\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 25458.4199 - val_loss: 15452.2324 - lr: 0.0010\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25435.5020 - val_loss: 15442.7910 - lr: 0.0010\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 25418.0039 - val_loss: 15421.2451 - lr: 0.0010\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25396.1328 - val_loss: 15402.5000 - lr: 0.0010\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25383.0801 - val_loss: 15396.4502 - lr: 0.0010\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25361.6152 - val_loss: 15385.4180 - lr: 0.0010\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25336.0137 - val_loss: 15402.5068 - lr: 0.0010\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 25307.4121 - val_loss: 15460.5361 - lr: 0.0010\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25281.2422 - val_loss: 15511.4014 - lr: 0.0010\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25258.6543 - val_loss: 15520.2412 - lr: 0.0010\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25224.4336 - val_loss: 15500.9121 - lr: 0.0010\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25205.2949 - val_loss: 15490.7305 - lr: 0.0010\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25183.3848 - val_loss: 15483.6143 - lr: 0.0010\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25160.8301 - val_loss: 15492.4268 - lr: 0.0010\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25148.4062 - val_loss: 15511.4424 - lr: 0.0010\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25121.6973 - val_loss: 15499.6680 - lr: 0.0010\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25106.7930 - val_loss: 15470.3682 - lr: 0.0010\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25084.5566 - val_loss: 15448.3408 - lr: 0.0010\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 25071.4844 - val_loss: 15436.2588 - lr: 0.0010\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25058.5996 - val_loss: 15434.6641 - lr: 0.0010\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25045.7656 - val_loss: 15421.8857 - lr: 0.0010\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25027.3613 - val_loss: 15429.3623 - lr: 0.0010\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 25017.4316 - val_loss: 15462.4961 - lr: 0.0010\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24980.9355 - val_loss: 15462.5479 - lr: 0.0010\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24964.5645 - val_loss: 15473.0625 - lr: 0.0010\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24939.9766 - val_loss: 15463.0371 - lr: 0.0010\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24921.9121 - val_loss: 15441.7344 - lr: 0.0010\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24903.9961 - val_loss: 15432.6826 - lr: 0.0010\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24883.5938 - val_loss: 15428.8555 - lr: 0.0010\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24867.2402 - val_loss: 15420.7588 - lr: 0.0010\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24854.9062 - val_loss: 15410.7305 - lr: 0.0010\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 24836.4219 - val_loss: 15435.8965 - lr: 0.0010\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24818.6152 - val_loss: 15428.1748 - lr: 0.0010\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24803.1992 - val_loss: 15426.8428 - lr: 0.0010\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24791.9648 - val_loss: 15418.3018 - lr: 0.0010\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24777.3438 - val_loss: 15429.9424 - lr: 0.0010\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24761.0801 - val_loss: 15438.8193 - lr: 0.0010\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24751.6562 - val_loss: 15452.6016 - lr: 0.0010\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24730.9707 - val_loss: 15452.8408 - lr: 0.0010\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24731.9805 - val_loss: 15430.6123 - lr: 0.0010\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 24707.9199 - val_loss: 15407.6699 - lr: 0.0010\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24698.1992 - val_loss: 15387.5576 - lr: 0.0010\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 24699.7852 - val_loss: 15373.9482 - lr: 0.0010\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24678.7617 - val_loss: 15362.6807 - lr: 0.0010\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24673.1445 - val_loss: 15341.2432 - lr: 0.0010\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24656.8418 - val_loss: 15348.8750 - lr: 0.0010\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24642.3945 - val_loss: 15367.5586 - lr: 0.0010\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24618.2969 - val_loss: 15388.0537 - lr: 0.0010\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24616.4688 - val_loss: 15423.0537 - lr: 0.0010\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24582.1719 - val_loss: 15427.7930 - lr: 0.0010\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24567.6914 - val_loss: 15437.7891 - lr: 0.0010\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24551.4238 - val_loss: 15469.0840 - lr: 0.0010\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24520.1348 - val_loss: 15488.5586 - lr: 0.0010\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24508.8398 - val_loss: 15506.8535 - lr: 0.0010\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24493.1426 - val_loss: 15518.3896 - lr: 0.0010\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24477.2402 - val_loss: 15510.3984 - lr: 0.0010\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24470.4746 - val_loss: 15486.1504 - lr: 0.0010\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24451.2246 - val_loss: 15462.7734 - lr: 0.0010\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24450.5703 - val_loss: 15434.3623 - lr: 0.0010\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24434.0762 - val_loss: 15432.6963 - lr: 0.0010\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24425.2324 - val_loss: 15448.5156 - lr: 0.0010\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24410.5820 - val_loss: 15447.6104 - lr: 0.0010\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24395.7734 - val_loss: 15443.2305 - lr: 0.0010\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24385.0820 - val_loss: 15428.5391 - lr: 0.0010\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24371.8164 - val_loss: 15418.4033 - lr: 0.0010\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24355.7676 - val_loss: 15439.3018 - lr: 0.0010\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24348.4590 - val_loss: 15464.2754 - lr: 0.0010\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24330.6523 - val_loss: 15476.1143 - lr: 0.0010\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24321.5039 - val_loss: 15472.2051 - lr: 0.0010\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24312.1328 - val_loss: 15465.7891 - lr: 0.0010\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24310.8789 - val_loss: 15445.2373 - lr: 0.0010\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24294.1133 - val_loss: 15482.1592 - lr: 0.0010\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24278.3438 - val_loss: 15500.7090 - lr: 0.0010\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24265.0098 - val_loss: 15501.5928 - lr: 0.0010\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24252.6348 - val_loss: 15494.4629 - lr: 0.0010\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24244.0742 - val_loss: 15509.2031 - lr: 0.0010\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 24229.9844 - val_loss: 15492.4873 - lr: 0.0010\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24233.1680 - val_loss: 15500.1357 - lr: 0.0010\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24204.2656 - val_loss: 15484.2031 - lr: 0.0010\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 24194.8613 - val_loss: 15464.1719 - lr: 0.0010\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24185.0039 - val_loss: 15451.9395 - lr: 0.0010\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24182.0156 - val_loss: 15470.0986 - lr: 0.0010\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24165.5703 - val_loss: 15473.6514 - lr: 0.0010\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24156.4844 - val_loss: 15474.6035 - lr: 0.0010\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24150.4453 - val_loss: 15476.2021 - lr: 0.0010\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24133.5801 - val_loss: 15514.9629 - lr: 0.0010\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24127.6035 - val_loss: 15544.9053 - lr: 0.0010\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24116.4570 - val_loss: 15559.2354 - lr: 0.0010\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24110.3164 - val_loss: 15552.0107 - lr: 0.0010\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24096.4629 - val_loss: 15536.8174 - lr: 0.0010\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 24089.1348 - val_loss: 15551.9951 - lr: 0.0010\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24074.9414 - val_loss: 15545.8574 - lr: 0.0010\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24068.4375 - val_loss: 15537.8750 - lr: 0.0010\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24061.1172 - val_loss: 15520.4033 - lr: 0.0010\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24052.4414 - val_loss: 15503.2607 - lr: 0.0010\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24046.9570 - val_loss: 15491.0049 - lr: 0.0010\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24034.5547 - val_loss: 15479.8711 - lr: 0.0010\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 24026.5879 - val_loss: 15471.6787 - lr: 0.0010\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 24021.7871 - val_loss: 15496.5361 - lr: 0.0010\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24013.6367 - val_loss: 15516.5645 - lr: 0.0010\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24005.4922 - val_loss: 15514.0967 - lr: 0.0010\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 24001.1680 - val_loss: 15489.1592 - lr: 0.0010\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23992.8613 - val_loss: 15495.9658 - lr: 0.0010\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23981.6133 - val_loss: 15479.6914 - lr: 0.0010\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23973.4062 - val_loss: 15484.2754 - lr: 0.0010\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23965.3672 - val_loss: 15486.3594 - lr: 0.0010\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23956.7773 - val_loss: 15478.4932 - lr: 0.0010\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23946.7344 - val_loss: 15477.8750 - lr: 0.0010\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23932.7363 - val_loss: 15497.3037 - lr: 0.0010\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23928.2871 - val_loss: 15494.8730 - lr: 0.0010\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23916.4805 - val_loss: 15492.6094 - lr: 0.0010\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 23912.6348 - val_loss: 15489.0908 - lr: 0.0010\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23906.8184 - val_loss: 15509.4336 - lr: 0.0010\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23903.7422 - val_loss: 15524.0557 - lr: 0.0010\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23891.6992 - val_loss: 15508.9336 - lr: 0.0010\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23889.5273 - val_loss: 15491.1855 - lr: 0.0010\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23872.8867 - val_loss: 15469.2627 - lr: 0.0010\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23868.0918 - val_loss: 15465.8408 - lr: 0.0010\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23855.0410 - val_loss: 15455.9824 - lr: 0.0010\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23847.5391 - val_loss: 15439.4053 - lr: 0.0010\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23839.4473 - val_loss: 15421.4004 - lr: 0.0010\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23839.1270 - val_loss: 15421.0820 - lr: 0.0010\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23830.7285 - val_loss: 15419.6680 - lr: 0.0010\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23826.7871 - val_loss: 15436.3252 - lr: 0.0010\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23826.9355 - val_loss: 15445.5859 - lr: 0.0010\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23811.5078 - val_loss: 15442.2979 - lr: 0.0010\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23810.9336 - val_loss: 15445.5859 - lr: 0.0010\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23795.9980 - val_loss: 15461.4229 - lr: 0.0010\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23788.4707 - val_loss: 15458.9111 - lr: 0.0010\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23784.1504 - val_loss: 15465.9336 - lr: 0.0010\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23779.4219 - val_loss: 15468.9014 - lr: 0.0010\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23776.7480 - val_loss: 15462.3857 - lr: 0.0010\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23766.6211 - val_loss: 15463.3252 - lr: 0.0010\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23762.3535 - val_loss: 15451.7070 - lr: 0.0010\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23758.2168 - val_loss: 15446.8076 - lr: 0.0010\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23746.0918 - val_loss: 15474.7021 - lr: 0.0010\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23749.9102 - val_loss: 15502.3320 - lr: 0.0010\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23732.4004 - val_loss: 15509.2266 - lr: 0.0010\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23728.4883 - val_loss: 15509.2549 - lr: 0.0010\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23724.5918 - val_loss: 15529.3555 - lr: 0.0010\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23725.0449 - val_loss: 15542.4424 - lr: 0.0010\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23716.2207 - val_loss: 15524.3730 - lr: 0.0010\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 23710.8281 - val_loss: 15488.1660 - lr: 0.0010\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23703.8867 - val_loss: 15455.7246 - lr: 0.0010\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23699.7969 - val_loss: 15435.2588 - lr: 0.0010\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23692.6289 - val_loss: 15439.1016 - lr: 0.0010\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23689.7207 - val_loss: 15425.1201 - lr: 0.0010\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23683.1719 - val_loss: 15409.3604 - lr: 0.0010\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23677.2168 - val_loss: 15397.3086 - lr: 0.0010\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23673.4980 - val_loss: 15386.8408 - lr: 0.0010\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23671.4883 - val_loss: 15361.5107 - lr: 0.0010\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23669.5332 - val_loss: 15345.3838 - lr: 0.0010\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23664.5332 - val_loss: 15327.9463 - lr: 0.0010\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23662.7246 - val_loss: 15310.4375 - lr: 0.0010\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23663.1172 - val_loss: 15316.8594 - lr: 0.0010\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23651.8301 - val_loss: 15315.9014 - lr: 0.0010\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23650.6133 - val_loss: 15326.6611 - lr: 0.0010\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23646.6445 - val_loss: 15326.3701 - lr: 0.0010\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23645.1133 - val_loss: 15328.4893 - lr: 0.0010\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23638.9922 - val_loss: 15359.1465 - lr: 0.0010\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23637.5957 - val_loss: 15391.0303 - lr: 0.0010\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23635.6328 - val_loss: 15407.0303 - lr: 0.0010\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23630.2695 - val_loss: 15412.8926 - lr: 0.0010\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23626.5332 - val_loss: 15409.0625 - lr: 0.0010\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23620.3125 - val_loss: 15421.3389 - lr: 0.0010\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23621.7871 - val_loss: 15414.0371 - lr: 0.0010\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23616.2988 - val_loss: 15419.5322 - lr: 0.0010\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23617.1172 - val_loss: 15433.0771 - lr: 0.0010\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23607.8438 - val_loss: 15428.6406 - lr: 0.0010\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23597.7715 - val_loss: 15445.6211 - lr: 0.0010\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23616.9551 - val_loss: 15458.7734 - lr: 0.0010\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23582.1777 - val_loss: 15471.6553 - lr: 0.0010\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 23578.0273 - val_loss: 15493.7764 - lr: 0.0010\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23568.8340 - val_loss: 15500.2520 - lr: 0.0010\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23566.9121 - val_loss: 15521.4609 - lr: 0.0010\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 23556.0645 - val_loss: 15529.6484 - lr: 0.0010\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23553.0527 - val_loss: 15541.7646 - lr: 0.0010\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23549.7695 - val_loss: 15548.7344 - lr: 0.0010\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23546.1602 - val_loss: 15560.6836 - lr: 0.0010\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23542.2852 - val_loss: 15552.1104 - lr: 0.0010\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23538.2500 - val_loss: 15557.9180 - lr: 0.0010\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23535.8145 - val_loss: 15601.1826 - lr: 0.0010\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23526.3164 - val_loss: 15628.4521 - lr: 0.0010\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23514.7852 - val_loss: 15634.5820 - lr: 0.0010\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23513.7188 - val_loss: 15646.3037 - lr: 0.0010\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23504.9297 - val_loss: 15636.9854 - lr: 0.0010\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 23505.0312 - val_loss: 15641.0430 - lr: 0.0010\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23497.3027 - val_loss: 15648.4893 - lr: 0.0010\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23494.2031 - val_loss: 15646.8701 - lr: 0.0010\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23496.6973 - val_loss: 15649.6826 - lr: 0.0010\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 23483.2852 - val_loss: 15645.0820 - lr: 0.0010\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 23484.1387 - val_loss: 15634.3926 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "#lat_history = nu_model_lat.fit(X_train_norm, y_train_lat, validation_split=0.2, batch_size=32, epochs=8000, callbacks=[lrd, mcp, es])\n",
        "lat_history = nu_model_lat.fit(X_train_norm, y_train_lat, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[lrd, mcp, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTLs2OEtWXBb",
        "outputId": "aa11c4c0-ff58-4784-f68e-71498f92866d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 16779.5078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16779.5078125"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "nu_model_lat.evaluate(X_test_norm, y_test_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEFOeq7Xei3U",
        "outputId": "1d968c58-58bc-46b4-f0f5-71e5d3f6ce37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2421.5093]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "nu_model_lat.predict([[3,13,1,0,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dbAYhXsgaY-1"
      },
      "outputs": [],
      "source": [
        "y_pred_lat = nu_model_lat.predict(X_test_norm)\n",
        "# y_pred_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RCwlmwvYPh3",
        "outputId": "fc31fd1c-0ba8-4bc2-8685-379326dc4316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score is 0.789916910516351\n",
            "RMSE is 129.53572632162206\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "RMSE = (((y_pred_lat[:,0]-y_test_lat)**2).mean())**.5\n",
        "print('R2 score is',r2_score(y_test_lat, y_pred_lat))\n",
        "print('RMSE is',RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "5TXzQWsSbEMx",
        "outputId": "1aba2e6c-3659-432b-b57c-04cb619e9a1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(lat_history.history['loss'])\n",
        "plt.plot(lat_history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljt3nWfWbjcq",
        "outputId": "0057c45f-cf59-43b4-aaad-c230ada8ef7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2421.5093]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "nu_model_lat.predict([[3,13,1,0,0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-TgKxGGtPz"
      },
      "source": [
        "## Extra Tree Regressor for Latency\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqF1P4Vo3p8f",
        "outputId": "dfa2f062-4515-4349-b2ed-82a5e70a2739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for this model is 0.9984531017276932\n",
            "RMSE score for this model is 11.115394833647999\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "reg_lat = ExtraTreesRegressor(n_estimators=100, random_state=0, bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                    n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_lat, y_train_lat)\n",
        "\n",
        "R2_score = reg_lat.score(X_test_lat, y_test_lat)\n",
        "print(\"R2 score for this model is\", R2_score)\n",
        "\n",
        "y_pred_lat = reg_lat.predict(X_test_lat)\n",
        "MSE = ((y_pred_lat-y_test_lat)**2).mean()\n",
        "RMSE = (((y_pred_lat-y_test_lat)**2).mean())**.5\n",
        "print(\"RMSE score for this model is\", RMSE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "cNBawuMSuNT2"
      },
      "outputs": [],
      "source": [
        "y_pred_all = reg_lat.predict(x_lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Na3-KpWuTtg",
        "outputId": "4e13de0e-bd08-445b-af86-8d3d7ea50491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 3.514997234669781\n"
          ]
        }
      ],
      "source": [
        "# RMSE for all data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse_all = mean_squared_error(y_lat, y_pred_all)\n",
        "sk_rmse_all = sk_mse_all**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNId8zgaFKBZ",
        "outputId": "50801ce0-b4de-4809-cf66-6378c20806c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE score for this model is 11.115394833647997\n"
          ]
        }
      ],
      "source": [
        "# RMSE for validation data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "sk_mse = mean_squared_error(y_test_lat, y_pred_lat)\n",
        "sk_rmse = sk_mse**.5\n",
        "print(\"RMSE score for this model is\", sk_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "rGwAP5B-3qyb"
      },
      "outputs": [],
      "source": [
        "# y_pred_lat = reg.predict(X_test_lat)\n",
        "# y_pred_lat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "i_UPadyH3qF_"
      },
      "outputs": [],
      "source": [
        "# MSE = ((y_pred_lat-y_test_lat)**2).mean()\n",
        "# RMSE = (((y_pred_lat-y_test_lat)**2).mean())**.5\n",
        "# RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT6JoVKB5i-F",
        "outputId": "27029465-bee1-46e4-8332-e57bd5019ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -35.775925 using {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#define your own mse and set greater_is_better=False\n",
        "# mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
        "\n",
        "etr_lat = ExtraTreesRegressor(n_estimators=100,random_state=0, bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                    max_samples=None, min_impurity_decrease=0.0,\n",
        "                    min_impurity_split=None, min_samples_leaf=1,\n",
        "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                    n_jobs=-1, oob_score=False,\n",
        "                    verbose=0, warm_start=False).fit(X_train_lat, y_train_lat)\n",
        "\n",
        "                            \n",
        "param_grid = {\n",
        "    'n_estimators': [50,100],\n",
        "    # 'criterion': ['mse', 'mae'],\n",
        "    'max_depth': [50,60,80],\n",
        "    # 'oob_score': [True, False],\n",
        "    'max_features': ['auto','sqrt','log2'],    \n",
        "    # 'bootstrap': [True, False],\n",
        "    # 'warm_start': [True, False],\n",
        "}\n",
        "\n",
        "gcv = GridSearchCV(etr_lat,param_grid,scoring='neg_root_mean_squared_error',cv=20,n_jobs=-1).fit(x_lat,y_lat)\n",
        "#gcv = GridSearchCV(etr_lat,param_grid,scoring='r2',cv=20,n_jobs=-1).fit(x_lat,y_lat)\n",
        "\n",
        "# grid_result = gsc.fit(x_output, y_output)\n",
        "\n",
        "print(\"Best: %f using %s\" % (gcv.best_score_, gcv.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CXljZRBWovcf",
        "outputId": "199200ce-3e53-4396-bec2-9e8f25709f3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9b7873d-9bb3-4ca1-9c85-91f76f573f5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Block_period</th>\n",
              "      <th>Block_size</th>\n",
              "      <th>Intensity_High</th>\n",
              "      <th>Intensity_Low</th>\n",
              "      <th>Intensity_Medium</th>\n",
              "      <th>actual_latency</th>\n",
              "      <th>prdicted_latency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>71.048</td>\n",
              "      <td>72.730933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146.048</td>\n",
              "      <td>146.048000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>218.549</td>\n",
              "      <td>218.058799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>291.848</td>\n",
              "      <td>291.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>365.552</td>\n",
              "      <td>365.552000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9b7873d-9bb3-4ca1-9c85-91f76f573f5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9b7873d-9bb3-4ca1-9c85-91f76f573f5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9b7873d-9bb3-4ca1-9c85-91f76f573f5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Block_period  Block_size  ...  actual_latency  prdicted_latency\n",
              "0             1          13  ...          71.048         72.730933\n",
              "1             2          13  ...         146.048        146.048000\n",
              "2             3          13  ...         218.549        218.058799\n",
              "3             4          13  ...         291.848        291.848000\n",
              "4             5          13  ...         365.552        365.552000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "#combine x_test,y_test and y_pred on one table to be able to visualise it\n",
        "df_vis_lat = x_lat.copy()\n",
        "df_vis_lat['actual_latency'] = y_lat\n",
        "df_vis_lat['prdicted_latency'] = y_pred_all\n",
        "df_vis_lat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assess Performance of the ExtraTreeRegressor model for Latency\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "To5eBXAUbGRX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "zdfu9vxhEeGF",
        "outputId": "09b971bc-09c8-4eff-bdc4-b2488fe323d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Error: 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa3e7303b90>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFnCAYAAACoxECQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeViU9f7/8Sey6BfDFBVDwyU7am6Q2KLmUXEBzMQlzTyYaycTFVNzK8uO51imltqxLBcgy9OiqWTmnpZGlKCmtriUiooKCiKMAgPz++Ou+blgIsLcLK/HdXnl3HPPzHs+cs6b131/7s/tZLPZbIiIiEiZUc7sAkRERMSx1PxFRETKGDV/ERGRMkbNX0REpIxR8xcRESlj1PxFRETKGDV/kZto2LAhnTt3JigoiMDAQHr37k1MTMxtv+/bb7/NpEmTABg4cCAHDhz4y/0/+eSTW/6MXbt2ERAQUKD6biY1NZXWrVvz4osv5mv/rKwsVq9efVufOWDAANasWXPd9rfeeosXXnjhlt+vIGMqUhqo+Yvkw7Jly1i/fj0bNmxgypQphIeHc/78+UJ7/6ioKJo0aXLD53Nycnj99dcL7fMKw9q1axkwYAAxMTFkZmbedP+ffvrptpt/YUpKSmLx4sVmlyFiCjV/kVvk7+9P7dq12b17NydOnOCRRx5hxowZhIaGAhAXF0fv3r3p3Lkzffv2JSEhAYDLly8zZswYOnToQGhoKKdPn7a/Z0BAALt27QJg9erVBAYGEhgYyPPPP09WVhaDBw/m4sWLBAUFkZCQwOnTpxk+fLh9v+3bt9vf6+2336Zdu3b06NGDb7/9Ns/v8Pjjj7Nhwwb7482bN9O3b1+sVisvvPACgYGBdO7cmZEjR5Kenp7ne6xevZpu3brRpk0btmzZYt9us9l49dVXCQgIIDAwkMWLF5OcnMzIkSPZs2cP/fv358SJEzRu3Nj+misf5+bm8sorrxAYGEhAQADPP/882dnZt/RvdKUtW7bw2GOPERgYSK9evfj5558B6NevH6dOnSIoKIisrCwOHz5MaGgogYGBPPbYY+zbtw+A2NhYnnjiCebMmUNwcDABAQF8//33gPFvOmHCBAICAggODmbNmjUcOnSIBx98kKysLHsNo0ePJjIyssDfQaSwqfmLFIDVasXNzQ0wDn/fd999fPDBB6Snp/Pss88yduxYNm3axFNPPUV4eDgAK1euJDk5mU2bNvHWW2+xY8eO6973xIkTzJw5k/fff5/169dz6dIl3n//fWbMmIGzszPr16/Hx8eHiRMn0qhRIzZs2MB7773HhAkTSElJ4fDhw0RGRrJy5UpWrlzJr7/+mmf9gYGBbN261f5406ZNBAcHs2PHDk6cOMH69evZuHEj9957L7t3777u9YcOHcLV1RUfHx+6d+9+VaKPjo7mxx9/ZMOGDaxcuZIPPviAU6dOMXbsWPz8/Fi+fPlfju2mTZvYtWsXa9eu5csvv+TAgQOsW7fu5v8oebBarUyaNInp06ezYcMGAgICmDlzJgAzZszA29ub9evX4+LiQlhYGCEhIWzYsIFp06YxYsQIrFYrYBy18PX15csvv6R///688847ACxdupTs7Gy2bt1KREQE06dPp1KlStSoUYNvvvkGgMzMTHbs2EFwcHCBvoNIUVDzF7lF27dvJzk5mRYtWgCQnZ1N586dASP116hRgzZt2gDQrVs3jh8/zqlTp9i1axedO3fGxcWFKlWq0KFDh+vee+fOndx///3UqFEDJycn5syZw6BBg67ax2KxEBsba99ep04d/P392b59Oz/88AMPPPAA1apVw9nZme7du+f5HYKCgti+fTs5OTlYrVa2bdtGUFAQnp6eHDlyhE2bNnHp0iXGjBlD27Ztr3v9qlWr7O/t7+/P0aNHSU5OBuDrr78mMDAQV1dX7rjjDtatW0ezZs3yPb6BgYGsXLkSV1dXypcvT7NmzexHT26Vi4sL3377LX5+fgC0bNkyz/f67bffOHfuHI8//rj9O3l6etp/8alYsSKdOnUCoEmTJpw6dcr+XR999FEA7rrrLrZv306NGjXo1q0bX3zxBQA7duygcePG1KhRo0DfQaQouJhdgEhJMGDAAJydnbHZbNSqVYtFixZRsWJFUlJScHZ25o477gAgLS2NhIQEgoKC7K91c3Pj/PnzXLhwAQ8PD/v2SpUqkZGRcdXnpKSkUKlSJfvj8uXLX1fLxYsXsdls9OvXz77NYrHw8MMPY7FYrvuMvPj4+ODt7c3u3bvJzs6mXr16eHt74+3tzYsvvsiyZcuYOHEiAQEBvPzyy1e9T05ODp9//jkWi4U5c+YARrr9/PPPGTx48HXfwd3d/a8H9xrnz59n+vTp/PTTTzg5OZGcnMzAgQNv6T2utGzZMlatWkVWVhZZWVk4OTldt09aWhqXL1++Kp2np6eTmppKpUqVrhrTcuXKkZubCxj/Xlc+V7FiRQC6du3KwoULsVgsbN68Walfih01f5F8WLZsGXfddddN9/Py8uKee+7hs88+u+65SpUqcfHiRfvjvCYMVqlS5arD7Onp6Vy+fPmqfapWrYqzszMrV660N5s/LV++/KrPSElJuWGtgYGBbNmyhezs7KuaU1BQEEFBQaSmpjJlyhSWLFnCc889Z39+x44dNGjQgCVLlti3/fTTT0yePJnBgwdTpUqVqz43OTmZChUqXPXZzs7O5ObmYrPZcHJyIi0tzf7cm2++iYuLC59//jlubm6MGzfuht/hZuLj41m0aBGffvopd999Nzt37mTq1KnX7efl5UXFihVZv379dc/Fxsbe8P2v/a6nT5/mzjvvxMfHhwYNGrB582a2bdvG+PHjC/wdRIqCDvuLFCJfX1+SkpLYu3cvAAkJCTz//PPYbDb8/PzYunUrOTk5nD9/nq+//vq617dr1474+HhOnDiBzWbj5ZdfZsWKFbi6upKbm0t6ejouLi60a9eOjz76CIBLly4xefJkEhMTuf/++4mLi+P8+fPk5OQQHR19w1oDAwOJiYnhq6++sh+pWLlyJQsWLACgcuXK3HPPPde9btWqVfZD4H9q3LgxFy9e5NdffyUgIIAvvviCrKwsLBYL/fv35+DBg7i4uJCeno7NZqNKlSo4Ozvb5yRcOWfg3LlzNGjQADc3N3755Rd2796NxWK5lX8Gu/Pnz1O1alVq1qzJpUuXWLVqFRaLBZvNhouLCxaLBavVSq1atbjrrrvszf/8+fOMHTv2pp8bEBDA6tWrsdlsJCUl0aNHD/svA926dWPu3Lk0bNiQqlWrFqh+kaKi5i9SiCpUqMD8+fOZPn06wcHBhIWFERQUhJOTE3379sXDw4NOnToxatSo6xooGOeN//WvfzFw4EACAwMBGDx4MNWrV8ff358OHToQHx/PtGnT+OGHHwgKCqJnz572w/j33Xcf/fr1o2fPnvTq1cs+LyEv9erVIzc3lxo1atjPR3fs2JEDBw7QpUsXgoODOXz4MIMHD7a/Ji0tja+++oqOHTte934dO3Zk9erVdO3alUceeYQuXbrQs2dPHn/8cVq0aIG/vz9nz56lbdu2uLq6MmrUKIYNG0avXr2477777O8zZMgQPvroI4KDg/nwww+ZOHEin376KV9++eVfjv2GDRvsRy2CgoJ47rnnaNu2LV5eXnTq1IkhQ4YwcOBAPDw8GD16NA0bNuTOO++kTZs2JCYm8sYbb/Dhhx8SFBREaGgorVq1uukpi0GDBlG1alU6dOjAgAEDmDhxIjVr1gQgODiY06dP07Vr1798DxEzONlsNpvZRYiIlDZZWVkEBASwdu1aKleubHY5IldR8hcRKQKRkZG0a9dOjV+KJU34ExEpZEFBQVStWpW33nrL7FJE8lSkh/0PHjzIiBEjGDRoEKGhoSQmJjJ58mSsVisuLi7MmjWL6tWrEx0dTVRUFOXKlaNv37706dOH7OxsJk2axKlTp3B2dubVV1/Fx8enqEoVEREpM4rssL/FYmH69Om0atXKvm3u3Ln07duXDz74gM6dOxMREYHFYmHBggVERkaybNkyoqKiSE1NZe3atVSqVIn//e9/DB8+3H49sYiIiNyeIjvs7+bmxqJFi1i0aJF928svv2xftKRKlSocOHCAvXv30qxZM/tCGS1atCA+Pp6YmBh69OgBQOvWrZkyZcpffl5ubi4ZGRm4urrmuYiHiIhIaWKz2cjOzqZixYqUK3drWb7Imr+LiwsuLle//Z+XzeTk5LB8+XLCwsJITk7G09PTvo+npydJSUlXbS9XrhxOTk5kZWXZ11O/VkZGBgcPHiyibyMiIlI8NWjQ4KqVJvPD4bP9c3JymDBhAg8//PBVpwT+dKMpCDebmuDq6loo9YmIiBQbubl4fv45jXv3puljj+Hz2ms4X7hw1S4F6X8On+0/efJk6tSpw8iRIwFjWc0/bwgCcPbsWfz8/PDy8iIpKYlGjRqRnZ2NzWa7YeoH7If6mzZtmud66GVdXFwc/v7+ZpdR7Gmc8kfjlD8ap/zTWOXht99gyBDYvh2qVoW33yahfn37OGVmZrJ///4Cnep2aPKPjo7G1dWV0aNH27f5+vqyb98+0tLSyMjIID4+npYtW9KmTRv7UptfffUVDz30kCNLFRERMYfNBgsXQvPmRuPv0QMOHIC+fQvtI4os+e/fv5+ZM2dy8uRJXFxc2LBhA+fOnaN8+fIMGDAAgPr16zNt2jTGjRvH0KFDcXJyIiwsDA8PD7p27cq3337Lk08+iZubG6+99lpRlSoiIlI8HD8OQ4fC5s1QuTJ88AH07w+FPJG9yJp/06ZNWbZsWb72/XMt7iv9eW2/iIhIqWezwdKl8NxzcPEiPPoovPce/HGviMKm5X1FRETMdOIEdO0Kw4YZCT8iAj7/vMgaP2h5XxEREXPYbPD++xAeDhcuQGAgLFoEDljNVslfRETE0RITISQEBg2CnBzjEP+XXzqk8YOSv4iIiENYLBYST53i7m++ofy4cZCSAgEBxrn+OnUcWouav4iISBGyWq2MHz+eHZ99xpSEBOoDmS4uuMyfj3NYGNzi0ryFQYf9RUREitD48eM5OW8eXyYk0AvYDtxntTLuyBFTGj+o+YuIiBQZy/HjdFy0iE+BikA40AH4HVizZg0Wi8WUutT8RUREisLq1bi1aMFjFgs7AT9gPvDnnWoSEhJITEw0pTQ1fxERkcJ0/jyEhkLPnjinpzOjShX+Dhy6ZjcfHx+8vb3NqFDNX0REpNCsXQtNm8KHH8KDD+K0ezdnn3qK3Dx2DQkJsd/q3tE0219EROR2paYaS/NGRoKbG7z6KowfDy4uzJ49GzDO8SckJODj40NISIh9uxnU/EVERG7Hhg3G0rwnTkCLFhAVZaT/P7i4uDB37lxmzJhBYmIi3t7epiX+P+mwv4iISEGkpcE//wlBQXD6NPzrX/Ddd1c1/iu5u7tTv3590xs/KPmLiIjcui1bYMgQ4xa8zZsbad/Pz+yq8k3JX0REJL/S0yEsDDp1gpMnYepU+OGHEtX4QclfREQkf77+GgYPht9+g8aNjbTfsqXZVRWIkr+IiMhfsVhgzBho1w6OHoVJkyA+vsQ2flDyFxERubGdO420f+gQNGxopP2HHjK7qtum5C8iInKtS5eM6/TbtoXDh2HcONi9u1Q0flDyFxERuVpsLAwaBL/8Avfeayzc06aN2VUVKiV/ERERgMxMmDIFWrc2Gv/o0bBnT6lr/KDkLyIiAnFxMHAgHDgA9epBRIQxwa+UUvIXEZGyKysLXn7ZOJd/4AA8+yz8+GOpbvyg5C8iImXV3r1G2t+7F2rXhiVLjMV7ygAlfxERKVuys2H6dOM6/b17jZvy7NtXZho/KPmLiEhZsn+/MZM/Lg5q1YLFi40b85QxSv4iIlL6Wa3w2mvg7280/kGDjF8EymDjByV/EREp7X75xWj2sbFw113w3nvw2GNmV2UqJX8RESmdcnJgzhzjjnuxsfCPfxgz+st44wclfxERKY0OHTLW5N+5E6pXh3ffhZ49za6q2FDyFxGR0iM3F+bPB19fo/H36WOkfTX+qyj5i4hI6fDbbzBkCGzfDlWrGmvy9+1rdlXFkpK/iIiUbLm58M470Ly50fh79DDSvhr/DSn5i4hIyXXsGAwdClu2QJUqxkz+J58EJyezKyvWlPxFRKTksdmMBXqaNTMaf7duRtrv31+NPx/U/EVEpGQ5cQKCg+Hpp6FcOePcfnQ0eHubXVmJocP+IiJSMths8P77EB4OFy5AYKCR/u++2+zKShwlfxERKf4SE6F7d2OlvtxcWLQIvvxSjb+AlPxFRKT4stlg+XIYNQpSUqBjR+PWu3XqmF1ZiabkLyIixdOZM9C7N4SGQlYWvP02bNqkxl8IlPxFRKT4+eQTGDECzp2Ddu1g6VK45x6zqyo1ijT5Hzx4kE6dOvHBBx8AkJiYyIABA+jfvz/h4eFkZWUBEB0dTe/evenTpw+ffvopANnZ2YwbN44nn3yS0NBQEhISirJUEREpDpKT4YknjD8WC8ybB1u3qvEXsiJr/haLhenTp9OqVSv7tvnz59O/f3+WL19OnTp1WLFiBRaLhQULFhAZGcmyZcuIiooiNTWVtWvXUqlSJf73v/8xfPhw5syZU1SliohIcbBqFTRpYqT+1q1h714YPdq4nE8KVZGNqJubG4sWLcLLy8u+LTY2lo4dOwLQoUMHYmJi2Lt3L82aNcPDw4MKFSrQokUL4uPjiYmJoXPnzgC0bt2a+Pj4oipVRETMdP48dadOhV69jEv4Zs+Gr7+Gv/3N7MpKrSI75+/i4oKLy9Vvf+nSJdzc3ACoWrUqSUlJJCcn4+npad/H09Pzuu3lypXDycmJrKws++tFRKQUWLsWnn6aqqdPw4MPQlQUNGpkdlWlnmkT/mw2W6Fsv9b+/fsLXFNpFxcXZ3YJJYLGKX80Tvmjccqb88WL3D1nDtXWriXX1ZVTI0dyJjQUMjJAY/aXCuNnyqHN393dncuXL1OhQgXOnDmDl5cXXl5eJCcn2/c5e/Ysfn5+eHl5kZSURKNGjcjOzsZms+Ur9Tdt2pTy5csX5dcokeLi4vD39ze7jGJP45Q/Gqf80TjdwPr1MGwYnDwJ/v6Ui4zkTGamxiofrvyZyszMLHDgdegsitatW7NhwwYANm7cSNu2bfH19WXfvn2kpaWRkZFBfHw8LVu2pE2bNqxfvx6Ar776ioceesiRpYqISGFLSzPW4w8OhrNnYfp0iImBpk3NrqzMKbLkv3//fmbOnMnJkydxcXFhw4YNzJ49m0mTJvHxxx9Ts2ZNevTogaurK+PGjWPo0KE4OTkRFhaGh4cHXbt25dtvv+XJJ5/Ezc2N1157rahKFRGRorZlCwwZAsePg6+vcW7f19fsqsqsImv+TZs2ZdmyZddtj4iIuG5bUFAQQUFBV21zdnbm1VdfLaryRETEEdLTYcIEeOcdcHaGl16CF14ATd42lVb4ExGRorF9OwweDL//bly/HxUFOq9fLGjlBBERKVwWi3Hb3fbt4dgxmDzZmMGvxl9sKPmLiEjh2bnTuO3u4cPG9fqRkaAJ28WOkr+IiNy+S5dg/Hho2xaOHDH+Hh+vxl9MKfmLiMjtiY2FgQPh11+NJXkjIqBNG7Orkr+g5C8iIgWTmWmcz2/d2mj84eGwZ48afwmg5C8iIrcuLs5I+wcOQL16Rtpv187sqiSflPxFRCT/srKMa/Ufesho/CNGwI8/qvGXMEr+IiKSP3v2GGn/xx+hdm1YuhT+uE27lCxK/iIi8teys411+B94wGj8Tz8N+/ap8ZdgSv4iInJj+/cbaT8+HmrVgiVLIDDQ7KrkNin5i4jI9axWePVVY1W++Hhj4Z79+9X4SwklfxERudrPPxvN/vvvwdsb3nsPunUzuyopREr+IiJiyMmB2bPh/vuNxh8aaqR9Nf5SR8lfRETg0CEj7X/7LXh5wcKF0LOn2VVJEVHyFxEpy3JzYd488PU1Gv8TTxjX76vxl2pK/iIiZdVvv8HgwfD111C1KkRFQZ8+ZlclDqDkLyJS1uTmwttvQ/PmRuPv2dNI+2r8ZYaSv4hIWXLsGAwdClu2QJUqxkz+J58EJyezKxMHUvIXESkLbDZYtAiaNjUaf7duRtrv31+NvwxS8xcRKe0SEiA4GP75T3B2Ns7tR0cb1/BLmaTD/iIipZXNZjT68HBIS4OgICP933232ZWJyZT8RURKo1OnoHt3Yza/zQaLF8O6dWr8Aij5i4iULjYbLF8Oo0ZBSopx570lS6BOHbMrk2JEyV9EpLQ4cwZ69TKW5c3KgnfegU2b1PjlOkr+IiKlwccfQ1gYnDsH7drB0qVwzz1mVyXFlJK/iEhJlpQEfftCv35gscD8+bB1qxq//CUlfxGRkuqzz2D4cOMXgDZtIDIS7r3X7KqkBFDyFxEpac6dg3/8A3r3hosXYc4c2L5djV/yTclfRKQk+fxzY7Ge06fhoYeMtN+okdlVSQmj5C8iUhKkpsKgQca1++fPw2uvwY4davxSIEr+IiLF3ZdfwtNPw8mT4O9vrNrXpInZVUkJpuQvIlJcpaXBsGHQtSucPQvTp0NMjBq/3DYlfxGR4mjzZhgyxLgpj5+fcW7f19fsqqSUUPIXESlO0tPh2Wehc2dITISXX4bYWDV+KVRK/iIixcW2bcaNeI4ehaZNjXP7LVqYXZWUQkr+IiJmy8iA0aOhQwc4fhymTIFdu9T4pcgo+YuImGnHDiPtHz5sXLYXFQUPPmh2VVLKKfmLiJjh0iUYNw7+/nc4cgTGj4fdu9X4xSGU/EVEHO2774wFe379Ff72N2Mmf+vWZlclZYiSv4hIEbNYLBw5cgTL+fMwaZJxE56DB2HMGNizR41fHM6hyT8jI4OJEydy4cIFsrOzCQsLo3r16kybNg2Ahg0b8sorrwCwePFi1q9fj5OTEyNHjqRdu3aOLFVE5LZZrVbGjBnDmjVrqH7sGB+4uNAgOxvbPffgFBFhHPIXMYFDm/+qVauoV68e48aN48yZMwwcOJDq1aszZcoUmjdvzrhx49i+fTv33HMP69at46OPPiI9PZ3+/fvzyCOP4Ozs7MhyRURuy9y5c1n50UdMBSYDLtnZ/Bc4HhTE62r8YiKHHvavUqUKqampAKSlpVG5cmVOnjxJ8+bNAejQoQMxMTHExsbStm1b3Nzc8PT0pFatWhw+fNiRpYqI3BaLxULy5s38AEwFTgABwCjg03XrsFgsptYnZZtDm/+jjz7KqVOn6Ny5M6GhoUyYMIFKlSrZn69atSpJSUkkJyfj6elp3+7p6UlSUpIjSxURKbjsbC5PmcK65GR8gXeB5sBXfzydkJBAYmKiefVJmefQw/5r1qyhZs2aLFmyhF9++YWwsDA8PDzsz9tstjxfd6Ptedm/f/9t11laxcXFmV1CiaBxyh+NU94qHD5MvZdfxvPXXzlVrhyDcnPZdM0+NWrU4PTp0/YjoWLQz1T+FMY4ObT5x8fH88gjjwDQqFEjMjMzsVqt9ufPnDmDl5cXXl5e/P7779dtz4+mTZtSvnz5wi28FIiLi8Pf39/sMoo9jVP+aJzyYLXCrFnGWvzZ2TB4MFMvXGDTZ59dt2ufPn1o06aNCUUWX/qZyp8rxykzM7PAgdehh/3r1KnD3r17ATh58iQVK1akfv367Nq1C4CNGzfStm1bHn74YbZt20ZWVhZnzpzh7Nmz3HvvvY4sVUQk/37+2bhcb8oUqFYN1q6FpUv554QJhIeHU7duXZydnalbty7h4eHMnj3b7IqljHNo8n/iiSeYMmUKoaGhWK1Wpk2bRvXq1XnppZfIzc3F19eX1n9c79q3b19CQ0NxcnJi2rRplCunJQlEpJjJyYE33oCpUyEzE0JDYf58qFIFABcXF+bOncuMGTNITEzE29sbd3d3k4sWcXDzr1ixIvPmzbtu+/Lly6/bNmDAAAYMGOCIskREbt3Bg8YqfTEx4OUF774LPXrkuau7uzv169d3bH0if0FxWkTkVuTmwty54OtrNP5+/eDAgRs2fpHiSGv7i4jk15Ejxh34vvnGOLf//vvQp4/ZVYncMiV/EZGbyc2FBQugeXOj8ffqZaR9NX4poZT8RUT+ytGjMHQobN1qTORbvNg41O/kZHZlIgWm5C8ikhebDd57D5o1Mxr/Y48Zaf/JJ9X4pcRT8hcRuVZCAgwbBhs3wp13QlQUDBigpi+lhpK/iMifbDaIiICmTY3GHxxspP2nnlLjl1JFzV9EBODUKejWDYYMMX4JWLIEvvgCatUyuzKRQqfD/iJSttls8OGHMGoUpKZCp05G469d2+zKRIqMkr+IlF1nzkDPnsb5/OxsWLjQONyvxi+lnJK/iJQ9Nht88gmEhcG5c9C+PSxdCvXqmV2ZiEMo+YtI2ZKUBH37GtfqX7oEb70FW7ao8UuZouQvImXHypXw7LPGLwBt2kBkJOh24VIGKfmLSOl37hz07w+PPw4XLxq34d2+XY1fyiwlfxEp3aKj4Z//NCb3PfywkfYbNjS7KhFTKfmLSOmUkgIDB0JIiPH3mTNhxw41fhGU/EWkNPryS2N53lOnoGVLY3nexo3Nrkqk2FDyF5HS48IFo+l37WpM6vv3vyEmRo1f5BpK/iJSOmzaZNx6NyEB/PyMtN+8udlViRRLSv4iUrJdvAjDh0OXLpCYCC+/DN9/r8Yv8heU/EWk5PrqK+NGPEePGnfii4qCFi3Mrkqk2FPyF5GSJyPDuBFPQAAcPw5TpsCuXWr8Ivmk5C8iJcuOHTBoEBw5AvfdZ6T9Bx4wuyqREkXJX0RKhkuXYOxY+Pvf4fffYcIEiI9X4xcpACV/ESn+vvvOWLDn4EH429+MtN+qldlViZRYSv4iUnxdvgwTJxo34Tl0CMaMgT171PhFbpOSv4gUTz/8YJzb/+kncuvVI/E//6FKSAju7u5mVyZS4in5i0jxkpkJL75opPuffuJrX1+a5uRQOzSUJk2aMGbMGKxWq9lVipRoSv4iUnzs3m2c29+3D+rW5b8tWjDqs8/sTx89epR58+YBMHfuXLOqFCnxlPxFxHzZ2fDKK6CMx5gAACAASURBVPDgg0bjf+YZLN99x+y4uDx3X7NmDRaLxcFFipQeav4iYq59++Chh2DaNLjrLtiwARYuJDE9nYSEhDxfkpCQQGJiomPrFClF1PxFxBxWK8yYAf7+xuH+IUNg/35jjX7A29ub2rVr5/lSHx8fvL29HVmtSKmi5i8ijvfTT8aEvhdegOrV4YsvYMkSuPNO+y7u7u6EhITk+fIQzfoXuS2a8CcijpOTA2+8AVOnGrP6BwyAefOgSpU8d589ezZgnONPSEjAx8eHkJAQ+3YRKRg1fxFxjF9/hcGDISYGatSAd9+FGyT7P7m4uDB37lxmzJhBYmIi3t7eSvwiheCmh/1PnjzJ6NGjGTBgAACffPIJR48eLeq6RKS0yM2FN98EPz+j8ffrBwcO3LTxX8nd3Z369eur8YsUkps2/6lTpxISEoLNZgOgXr16TJ06tcgLE5FS4PBhaN/euCHPHXfAp5/C//4HVauaXZlImXbT5p+dnU3Hjh1xcnIC4AHdQUtEbiY3F/77X/D1hW++gd69jbT/+ONmVyYi5POcf1pamr35Hzp0iMzMzCItSkRKsKNHjcv2vvoKPD2NWfxPPAF//H+IiJjvps0/LCyMvn37kpSUxGOPPUZKSgqzZs1yRG0iUpLYbPDeezB+PKSnQ/fuxqS+u+4yuzIRucZNm//DDz/M6tWrOXjwIG5ubtSrV4/y5cs7ojYRKSkSEmDoUNi0CSpXhvffh9BQpX2RYuqmzf/Pm2hcKzw8vEAfGB0dzeLFi3FxcWH06NE0bNiQCRMmkJOTQ/Xq1Zk1axZubm5ER0cTFRVFuXLl6Nu3L3369CnQ54lIEbLZICICnnsO0tIgOBgWLYJatcyuTET+wk0n/Dk7O9v/5ObmEhsby8WLFwv0YSkpKSxYsIDly5ezcOFCtmzZwvz58+nfvz/Lly+nTp06rFixAovFwoIFC4iMjGTZsmVERUWRmppaoM8UkSJy8iR062YkfjDO7X/xhRq/SAlw0+Q/cuTIqx7n5OQwatSoAn1YTEwMrVq14o477uCOO+5g+vTpBAQE8MorrwDQoUMHli5dSr169WjWrBkeHh4AtGjRgvj4eAICAgr0uSJSiGw2PL/4wrh2PzUVOneGxYvhBuvwi0jxc8sr/FmtVo4fP16gDztx4gSXL19m+PDhpKWlMWrUKC5duoSbmxsAVatWJSkpieTkZDw9Pe2v8/T0JCkpqUCfKSKF6PRpeOYZ6kVHG9ftv/suPP20zu2LlDA3bf7t2rWzX+YHcOHCBXr27FngD0xNTeW///0vp06d4qmnnrIvHgRc9fcr3Wh7Xvbv31/g2kq7uBvcG12upnHKg81GlY0bqf3667hcuEBay5Yce+klsmrWhPh4s6sr1vTzlH8aq/wpjHG6afNfvny5/e9OTk7ccccdVKpUqUAfVrVqVe6//35cXFyoXbs2FStWxNnZmcuXL1OhQgXOnDmDl5cXXl5eJCcn21939uxZ/Pz88vUZTZs21dUIeYiLi8Pf39/sMoo9jVMekpLg2Wdh5Upwd4e33uLQQw/hrwW/bko/T/mnscqfK8cpMzOzwIH3phP+Zs2aRa1atahVqxY1a9YscOMHeOSRR/juu+/Izc0lJSUFi8VC69at2bBhAwAbN26kbdu2+Pr6sm/fPtLS0sjIyCA+Pp6WLVsW+HNFpIBWroQmTYz/PvII7N0LI0dCOd0NXKQku2nyv/vuu1mxYgX333+//dw8gI+Pzy1/WI0aNQgMDKRv374AvPjiizRr1oyJEyfy8ccfU7NmTXr06IGrqyvjxo1j6NChODk5ERYWZp/8JyIOcO6c0eQ/+ggqVDAm940eraYvUkrcsPlHR0fTvXt31q1bd91zTk5ObNmypUAf2K9fP/r163fVtoiIiOv2CwoKIigoqECfISK3Yc0aeOYZOHMGHn4YIiOhYUOzqxKRQnTD5r9ixQq6d+/O1q1bHVmPiJglJQXCw2HZMihfHl5/3bgbn7Oz2ZWJSCG75Uv9RKQUWrfOuGTv1Cl44AEj7TdubHZVIlJEbtj8d+/eTfv27a/bbrPZcHJyYtu2bUVYlog4xIULRrpfuhRcXeE//4EJE8BFuUCkNLvh/8IbN27MG2+84chaRMSRNm40luY9cQLuvx+ioqBZM7OrEhEHuGHzd3Nzo5bW6BYpfS5ehOefN1bnc3GBadNgyhQj+YtImXDD5t+8eXNH1iEijrB1KwwZAseOGSk/KspI/SJSptzwot3nn3/ekXWISFHKyDCu2+/Y0TjM/8ILsGuXGr9IGaVZPSKl3TffwKBB8NtvcN99RtrX0rwiZZqW6xIprSwWeO45aNcOjh41ZvHHx6vxi4iSv0ipFBNjpP2DB6FBA+O6/VatzK5KRIoJJX+R0uTyZSPhP/IIHDpkXMO/Z48av4hcRclfpLT44QcYOBB+/hnq14eICGjb1uyqRKQYUvIXKekyM43Z+61aGY1/5Ejj1rtq/CJyA0r+IiVZfLxxbn/fPqhb11imt0MHs6sSkWJOyV+kJMrKMlbme+gho/EPHw4//qjGLyL5ouQvUtL8+KNxbn/PHvDxgSVLoHNns6sSkRJEyV+kpLBajbvutWxpNP6hQ43Ur8YvIrdIyV+kJPjpJyPt79oFNWvC4sUQHGx2VSJSQin5ixRnOTnw+uvGGvy7dsFTT8H+/Wr8InJblPxFiqtffzVm8n/3HdSoAe+9B927m12ViJQCSv4ixU1ODrz5Jvj5GY3/ySfhwAE1fhEpNEr+IsXJ4cMweDDs2AHVq8MHH0Dv3mZXJSKljJK/SHGQmwtvvQXNmxuN//HHjbSvxi8iRUDNX+QWWSwWjhw5gsViKZw3/P136NgRRo+G//s/+Ogj+OQTI/mLiBQBNX+RfLJarYwZM4YmTZrQoEEDmjRpwpgxY7BarQV7Q5sNFi6EZs1g2zYICTHS/hNPgJNTodYuInIlnfMXyafx48czb948++OjR4/aH8+dO/fW3uz4cWORns2boXJlWLYM/vEPNX0RcQglf5F8sFgsrF69Os/n1qxZk/9TADabsRxv06ZG4+/a1Uj7oaFq/CLiMGr+IvmQmJhIQkJCns8lJCSQmJh48zc5eRIefRSGDTMa/dKlsHatsWKfiIgDqfmL5IO3tze1a9fO8zkfHx+8vb1v/GKbDd5/H5o0gS+/hC5djFX6Bg9W2hcRU6j5i+SDu7s7ISEheT4XEhKCu7t73i88fRp69DDW5c/JgXffhfXrjbvxiYiYRBP+RPJp9uzZgHGOPyEhAR8fH0JCQuzbr2KzGZfsjRwJ589Dhw7GYf66dR1btIhIHtT8RfLJxcWFuXPnMmPGDBITE/H29s478Z89C88+C599Bu7usGABDB8O5XSgTUSKBzV/kVvk7u5O/fr1835yxQqj8ScnQ9u2EBEBN9pXRMQkiiIiheHcOejXD/r0gfR048Y827ap8YtIsaTkL3K71qyBZ56BM2egVSuIjIQGDcyuSkTkhpT8RQoqJQUGDDBm86emwqxZ8M03avwiUuwp+YsUxBdfwNNPQ2IiPPCAkfYbNza7KhGRfFHyF7kVFy7AkCHQrZsxqW/GDPj2WzV+ESlRlPxF8mvjRuNmPCdOwP33Q1SUcUc+EZESRslf5GYuXjQm9AUGGiv2vfIKxMaq8YtIiaXkL/JXtm41DvMfOwbNmxtp38/P7KpERG6LKcn/8uXLdOrUic8++4zExEQGDBhA//79CQ8PJysrC4Do6Gh69+5Nnz59+PTTT80oU8qy9HRjad6OHY3D/C++CD/8oMYvIqWCKc3/nXfe4c477wRg/vz59O/fn+XLl1OnTh1WrFiBxWJhwYIFREZGsmzZMqKiokhNTTWjVCmLvv4afH2NZXkbN4bvvoPp08HNzezKREQKhcOb/5EjRzh8+DDt27cHIDY2lo4dOwLQoUMHYmJi2Lt3L82aNcPDw4MKFSrQokUL4uPjHV2qlDUWC3fPmQPt28PRozBxIsTFQcuWZlcmIlKoHN78Z86cyaRJk+yPL126hNsfiapq1aokJSWRnJyMp6enfR9PT0+SkpIcXaqUJd9+C35+1Pjf/4xFenbuhNdegwoVzK5MRKTQOXTC3+rVq/Hz88PnBvcyt9lst7Q9L/v37y9QbWVBXFyc2SUUO06ZmdRcuJAaH3wAwNl//IOTzz6LzdXVSP1yQ/p5yh+NU/5prPKnMMbJoc1/27ZtJCQksG3bNk6fPo2bmxvu7u5cvnyZChUqcObMGby8vPDy8iI5Odn+urNnz+KXz4lWTZs2pXz58kX1FUqsuLg4/P39zS6jePn+e+O6/V9+MW7AExnJif/7P41TPujnKX80TvmnscqfK8cpMzOzwIHXoYf9586dy8qVK/nkk0/o06cPI0aMoHXr1mzYsAGAjRs30rZtW3x9fdm3bx9paWlkZGQQHx9PS513lcKSmQlTphg34fnlFxg9GvbuhUceMbsyERGHMP06/1GjRjFx4kQ+/vhjatasSY8ePXB1dWXcuHEMHToUJycnwsLC8PDwMLtUKQ3i42HgQNi/H+rWhYgIY4KfiEgZYlrzHzVqlP3vERER1z0fFBREUFCQI0uS0iwrC/7zH+NPTg4MH27che+OO8yuTETE4UxP/iJFbu9eGDQI9uwBHx9YsgQ6dza7KhER02htfym9srPh3/82brm7Zw8MG2Yc7lfjF5EyTslfSqcDB4xz+3FxULMmLF4MwcFmVyUiUiwo+UvpYrXCzJnQooXR+P+c3KfGLyJip+QvpcevvxrNPjYW7roL3n0Xunc3uyoRkWJHyV9KvpwceOMN4457sbHQv7+R9tX4RUTypOQvJZbFYiE5JoZaU6fiHBMD1avDhx9Cr15mlyYiUqyp+UuJY7VaeX7cOO784AMmnD+PM7Dn3ntp+vXXuHh7m12eiEixp8P+UuK8+vTThMyfz7Tz57EAfYH7Dx9m/MyZZpcmIlIiqPlLyWGzkTV/PmOjomgPrAKaAJ/+8fSaNWuwWCymlSciUlKo+UvJcOwYdOmCW3g4mTYb/wB6AWev2CUhIYHExESTChQRKTnU/KV4s9mMBXqaNYPNm8kJCiL47rtZnseuPj4+eOucv4jITan5S7FgsVg4cuSI/bC9xWLh6I4d5AQGwtNPg5MTRETgvG4drXr3zvM9QkJCcHd3d2TZIiIlkmb7i6msVivjx49nzZo1HD9+HB8fH6pUrkzAiRNMPXcOZ+DnOnX421df4VKvHgCzZ88GjHP8CQkJ+Pj4EBISYt8uIiJ/TclfTDV+/HjmzZvH0aNHyc3NJfPYMV7Zu5c5fzT+p4HGx44xft48+2tcXFyYO3cuBw4c4Ndff+XAgQPMnTsXFxf9Lisikh9q/mIai8XC6tWr7Y+fBA4A3YEtQFNg8R/P5TWT393dnfr16+tQv4jILVLzF4e68tx+YmIiCQkJVAdWAMuB8sAIoDNw/IrXaSa/iEjh0XFScYhrz+3Xrl2brl278oynJ68kJ1Md2A4MBn7P4/WayS8iUnjU/MUh/jy3/6eLR4/S9u236QdYgNHAfwHbDV6vmfwiIoVHzV+K3LXn9kOAd4EawK7y5fmid28+//ZbyiUkcPfdd1OlShVSUlI4ceKEZvKLiBQBNX8pcn+e268CzAdCgcvAeGB+djY//+tfPO/tTWJiIt7e3ri7u9vnBPz5WERECo+avxQ5b29vBlWrxvSzZ6kJxAKDgF+AurVr2xt8/fr17a+59rGIiBQezfaXopWaintYGEvOnqUqMAlog9H4QefyRUTMoOQvRWfDBhg2DE6cwHb//bzZuDEf79wJCQnU1bl8ERHTqPlL4UtLg/HjYdEicHGBf/0Lp0mTmOTqymidyxcRMZ2avxSuLVtgyBA4fhyaN4eoKPDzsz+tc/kiIubTOX8pHOnpEBYGnTrByZMwdSr88MNVjV9ERIoHJX+5fdu3w+DB8Pvv0KSJkfb9/c2uSkREbkDJXwrOYoExY6B9ezh2DCZNgrg4NX4RkWJOyV8KZudOI+0fOgQNGxpp/6GHzK5KRETyQclfbs2lS8ZM/rZt4fBhGDcOdu9W4xcRKUGU/CX/YmNh0CD45Re4916IjIQ2bcyuSkREbpGSv9xcZiZMngytWxuNf/Ro2LNHjV9EpIRS8pe/FhcHAwfCgQNQrx5EREC7dmZXJSIit0HJX/KWlQUvvWScyz9wAEaMgB9/VOMXESkFlPzlenv3Gml/716oXRuWLDEW7xERkVJByb8Ms1gsHDlyBIvFYmzIzobp06FlS6PxDxsG+/ap8YuIlDJK/mWQ1Wpl/PjxrFmzhuPHj1O7dm2eadOGiT//jFN8PNSqBYsXQ1CQ2aWKiEgRUPMvg8aPH8+8efMAcAaeOHqU544exQmMS/nefBMqVzaxQhERKUo67F/GWCwWVq9eDUBDYAfwGnAeGOblhWXBAjV+EZFSTs2/jElMTOTk8eOMBfYADwMfAE2AyHPnSExMNLU+EREpeg4/7P/6668TFxeH1WrlmWeeoVmzZkyYMIGcnByqV6/OrFmzcHNzIzo6mqioKMqVK0ffvn3p06ePo0stlWpmZPCtmxsPZGZyFngSWP3Hc3V9fPD29jaxOhERcQSHNv/vvvuOQ4cO8fHHH5OSkkLPnj1p1aoV/fv3Jzg4mDfeeIMVK1bQo0cPFixYwIoVK3B1deXxxx+nc+fOVNbh6ILLzYX58/m/SZN4IDOTj4GRQPIVu4SEhODu7m5SgSIi4igOPez/wAMP2CeaVapUiUuXLhEbG0vHjh0B6NChAzExMezdu5dmzZrh4eFBhQoVaNGiBfHx8Y4stUS77hK+336jwfDhEB4O7u7kLF9OTHg4d9Sti7OzM3Xr1iU8PJzZs2ebW7iIiDiEQ5O/s7OzPVmuWLGCv//97+zYsQM3NzcAqlatSlJSEsnJyXh6etpf5+npSVJSkiNLLZGuvYSvjo8PM++5h8e//x6PjAzo0QMWLsS5Rg3mPvkkM2bMIDExEW9vbyV+EZEyxJRL/TZv3syKFStYunQpXbp0sW+32Wx57n+j7XnZv3//bddXUs2ePZuPPvoIgNrAe8eO0enYMdLd3Dj773+TEhgIJ04Yf66QmppqQrXFV1xcnNkllAgap/zROOWfxip/CmOcHN78v/nmGxYuXMjixYvx8PDA3d2dy5cvU6FCBc6cOYOXlxdeXl4kJ///s9Fnz57Fz88vX+/ftGlTypcvX1TlFzsWi4XExETuvPNOYmJiABgKvAFUAj4Hpnt58Wb79rRp2dLESkuGuLg4/P39zS6j2NM45Y/GKf80Vvlz5ThlZmYWOPA69Jz/xYsXef3113n33Xftk/dat27Nhg0bANi4cSNt27bF19eXffv2kZaWRkZGBvHx8bRU47qK1WplzJgxNGnShAYNGuDn54f12DG+BBYDucBAoDsQn5h41S9TIiJStjk0+a9bt46UlBTGjBlj3/baa6/x4osv8vHHH1OzZk169OiBq6sr48aNY+jQoTg5OREWFoaHh4cjSy3WLBYLYWFhREZG2rd1OnmSuUBlYD0wDDj5x3M+Pj5Uq1bN4XWKiEjx5NDm/8QTT/DEE09ctz0iIuK6bUFBQQRpbfmr/Dmhb9WqVRw/fhyAu4D3gMeANIymv+Sa14WEhFChQgWH1ioiIsWX1vYvQa5ckx+gP/AW4AlsxjjXn+DkRK2aNTl9+jQ+Pj6EhIQwe/Zs9u7da07RIiJS7Kj5lxBXrsnvBbwD9ALSgWeBhX/sV7dOHX744QcuXLigS/hERCRPav4lRGJiIgkJCfQB3gaqAduAIcDvV+wXEhJCtWrVdI5fRERuSM2/hPB2dWVNhQp0s1iwAKOB/wJ/roBQp04devTooVX6RETkptT8S4JVq3AfPpxuFgs7gUHA4SueHjhwIG+//bYO8YuISL6o+Rdn58/D6NHw4YdQvjw5r7/OioQErJ9/jnNCwlUT+lxc9E8pIiL5o45RXK1dC08/DadPw4MPQlQUzo0a8Sbwn9de05r8IiJSYA5d4U/yITUVBg2Cxx4zkv+rr8LOndCokX0Xd3d36tevr8YvIiIFouRfnKxfD8OGwcmT4O8PkZHQtKnZVYmISCmj5F8cpKUZh/iDg+HsWZg+HWJi1PhFRKRIKPmbbcsWGDIEjh8HX1+IijL+KyIiUkSU/M2Sng4jRkCnTsZh/pdegu+/V+MXEZEip+Rvhu3bYfBg+P13aNLESPu6j7WIiDiIkr8jZWRAeDi0bw/HjsHkyRAXp8YvIiIOpeTvKDt3GpfwHT5sXLYXFWVcvy8iIuJgSv6FLDk5ma1bt5KcnAyA5dw5UocNw9a2LRw5AuPHQ3y8Gr+IiJhGyb+QXL58mVatWrFv3z5ycnJwdnam4x13sCAjg3utVn53cSG6Z0/CXn1VS/GKiIiplPwLSatWrdizZw85OTm4AdNzclh34QL3Wq3MBZpYrYz59FPGjx9vdqkiIlLGqfkXguTkZPbt2weAPxAHTAaOAe2A54BLf+y7Zs0aLBaLGWWKiIgAav6F4scff6RcTg7/Ar4DmgILgObA19fsm5CQQGJioqNLFBERsdPJ50Jwv5MTPwC+GGl/CLD1Bvv6+Pjg7e3tsNpERESupeR/O7KzYfp0qnTpgi/wLtCMGzd+gJCQEN2NT0RETKXmX1D798PDDxvL8taoQVZ0NAv9/LA4OwPg7OxMtWrVqF27Ns7OztStW5fw8HBmz55tcuEiIlLW6bB/PlgsFhITE/H29sbdzQ1mzYJp0yAry1i45803catcmd2PPUZycjI//vgjzZs3p1q1ale/VolfRESKATX/G7BYLBw8eJDZs2fzzTffcOLECTrcdRdLcnKoc+YMeHvDe+9Bt25Xva5atWoEBATYH7u7u1O/fn1Hly8iInJDav7XsFqtjB07loiICNLT0wHj3MhzwL9PnaIC8EOjRjywcyd4eppZqoiISIGo+V9j7NixvPXWW/bHfwMigDbAGeBJYM/lyxyoUAEdxBcRkZJIE/6uYLFYiIiIAMAJGA3swWj8HwFNgNXoWn0RESnZlPyv8Ntvv5Genk49jLTfDkgGBgIrrthP1+qLiEhJpuR/pdxcngV+xGj8n2Gk/RXX7KZr9UVEpCRT8v/T0aPcN3o0bwPnMc7tf3TNLh4eHgwZMkTX6ouISImm5m+zweLFMHYszunp7K9bl85Hj3L6mt0aNWpEbGwslSpVMqVMERGRwlK2D/snJEBwMPzzn+DsDFFRNDp4kCfCw6lduzZOTk54e3szYsQI9u3bp8YvIiKlQtlM/jYbREVBeDikpUFQECxaBHffjQswd+5cZsyYoZX5RESkVCp7zf/UKSPpf/EFeHgYh/yHDAEnp6t208p8IiJSWpWd5m+zwYcfwqhRkJoKHTvCkiVQp47ZlYmIiDhU2Tjnf+YM9OoFAwYYt+F95x3YtEmNX0REyqTSn/w//hjCwuDcOWjfHpYuhXr1zK5KRETENKU3+SclQd++0K8fWCwwfz5s2aLGLyIiZV7pTP6ffQbDhxu/ALRpA5GRcO+9ZlclIiJSLJS+5D9mDPTuDRcvwpw5sH27Gr+IiMgVSl/yX7MGHnrISPuNGpldjYiISLFTapq/zWYDIOull+Cpp4wV+zIzTa6qeMnUeOSLxil/NE75o3HKP41V/vw5TllZWcD/73+3wslWkFcVQxcvXuTgwYNmlyEiIuJQDRo0wMPD45ZeU2qaf25uLhkZGbi6uuJ0zWp9IiIipY3NZiM7O5uKFStSrtytTeErNc1fRERE8qf0zfYXERGRv6TmLyIiUsao+YuIiJQxav4iIiJlTKm5zl/g9ddfJy4uDqvVyjPPPEOzZs2YMGECOTk5VK9enVmzZuHm5kZ0dDRRUVGUK1eOvn370qdPH7NLd7jLly/TrVs3RowYQatWrTROeYiOjmbx4sW4uLgwevRoGjZsqHG6RkZGBhMnTuTChQtkZ2cTFhZG9erVmTZtGgANGzbklVdeAWDx4sWsX78eJycnRo4cSbt27Uys3HEOHjzIiBEjGDRoEKGhoSQmJub75yg7O5tJkyZx6tQpnJ2defXVV/Hx8TH7KxWZvMZq8uTJWK1WXFxcmDVrFtWrVy+csbJJqRATE2MbNmyYzWaz2c6fP29r166dbdKkSbZ169bZbDabbc6cObYPP/zQlpGRYevSpYstLS3NdunSJdujjz5qS0lJMbN0U7zxxhu2Xr162VauXKlxysP58+dtXbp0sV28eNF25swZ24svvqhxysOyZctss2fPttlsNtvp06dtgYGBttDQUNvevXttNpvNNnbsWNu2bdtsx48ft/Xs2dOWmZlpO3funC0wMNBmtVrNLN0hMjIybKGhobYXX3zRtmzZMtv/a+/uY2p+/ziOPw+nI0XqNCc6bpcNm5CbKWJk+a4Z/1gYZW62SCa3oczNMDKbm4S0mOWmSKOWjjC2/jja7KD8Ye7GVJZTtENFOn2+fzTHN06/7ze/crY+78d/5/qcc+36vHbVe+f6nF2Xoijtmke5ubnKrl27FEVRlOLiYiU+Pt5l99LZnGWVkJCgFBQUKIqiKOfPn1eSk5M7LCtZ9u8iJk6cyNGjRwHw8vKioaGBkpISZs6cCcCMGTMwm808fvyYwMBAevfujbu7O+PGjcNisbhy6H/cy5cvefHiBdOnTweQnJwwm82EhITQq1cvDAYDe/bskZyc8PHxoba2FgCbzYa3tzcVFRWMHj0a+JFTSUkJU6dORafTodfrMRqNvHjxwpVD/yN0Oh3p6ekYDAZHW3vmkdlsJjw8HIDJkyd36bnlLKudO3fy119/AT/mWkdlJcW/i+jevTseHh4A5OTkMG3aNBoaGtDpdAD4+vpitVqprq5Gr9c7PqfX67FarS4Zs6skJyezdetWx2vJ6Vfl5eV8+fKFVatWsWjRIsxm9QzGIgAABmFJREFUs+TkxOzZs6msrCQ8PJyoqCgSEhLw8vJyXFd7TlqtFnd391Zt7ZlH/2zv1q0bGo3GsaVtV+MsKw8PD7p3747dbufixYvMmTOnw7KSZ/5dzO3bt8nJyeHMmTPMmjXL0a60sZdTW+1d1bVr1xg7dmybz8Ikpx9qa2s5fvw4lZWVLFmypFUGklOL69ev4+/vT0ZGBk+fPiUuLq7VNquS0//W3nzUmJvdbichIYHg4GBCQkLIz89vdf13s5Jv/l1IcXExp06dIj09nd69e+Ph4cGXL18AqKqqwmAwYDAYqK6udnzm/fv3rZaZurp79+5x584d5s+fz5UrVzhx4oTk5ISvry9BQUFotVoGDRqEp6cnnp6ektNPLBYLoaGhAIwYMYKvX7/y8eNHx/W2cvrerkbt+XszGAyOFZJv376hKIpj1UAttm3bxuDBg1mzZg1Ah2Ulxb+L+PTpEwcPHiQtLQ1vb2+g5bnPzZs3ASgqKmLq1KmMGTOGsrIybDYbdXV1WCwWJkyY4Mqh/1FHjhzh6tWrXL58mcjISFavXi05OREaGsr9+/dpbm7m48eP1NfXS05ODB48mMePHwNQUVGBp6cnAQEBPHjwAPiRU3BwMPfu3aOxsZGqqirev3/PsGHDXDl0l2nPPJoyZQomkwmAu3fvMmnSJFcO/Y/Ly8vDzc2NtWvXOto6KivZ27+LyM7OJiUlhaFDhzraDhw4wPbt2/n69Sv+/v7s378fNzc3TCYTGRkZaDQaoqKimDt3rgtH7jopKSkYjUZCQ0PZsmWL5PSTrKwscnJyAIiNjSUwMFBy+kldXR2JiYnU1NTQ1NREfHw8ffv2ZceOHTQ3NzNmzBi2bdsGQGZmJvn5+Wg0GtatW0dISIiLR9/5njx5QnJyMhUVFWi1Wvz8/Dh06BBbt279T/PIbrezfft2Xr9+jU6n48CBA/Tv39/Vt9UpnGVVU1NDjx496NWrFwABAQHs2rWrQ7KS4i+EEEKojCz7CyGEECojxV8IIYRQGSn+QgghhMpI8RdCCCFURoq/EEIIoTJS/IVQifLyckaNGkV0dDTR0dEsXLiQjRs3YrPZfqu/K1euOLZJXr9+PVVVVW2+12Kx8Pbt2//cd1NTE8OHD/+tcQkh/p0UfyFURK/Xk5mZSWZmJllZWRgMBk6ePPl/93v48GH8/PzavJ6bm9uu4i+E6Fyyt78QKjZx4kSys7MJCwsjIiKCt2/fcuzYMW7cuMH58+dRFAW9Xs/evXvx8fHhwoULXLp0iX79+rXanjYsLIyzZ88ycOBA9u7dy5MnTwBYtmwZWq0Wk8lEaWmpY6vS3bt309DQQH19PRs2bGDy5Mm8evWKzZs307NnT9Xt5CbEnybFXwiVstvt3Lp1i/Hjx/P8+XOGDBnC5s2beffuHadOnSInJwedTse5c+dIS0sjLi6OY8eOYTKZ8PHxITY2lj59+rTqMy8vj+rqai5fvozNZmPTpk2cPHmSkSNHEhsbS0hICDExMSxfvpzg4GCsVisLFiygqKiI1NRU5s2bx6JFiygqKnJRKkKogxR/IVTkw4cPREdHA9Dc3MyECRNYunQpWVlZBAUFAfDw4UOsVisrVqwAoLGxkQEDBvDmzRuMRiM+Pj4ATJo0iadPn7bqv7S01PGt3cvLi9OnT/8yhpKSEurq6khNTQVajjKtqanh2bNnxMTEABAcHNwJdy+E+E6KvxAq8v2ZvzNubm4A6HQ6Ro8eTVpaWqvrZWVlaDQax+vm5uZf+tBoNE7b/0mn05GSktLqTHJoOYK0W7eWnyHZ7fZ/vxkhxG+TH/wJIVoJDAyktLTUcTxoYWEht2/fZtCgQZSXl2Oz2VAUBbPZ/Mtng4KCKC4uBuDz589ERkbS2NiIRqPh27dvAIwfP57CwkKgZSVi3759QMuhJY8ePQJw2rcQouPIN38hRCt+fn4kJSWxcuVKevbsibu7O8nJyfTp04dVq1axePFijEYjRqPRcS77dxEREVgsFhYuXIjdbmfZsmXodDqmTJnCzp07SUxMJCkpiR07dlBQUEBjYyOxsbEAxMXFsWXLFkwmE0FBQWi18u9JiM4ip/oJIYQQKiPL/kIIIYTKSPEXQgghVEaKvxBCCKEyUvyFEEIIlZHiL4QQQqiMFH8hhBBCZaT4CyGEECojxV8IIYRQmb8Bwf0ZJBCppPsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = [20, 10])\n",
        "base_color = sns.color_palette()[0]\n",
        " \n",
        "# plt.subplot(1, 2, 1)\n",
        "# # plot Block_period VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_period', y='actual_latency', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_period', y='prdicted_latency', color='red')\n",
        "# plt.title('Block period vs actual and prdicted latency')\n",
        "# plt.ylabel('Latency')\n",
        "# plt.xlabel('Block_period')\n",
        "# plt.legend(['y_test_lat', 'y_pred_lat'], loc='upper left')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plot Block_size VS Latency\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_size', y='actual_latency', color=base_color)\n",
        "# _ = sns.scatterplot(data=df_vis_lat, x='Block_size', y='prdicted_latency', color='red')\n",
        "# plt.title('Block size vs actual and prdicted latency')\n",
        "# plt.ylabel('Latency')\n",
        "# plt.xlabel('Block_size')\n",
        "# plt.legend(['actual_latency', 'prdicted_latency'], loc='upper right')\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "## residuals\n",
        "residuals = y_test_lat - y_pred_lat\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true  = y_test_lat.get(max_idx)\n",
        "max_pred = y_pred_lat[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))\n",
        "\n",
        "from statsmodels.graphics.api import abline_plot\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "ax.scatter(y_pred_lat, y_test_lat, color=\"black\")\n",
        "abline_plot(intercept=0, slope=1, color=\"red\", ax=ax)\n",
        "#ax[0].vlines(x=max_pred, ymin=max_true, ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n",
        "ax.grid(True)\n",
        "ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs Actual Latency\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "dALaE9iln-vz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ySmK3crQIPhu",
        "3R9U-GzuQY1c",
        "BXL4m2xtRDfd",
        "DDhyCOKXPkBy",
        "M99DdjFoSf_O",
        "m_-TgKxGGtPz"
      ],
      "name": "ExtraTreeRegressor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a278388d9b49f9b5de9743a0d0fcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2592615ad6af4bdb97df3e28eb017ecf",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_757f3a6850864f9b87049a1b335c1597"
          }
        },
        "2592615ad6af4bdb97df3e28eb017ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "757f3a6850864f9b87049a1b335c1597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "485d10ef5b3749aaab80585ddc9d3a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_d371e6093af74c05b0dd43f501355e6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a91a445d620c4de4b4c60d11f767df46"
          }
        },
        "d371e6093af74c05b0dd43f501355e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a91a445d620c4de4b4c60d11f767df46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25c5d9d9d3964495be264e0ff8d500cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fec14db65329472f9bbeee1995be08ef",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b7d927da08c405496facf56cdae8572"
          }
        },
        "fec14db65329472f9bbeee1995be08ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b7d927da08c405496facf56cdae8572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a35561fa17c84143924f9f276a71823c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8525441dcdd425ca63d1a76ae180a54",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_389ab271ead44b498ae498e6f2c64855"
          }
        },
        "f8525441dcdd425ca63d1a76ae180a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "389ab271ead44b498ae498e6f2c64855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd88e71a946d4e55ae413ef64bf1a6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_758fdaa572e143ffbbd5a04c524da5b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d27b8af787cd4fef839abb967b46da8d"
          }
        },
        "758fdaa572e143ffbbd5a04c524da5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d27b8af787cd4fef839abb967b46da8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caffd9a3e2654a64b5aecf41013a4e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_353d3d4b4ec146779e5f3c9363941972",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a72095a475b4b80bf55fbf989096b93"
          }
        },
        "353d3d4b4ec146779e5f3c9363941972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a72095a475b4b80bf55fbf989096b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}